{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T08:35:05.205674Z","iopub.status.busy":"2023-05-20T08:35:05.205297Z","iopub.status.idle":"2023-05-20T08:35:11.386121Z","shell.execute_reply":"2023-05-20T08:35:11.385155Z","shell.execute_reply.started":"2023-05-20T08:35:05.205643Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["from typing import Dict, List\n","\n","import numpy as np\n","import os\n","import pandas as pd\n","import argparse\n","import torch\n","import math\n","\n","from sklearn.metrics import f1_score\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from tqdm.auto import tqdm\n","from sklearn.utils import class_weight\n","import torch.nn.functional as F\n","import sklearn\n","from torch.cuda.amp import autocast, GradScaler\n","from sklearn.metrics import r2_score\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from transformers import AutoTokenizer, AutoModel\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","\n","from torch.utils.data import Dataset, DataLoader\n","\n","SEED = 227\n","\n","\n","class DataPreparation(Dataset):\n","    \n","    def __init__(self, tokenizer, data, scale_init, intelligence='verb', max_length=None, if_scale=True):\n","        \n","        self.tokenizer = tokenizer\n","        self.data = data\n","        self.intell = intelligence\n","        self.scale = scale_init\n","        self.if_scale = if_scale\n","        \n","        if max_length == None:\n","            max_length_counted = data[\"text\"].str.split(' ').str.len().max(axis=0)\n","            self.max_length = max_length_counted if max_length_counted < 512 else 512\n","        else:\n","            self.max_length = max_length\n","\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","\n","    def tokenize(self, text):\n","\n","        tokens = self.tokenizer(\n","            text,\n","            add_special_tokens=True,\n","            max_length=self.max_length,\n","            return_token_type_ids=False,\n","            padding=\"max_length\",\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_tensors='pt')\n","\n","        return tokens\n","\n","\n","    def scaling(self, labels):\n","      \n","        scaled_target = self.scale.transform(np.array(labels).reshape(-1, 1))\n","        \n","        return scaled_target\n","\n","     \n","    def __getitem__(self, index):\n","        \n","        source_text = self.data['text'].iloc[index]\n","        source = self.tokenize(source_text)\n","\n","        source_ids = source[\"input_ids\"].squeeze()\n","        source_mask = source[\"attention_mask\"].squeeze()\n","        \n","        if self.if_scale:\n","            scaled_labels = self.scaling(self.data[self.intell])\n","            label = scaled_labels[index][0]\n","        else:\n","            label = self.data[self.intell].iloc[index]\n","\n","        return {\n","            \"source_ids\": source_ids.to(dtype=torch.long),\n","            \"source_mask\": source_mask.to(dtype=torch.long),\n","            \"labels\":  label\n","        }\n","\n","class BertBaseline(nn.Module):\n","    \n","    def __init__(self, bert, output_neurons):\n","        super(BertBaseline, self).__init__()\n","\n","        self.bert = AutoModel.from_pretrained(bert)\n","\n","        self.dropout = nn.Dropout(0.5)\n","        self.relu = nn.ReLU()\n","        self.fc1 = nn.Linear(768,400)\n","        self.fc2 = nn.Linear(400,20)\n","        self.fc3 = nn.Linear(20,output_neurons)\n","    \n","    def forward(self, input_ids, attention_mask):\n","\n","        _, cls_hs = self.bert(input_ids, attention_mask = attention_mask, return_dict = False)\n","        x = self.fc1(cls_hs)\n","        x = self.dropout(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        x = self.dropout(x)\n","        x = self.relu(x)\n","        x = self.fc3(x)\n","        return x\n","    \n","\n","def initialize_scaling(data_org, intell):\n","    scale = StandardScaler().fit(np.array(data_org[intell]).reshape(-1, 1))\n","    return scale\n","\n","def inverse_toorig(scaler, list_of_labels):\n","    inverse = scaler.inverse_transform(list_of_labels.reshape(-1, 1))\n","    return inverse\n","\n","\n","def train(model, data_loader, device, optimizer, criterion, n_epoch):\n","\n","    print('Epoch #{}\\n'.format(n_epoch+1))\n","\n","    train_losses = []\n","    train_labels = []\n","    train_predictions = []   \n","\n","    progress_bar = tqdm(total=math.ceil(len(data_loader.dataset)/data_loader.batch_size), \n","                        desc='Epoch {}'.format(n_epoch + 1))\n","\n","    model.train()\n","\n","    for _, data in enumerate(data_loader, 0):\n","\n","\n","          input_ids = data[\"source_ids\"].to(device)\n","          attention_mask = data[\"source_mask\"].to(device)\n","          labels = data['labels'].to(device)\n","\n","          optimizer.zero_grad()\n","\n","          pred = model(input_ids=input_ids, attention_mask=attention_mask)\n","          loss = criterion(pred, labels)\n","              \n","          loss.backward()\n","              \n","          optimizer.step()\n","\n","          _, predict = torch.max(pred.cpu().data, 1)\n","          train_losses.append(loss.item())\n","          train_labels.extend(labels.cpu().detach().numpy())\n","          train_predictions.extend(predict.cpu().detach().numpy())\n","\n","          progress_bar.set_postfix(loss=np.mean(train_losses))\n","          progress_bar.update(1)\n","    \n","    progress_bar.update(1)\n","    progress_bar.close()\n","  \n","    \n","    print('\\n\\nMean Loss after epoch #{0} - {1}'.format(str(n_epoch + 1), np.mean(train_losses)))\n","    print('F1 score after epoch #{0} on train - {1}\\n'.format(str(n_epoch + 1), f1_score(train_labels, train_predictions, average='macro')))\n","    print('Accuracy score after epoch #{0} on train - {1}\\n'.format(str(n_epoch + 1), accuracy_score(train_labels, train_predictions)))\n","\n","    print(classification_report(train_labels, train_predictions))\n","    \n","    return train_labels, train_predictions\n","\n","\n","def validating(model, data_loader, device, criterion, n_epoch):\n","\n","    val_losses, val_labels, val_predictions = [], [], []\n","\n","    progress_bar = tqdm(total=math.ceil(len(data_loader.dataset)/data_loader.batch_size),\n","                        desc='Epoch {}'.format(n_epoch + 1))\n","\n","    model.eval()\n","\n","    for _, data in enumerate(data_loader, 0):\n","          \n","          input_ids = data[\"source_ids\"].to(device)\n","          attention_mask = data[\"source_mask\"].to(device)\n","          labels = data['labels'].to(device)\n","\n","          with torch.no_grad():\n","              pred = model(input_ids, attention_mask)\n","\n","          loss = criterion(pred, labels)\n","          \n","          _, predict = torch.max(pred.cpu().data, 1)\n","\n","          val_losses.append(loss.item())\n","          val_labels.extend(labels.cpu().detach().numpy())\n","          val_predictions.extend(predict.cpu().detach().numpy())\n","\n","          progress_bar.set_postfix(loss=np.mean(val_losses))\n","          progress_bar.update(1)\n","\n","    progress_bar.update(1)\n","    progress_bar.close()\n","    \n","    \n","    valid_stats.append(\n","        {\n","            'Val Loss': np.mean(val_losses)\n","        }\n","    )\n","\n","    print('\\n\\nMean Loss after epoch #{0} - {1}'.format(str(n_epoch + 1), np.mean(val_losses)))\n","    print('F1 score after epoch #{0} on validation - {1}\\n'.format(str(n_epoch + 1), f1_score(val_labels, val_predictions, average='macro')))\n","    print('Accuracy score after epoch #{0} on validation - {1}\\n'.format(str(n_epoch + 1), accuracy_score(val_labels, val_predictions)))\n","    \n","    print(classification_report(val_labels, val_predictions))\n","    return valid_stats\n","\n","\n","def evaluate(model, train_dataset, val_dataset, device, epochs, target_value, weights):\n","    \n","    model = model.to(device)\n","    optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-5)\n","    criterion = nn.CrossEntropyLoss(weight=weights,reduction='mean').to(device)\n","\n","    global valid_stats\n","    valid_stats = []\n","    best_valid_loss = float('inf')\n","\n","    for epoch in range(epochs):\n","        # train\n","        try:\n","            train(model, train_dataset, device, optimizer, criterion,  epoch)\n","            # # validate\n","            validating(model, val_dataset, device, criterion, epoch)\n","\n","            if valid_stats[epoch]['Val Loss'] < best_valid_loss:\n","                best_valid_loss = valid_stats[epoch]['Val Loss']\n","\n","                name_to_save = f'model_baseline_basic_{target_value}'\n","                if os.path.isfile('results/'+name_to_save+'.pth'):\n","                    os.remove('results/'+name_to_save+'.pth')\n","                    torch.save(model.state_dict(), 'results/'+name_to_save+'.pth')\n","                else:\n","                    if not os.path.isdir('results'):\n","                        os.mkdir('results')\n","                    torch.save(model.state_dict(), 'results/'+name_to_save+'.pth')\n","#                     else:\n","#                         os.mkdir('results')\n","        except KeyboardInterrupt:\n","            break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T09:16:04.513027Z","iopub.status.busy":"2023-05-20T09:16:04.512609Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch #1\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ac7b6e3a71f49b59d9f5b29ac34f53b","version_major":2,"version_minor":0},"text/plain":["Epoch 1:   0%|          | 0/593 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #1 - 1.6097260967299745\n","F1 score after epoch #1 on train - 0.17688218116596705\n","\n","Accuracy score after epoch #1 on train - 0.26013513513513514\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.19      0.54      0.28       810\n","           1       0.16      0.04      0.07       899\n","           2       0.44      0.33      0.38      2079\n","           3       0.16      0.07      0.10       759\n","           4       0.06      0.08      0.07       189\n","\n","    accuracy                           0.26      4736\n","   macro avg       0.20      0.21      0.18      4736\n","weighted avg       0.28      0.26      0.24      4736\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"171630f2e13641ef8f05c081d680777e","version_major":2,"version_minor":0},"text/plain":["Epoch 1:   0%|          | 0/119 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #1 - 1.5937832814304769\n","F1 score after epoch #1 on validation - 0.17481095176010433\n","\n","Accuracy score after epoch #1 on validation - 0.370253164556962\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.23      0.61      0.34       162\n","           1       0.00      0.00      0.00       180\n","           2       0.48      0.61      0.54       416\n","           3       0.00      0.00      0.00       152\n","           4       0.00      0.00      0.00        38\n","\n","    accuracy                           0.37       948\n","   macro avg       0.14      0.24      0.17       948\n","weighted avg       0.25      0.37      0.29       948\n","\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Epoch #2\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eb45123e8f22465d98951d5dc2a25b8b","version_major":2,"version_minor":0},"text/plain":["Epoch 2:   0%|          | 0/593 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #2 - 1.5908503399507419\n","F1 score after epoch #2 on train - 0.2035247309160174\n","\n","Accuracy score after epoch #2 on train - 0.2782939189189189\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.23      0.57      0.32       809\n","           1       0.16      0.05      0.07       900\n","           2       0.44      0.30      0.35      2080\n","           3       0.22      0.25      0.24       759\n","           4       0.03      0.03      0.03       188\n","\n","    accuracy                           0.28      4736\n","   macro avg       0.22      0.24      0.20      4736\n","weighted avg       0.30      0.28      0.26      4736\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"53e3473e9b074b06bd0ef96492e0aa75","version_major":2,"version_minor":0},"text/plain":["Epoch 2:   0%|          | 0/119 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #2 - 1.584333456864878\n","F1 score after epoch #2 on validation - 0.18651090058905692\n","\n","Accuracy score after epoch #2 on validation - 0.399789029535865\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.27      0.60      0.37       162\n","           1       0.00      0.00      0.00       180\n","           2       0.48      0.68      0.57       416\n","           3       0.00      0.00      0.00       152\n","           4       0.00      0.00      0.00        38\n","\n","    accuracy                           0.40       948\n","   macro avg       0.15      0.26      0.19       948\n","weighted avg       0.26      0.40      0.31       948\n","\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Epoch #3\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c8c7e0afc00d4432925b46c60982d792","version_major":2,"version_minor":0},"text/plain":["Epoch 3:   0%|          | 0/593 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #3 - 1.5763913314487483\n","F1 score after epoch #3 on train - 0.22137422532106016\n","\n","Accuracy score after epoch #3 on train - 0.30215371621621623\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.24      0.56      0.34       809\n","           1       0.18      0.05      0.07       899\n","           2       0.44      0.36      0.40      2080\n","           3       0.22      0.22      0.22       759\n","           4       0.08      0.07      0.07       189\n","\n","    accuracy                           0.30      4736\n","   macro avg       0.23      0.25      0.22      4736\n","weighted avg       0.31      0.30      0.29      4736\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ff06b2a4bca4cafbbfc7564c21a7ecd","version_major":2,"version_minor":0},"text/plain":["Epoch 3:   0%|          | 0/119 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #3 - 1.5727597555192578\n","F1 score after epoch #3 on validation - 0.1652091257614076\n","\n","Accuracy score after epoch #3 on validation - 0.2521097046413502\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.22      0.82      0.35       162\n","           1       0.00      0.00      0.00       180\n","           2       0.48      0.12      0.19       416\n","           3       0.24      0.38      0.29       152\n","           4       0.00      0.00      0.00        38\n","\n","    accuracy                           0.25       948\n","   macro avg       0.19      0.26      0.17       948\n","weighted avg       0.28      0.25      0.19       948\n","\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Epoch #4\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"91a3ba06b6fa412e90bdddafd32d19b4","version_major":2,"version_minor":0},"text/plain":["Epoch 4:   0%|          | 0/593 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["path_to_data = '/kaggle/input/traits-no-naives/dataset_all_nlp_features_target_classes_no_naive (1).csv'\n","target_value = 'raven'\n","path_to_model = 'DeepPavlov/rubert-base-cased'\n","epochs = 15\n","\n","dataset = pd.read_csv(path_to_data, sep='\\t')\n","\n","dataset = dataset[dataset.question_id != '129_Чтение текста - видео']\n","\n","if target_value == 'raven':\n","    dataset = dataset[dataset[\"raven\"] > 0]\n","if target_value == 'verb':\n","    dataset = dataset[dataset[\"verb\"] > 0]\n","        \n","tokenizer = AutoTokenizer.from_pretrained(path_to_model)\n","\n","intelligence = target_value+'_classes'\n","\n","dataset[intelligence] = dataset[intelligence].astype(int)\n","\n","dataset = dataset[dataset['N_words'] > 2]\n","\n","train_data, extra_data = train_test_split(dataset, test_size=0.25,\n","                                        stratify=dataset[intelligence],\n","                                        random_state=SEED)\n","\n","vaild_data, test_data = train_test_split(extra_data, test_size=0.4,\n","                                        stratify=extra_data[intelligence],\n","                                        random_state=SEED)\n","        \n","scaler = initialize_scaling(train_data, target_value)\n","\n","train_dataset_data = DataPreparation(\n","            tokenizer=tokenizer,\n","            data = train_data,\n","            scale_init = scaler,\n","            intelligence = intelligence,\n","            max_length = 120,\n","            if_scale = False\n","        )\n","\n","val_dataset_data = DataPreparation(\n","            tokenizer=tokenizer,\n","            data = vaild_data,\n","            scale_init = scaler,\n","            intelligence = intelligence,\n","            max_length = 120,\n","            if_scale = False\n","        )\n","\n","test_dataset_data = DataPreparation(\n","            tokenizer=tokenizer,\n","            data = test_data,\n","            scale_init = scaler,\n","            intelligence = intelligence,\n","            max_length = 120,\n","            if_scale = False\n","        )\n","\n","weights = class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(dataset[intelligence]), y=dataset[intelligence].to_numpy())\n","wights_tensor = torch.tensor(weights,dtype=torch.float)\n","\n","train_dataset = DataLoader(train_dataset_data, batch_size=8, drop_last=True, shuffle=True)\n","val_dataset = DataLoader(val_dataset_data, batch_size=8)\n","test_dataset = DataLoader(test_dataset_data, batch_size=8)\n","        \n","model = BertBaseline(bert=path_to_model, output_neurons=len(dataset[intelligence].unique()))\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","evaluate(model=model, train_dataset=train_dataset, val_dataset=val_dataset, device=device, epochs=epochs, target_value=target_value, weights=wights_tensor)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T09:13:01.699910Z","iopub.status.busy":"2023-05-20T09:13:01.697441Z","iopub.status.idle":"2023-05-20T09:13:01.723327Z","shell.execute_reply":"2023-05-20T09:13:01.716663Z","shell.execute_reply.started":"2023-05-20T09:13:01.699865Z"},"trusted":true},"outputs":[],"source":["def test(data_loader, device):\n","    \n","    model.load_state_dict(torch.load('/kaggle/working/results/model_baseline_basic_verb.pth'))\n","    \n","    test_labels, test_predictions = [], []\n","\n","    model.eval()\n","\n","    for _, data in enumerate(data_loader, 0):\n","          \n","          input_ids = data[\"source_ids\"].to(device)\n","          attention_mask = data[\"source_mask\"].to(device)\n","          labels = data['labels'].to(device)\n","          with torch.no_grad():\n","              pred = model(input_ids, attention_mask)\n","         \n","          _, predict = torch.max(pred.cpu().data, 1)\n","\n","          test_labels.extend(labels.cpu().detach().numpy())\n","          test_predictions.extend(predict.cpu().detach().numpy())\n","\n","    print('F1 macro score on test - {0}\\n'.format(f1_score(test_labels, test_predictions, average='macro')))\n","    print('F1 score on test - {0}\\n'.format(f1_score(test_labels, test_predictions, average='weighted')))\n","    print('Accuracy score on test - {0}\\n'.format(accuracy_score(test_labels, test_predictions)))\n","    \n","    print(classification_report(test_labels, test_predictions))"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T09:13:05.275799Z","iopub.status.busy":"2023-05-20T09:13:05.275390Z","iopub.status.idle":"2023-05-20T09:13:42.782635Z","shell.execute_reply":"2023-05-20T09:13:42.781447Z","shell.execute_reply.started":"2023-05-20T09:13:05.275764Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["F1 macro score on test - 0.3283653928609622\n","\n","F1 score on test - 0.2830607059035576\n","\n","Accuracy score on test - 0.3951812191103789\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.58      0.90      0.70       910\n","           1       0.26      0.64      0.37       742\n","           2       0.43      0.03      0.06      1231\n","           3       0.00      0.00      0.00      1211\n","           4       0.38      0.78      0.51       762\n","\n","    accuracy                           0.40      4856\n","   macro avg       0.33      0.47      0.33      4856\n","weighted avg       0.32      0.40      0.28      4856\n","\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["test(train_dataset, device)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T09:13:42.785728Z","iopub.status.busy":"2023-05-20T09:13:42.784921Z","iopub.status.idle":"2023-05-20T09:13:50.737460Z","shell.execute_reply":"2023-05-20T09:13:50.736386Z","shell.execute_reply.started":"2023-05-20T09:13:42.785685Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["F1 macro score on test - 0.22011847140232113\n","\n","F1 score on test - 0.1899953233399893\n","\n","Accuracy score on test - 0.2623456790123457\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.38      0.62      0.47       182\n","           1       0.17      0.44      0.24       148\n","           2       0.27      0.02      0.04       247\n","           3       0.00      0.00      0.00       243\n","           4       0.27      0.47      0.34       152\n","\n","    accuracy                           0.26       972\n","   macro avg       0.22      0.31      0.22       972\n","weighted avg       0.21      0.26      0.19       972\n","\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["test(val_dataset, device)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T09:13:50.740232Z","iopub.status.busy":"2023-05-20T09:13:50.739167Z","iopub.status.idle":"2023-05-20T09:13:56.119325Z","shell.execute_reply":"2023-05-20T09:13:56.118162Z","shell.execute_reply.started":"2023-05-20T09:13:50.740191Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["F1 macro score on test - 0.21739820120813533\n","\n","F1 score on test - 0.18868241368802394\n","\n","Accuracy score on test - 0.26080246913580246\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.34      0.57      0.43       122\n","           1       0.17      0.40      0.24        99\n","           2       0.42      0.03      0.06       164\n","           3       0.00      0.00      0.00       161\n","           4       0.27      0.53      0.36       102\n","\n","    accuracy                           0.26       648\n","   macro avg       0.24      0.31      0.22       648\n","weighted avg       0.24      0.26      0.19       648\n","\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["test(test_dataset, device)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
