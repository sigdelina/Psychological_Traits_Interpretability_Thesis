{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"execution":{"iopub.execute_input":"2023-05-27T10:57:51.818293Z","iopub.status.busy":"2023-05-27T10:57:51.817941Z","iopub.status.idle":"2023-05-27T10:58:04.101744Z","shell.execute_reply":"2023-05-27T10:58:04.100577Z","shell.execute_reply.started":"2023-05-27T10:57:51.818262Z"},"executionInfo":{"elapsed":14244,"status":"ok","timestamp":1684429681537,"user":{"displayName":"Help Study","userId":"07310851891543285849"},"user_tz":-180},"id":"PlIc-guUyjSS","jupyter":{"outputs_hidden":true},"outputId":"5ebbb13e-4d9d-4700-f777-107e5e34aaaa","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.29.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (5.4.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.5.5)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T10:58:04.105773Z","iopub.status.busy":"2023-05-27T10:58:04.105434Z","iopub.status.idle":"2023-05-27T10:58:10.846757Z","shell.execute_reply":"2023-05-27T10:58:10.845754Z","shell.execute_reply.started":"2023-05-27T10:58:04.105743Z"},"id":"bL2s5dvOi6Dx","trusted":true},"outputs":[],"source":["from typing import Dict, List\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import torch\n","\n","from sklearn.metrics import f1_score\n","from torch import nn\n","from transformers import AutoTokenizer, AutoModel\n","from torch.utils.data import DataLoader\n","from tqdm.auto import tqdm\n","import torch.nn.functional as F\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import scipy\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T10:58:10.848946Z","iopub.status.busy":"2023-05-27T10:58:10.848285Z","iopub.status.idle":"2023-05-27T10:58:11.185221Z","shell.execute_reply":"2023-05-27T10:58:11.184322Z","shell.execute_reply.started":"2023-05-27T10:58:10.848909Z"},"id":"Jl3mVh07oJg5","trusted":true},"outputs":[],"source":["dataset = pd.read_csv('/kaggle/input/no-naives/dataset_all_nlp_features_target_classes_no_naive.csv', sep='\\t')\n","dataset = dataset[dataset.question_id != '129_Чтение текста - видео']\n","dataset = dataset[dataset['N_words'] > 2]\n","# dataset = dataset[dataset[\"verb\"] > 0]\n","# dataset = dataset[dataset[\"raven\"] > 0]"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":394},"execution":{"iopub.execute_input":"2023-05-27T10:58:11.188098Z","iopub.status.busy":"2023-05-27T10:58:11.187708Z","iopub.status.idle":"2023-05-27T10:58:11.353322Z","shell.execute_reply":"2023-05-27T10:58:11.352212Z","shell.execute_reply.started":"2023-05-27T10:58:11.188064Z"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1684430215601,"user":{"displayName":"Help Study","userId":"07310851891543285849"},"user_tz":-180},"id":"IvDGX-PZoVS_","outputId":"2c1b8531-98d2-41ee-f6ae-92bed24c9e72","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>task_id</th>\n","      <th>user_id</th>\n","      <th>age</th>\n","      <th>E</th>\n","      <th>A</th>\n","      <th>C</th>\n","      <th>N</th>\n","      <th>O</th>\n","      <th>AP</th>\n","      <th>AM</th>\n","      <th>...</th>\n","      <th>raven_classes</th>\n","      <th>verb_classes</th>\n","      <th>AM_classes</th>\n","      <th>AP_classes</th>\n","      <th>BM_classes</th>\n","      <th>BP_classes</th>\n","      <th>GM_classes</th>\n","      <th>GP_classes</th>\n","      <th>DM_classes</th>\n","      <th>DP_classes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>6477.000000</td>\n","      <td>6477.000000</td>\n","      <td>1736.000000</td>\n","      <td>6477.000000</td>\n","      <td>6477.000000</td>\n","      <td>6477.000000</td>\n","      <td>6477.000000</td>\n","      <td>6477.000000</td>\n","      <td>6477.000000</td>\n","      <td>6477.000000</td>\n","      <td>...</td>\n","      <td>6467.000000</td>\n","      <td>6477.000000</td>\n","      <td>6477.000000</td>\n","      <td>6477.000000</td>\n","      <td>6477.000000</td>\n","      <td>6477.000000</td>\n","      <td>6477.000000</td>\n","      <td>6477.000000</td>\n","      <td>6477.000000</td>\n","      <td>6477.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>6.098966</td>\n","      <td>658.156091</td>\n","      <td>23.868664</td>\n","      <td>3.520113</td>\n","      <td>3.681306</td>\n","      <td>3.681509</td>\n","      <td>2.960723</td>\n","      <td>3.755056</td>\n","      <td>3.840862</td>\n","      <td>2.150763</td>\n","      <td>...</td>\n","      <td>1.666306</td>\n","      <td>2.035510</td>\n","      <td>0.516134</td>\n","      <td>1.232978</td>\n","      <td>0.844527</td>\n","      <td>0.920179</td>\n","      <td>0.710514</td>\n","      <td>1.008492</td>\n","      <td>0.695538</td>\n","      <td>1.330400</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>3.536441</td>\n","      <td>279.490692</td>\n","      <td>6.199752</td>\n","      <td>0.827778</td>\n","      <td>0.678065</td>\n","      <td>0.826531</td>\n","      <td>0.894088</td>\n","      <td>0.653033</td>\n","      <td>0.551309</td>\n","      <td>0.681014</td>\n","      <td>...</td>\n","      <td>1.077559</td>\n","      <td>1.333504</td>\n","      <td>0.725172</td>\n","      <td>0.762120</td>\n","      <td>0.810527</td>\n","      <td>0.759715</td>\n","      <td>0.781998</td>\n","      <td>0.772894</td>\n","      <td>0.826484</td>\n","      <td>0.725106</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>124.000000</td>\n","      <td>18.000000</td>\n","      <td>1.130000</td>\n","      <td>1.444444</td>\n","      <td>1.330000</td>\n","      <td>1.000000</td>\n","      <td>1.700000</td>\n","      <td>1.670000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>-1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>3.000000</td>\n","      <td>437.000000</td>\n","      <td>20.000000</td>\n","      <td>2.880000</td>\n","      <td>3.222222</td>\n","      <td>3.000000</td>\n","      <td>2.250000</td>\n","      <td>3.300000</td>\n","      <td>3.555556</td>\n","      <td>1.666667</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>6.000000</td>\n","      <td>654.000000</td>\n","      <td>22.000000</td>\n","      <td>3.500000</td>\n","      <td>3.670000</td>\n","      <td>3.777778</td>\n","      <td>3.000000</td>\n","      <td>3.800000</td>\n","      <td>3.888889</td>\n","      <td>2.110000</td>\n","      <td>...</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>9.000000</td>\n","      <td>874.000000</td>\n","      <td>25.000000</td>\n","      <td>4.250000</td>\n","      <td>4.220000</td>\n","      <td>4.333333</td>\n","      <td>3.625000</td>\n","      <td>4.300000</td>\n","      <td>4.220000</td>\n","      <td>2.555556</td>\n","      <td>...</td>\n","      <td>2.000000</td>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>12.000000</td>\n","      <td>1167.000000</td>\n","      <td>51.000000</td>\n","      <td>5.000000</td>\n","      <td>5.000000</td>\n","      <td>5.000000</td>\n","      <td>5.000000</td>\n","      <td>5.000000</td>\n","      <td>5.000000</td>\n","      <td>5.000000</td>\n","      <td>...</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 57 columns</p>\n","</div>"],"text/plain":["           task_id      user_id          age            E            A  \\\n","count  6477.000000  6477.000000  1736.000000  6477.000000  6477.000000   \n","mean      6.098966   658.156091    23.868664     3.520113     3.681306   \n","std       3.536441   279.490692     6.199752     0.827778     0.678065   \n","min       1.000000   124.000000    18.000000     1.130000     1.444444   \n","25%       3.000000   437.000000    20.000000     2.880000     3.222222   \n","50%       6.000000   654.000000    22.000000     3.500000     3.670000   \n","75%       9.000000   874.000000    25.000000     4.250000     4.220000   \n","max      12.000000  1167.000000    51.000000     5.000000     5.000000   \n","\n","                 C            N            O           AP           AM  ...  \\\n","count  6477.000000  6477.000000  6477.000000  6477.000000  6477.000000  ...   \n","mean      3.681509     2.960723     3.755056     3.840862     2.150763  ...   \n","std       0.826531     0.894088     0.653033     0.551309     0.681014  ...   \n","min       1.330000     1.000000     1.700000     1.670000     1.000000  ...   \n","25%       3.000000     2.250000     3.300000     3.555556     1.666667  ...   \n","50%       3.777778     3.000000     3.800000     3.888889     2.110000  ...   \n","75%       4.333333     3.625000     4.300000     4.220000     2.555556  ...   \n","max       5.000000     5.000000     5.000000     5.000000     5.000000  ...   \n","\n","       raven_classes  verb_classes   AM_classes   AP_classes   BM_classes  \\\n","count    6467.000000   6477.000000  6477.000000  6477.000000  6477.000000   \n","mean        1.666306      2.035510     0.516134     1.232978     0.844527   \n","std         1.077559      1.333504     0.725172     0.762120     0.810527   \n","min        -1.000000      0.000000     0.000000     0.000000     0.000000   \n","25%         1.000000      1.000000     0.000000     1.000000     0.000000   \n","50%         2.000000      2.000000     0.000000     1.000000     1.000000   \n","75%         2.000000      3.000000     1.000000     2.000000     2.000000   \n","max         4.000000      4.000000     2.000000     2.000000     2.000000   \n","\n","        BP_classes   GM_classes   GP_classes   DM_classes   DP_classes  \n","count  6477.000000  6477.000000  6477.000000  6477.000000  6477.000000  \n","mean      0.920179     0.710514     1.008492     0.695538     1.330400  \n","std       0.759715     0.781998     0.772894     0.826484     0.725106  \n","min       0.000000     0.000000     0.000000     0.000000     0.000000  \n","25%       0.000000     0.000000     0.000000     0.000000     1.000000  \n","50%       1.000000     1.000000     1.000000     0.000000     1.000000  \n","75%       2.000000     1.000000     2.000000     1.000000     2.000000  \n","max       2.000000     2.000000     2.000000     2.000000     2.000000  \n","\n","[8 rows x 57 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["dataset.describe()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T10:58:11.454339Z","iopub.status.busy":"2023-05-27T10:58:11.453913Z","iopub.status.idle":"2023-05-27T10:58:11.465679Z","shell.execute_reply":"2023-05-27T10:58:11.465014Z","shell.execute_reply.started":"2023-05-27T10:58:11.454285Z"},"id":"bKNG5IcHrlql","trusted":true},"outputs":[],"source":["def get_circumplex_labels(dataset):\n","    AP_LABELS = list(set(dataset['AP_classes'].unique()))\n","    AP_SCORE_INDICES = range(0, 3)\n","    AM_LABELS = list(set(dataset['AM_classes'].unique()))\n","    AM_SCORE_INDICES = range(3, 6)\n","\n","    BP_LABELS = list(set(dataset['BP_classes'].unique()))\n","    BP_SCORE_INDICES = range(6, 9)\n","    BM_LABELS = list(set(dataset['BM_classes'].unique()))\n","    BM_SCORE_INDICES = range(9, 12)\n","\n","    GP_LABELS = list(set(dataset['GP_classes'].unique()))\n","    GP_SCORE_INDICES = range(12, 15)\n","    GM_LABELS = list(set(dataset['GM_classes'].unique()))\n","    GM_SCORE_INDICES = range(15, 18)\n","\n","    DP_LABELS = list(set(dataset['DP_classes'].unique()))\n","    DP_SCORE_INDICES = range(18, 21)\n","    DM_LABELS = list(set(dataset['DM_classes'].unique()))\n","    DM_SCORE_INDICES = range(21, 24)\n","\n","    CIRCLE_LABELS = AP_LABELS + AM_LABELS + BP_LABELS + BM_LABELS + GP_LABELS + GM_LABELS + DP_LABELS + DM_LABELS\n","    INDEXEX_CIRCLE = [AP_SCORE_INDICES, AM_SCORE_INDICES, BP_SCORE_INDICES,\n","                      BM_SCORE_INDICES, GP_SCORE_INDICES, GM_SCORE_INDICES,\n","                      DP_SCORE_INDICES, DM_SCORE_INDICES]\n","    return INDEXEX_CIRCLE, CIRCLE_LABELS\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T10:58:11.467760Z","iopub.status.busy":"2023-05-27T10:58:11.467103Z","iopub.status.idle":"2023-05-27T10:58:11.480674Z","shell.execute_reply":"2023-05-27T10:58:11.479751Z","shell.execute_reply.started":"2023-05-27T10:58:11.467728Z"},"id":"1aifASulZTYs","trusted":true},"outputs":[],"source":["curc_indexes, curc_labels = get_circumplex_labels(dataset)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-05-27T10:58:11.485023Z","iopub.status.busy":"2023-05-27T10:58:11.484371Z","iopub.status.idle":"2023-05-27T10:58:11.491392Z","shell.execute_reply":"2023-05-27T10:58:11.490604Z","shell.execute_reply.started":"2023-05-27T10:58:11.484989Z"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1684430216910,"user":{"displayName":"Help Study","userId":"07310851891543285849"},"user_tz":-180},"id":"XgcTvyJfZb8R","outputId":"61408bc3-8e4a-4c4e-ec21-7a8764578449","trusted":true},"outputs":[{"data":{"text/plain":["[range(0, 3),\n"," range(3, 6),\n"," range(6, 9),\n"," range(9, 12),\n"," range(12, 15),\n"," range(15, 18),\n"," range(18, 21),\n"," range(21, 24)]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["curc_indexes"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T10:58:11.502370Z","iopub.status.busy":"2023-05-27T10:58:11.501670Z","iopub.status.idle":"2023-05-27T10:58:11.516666Z","shell.execute_reply":"2023-05-27T10:58:11.515936Z","shell.execute_reply.started":"2023-05-27T10:58:11.502340Z"},"id":"7GsLYLVJjMmy","trusted":true},"outputs":[],"source":["class DataPreparation(Dataset):\n","    \n","    def __init__(self, tokenizer, data, target_values='circumplex', max_length=None):\n","        \n","        self.tokenizer = tokenizer\n","        self.data = data\n","        self.t_val = target_values\n","        \n","        if max_length == None:\n","            max_length_counted = data[\"text\"].str.split(' ').str.len().max(axis=0)\n","            self.max_length = max_length_counted if max_length_counted < 512 else 512\n","        else:\n","            self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def tokenize(self, text):\n","\n","        tokens = self.tokenizer(\n","            text,\n","            add_special_tokens=True,\n","            max_length=self.max_length,\n","            return_token_type_ids=False,\n","            padding=\"max_length\",\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_tensors='pt')\n","\n","        return tokens\n","    \n","\n","    def reorganize_labels(self, row):\n","\n","        def return_zeros(row_data, classes):\n","          labels_zeros = np.zeros(len(set(self.data[classes].unique())))\n","          labels_zeros[row_data[classes]] = 1\n","          return labels_zeros\n","\n","        return np.concatenate((return_zeros(row, 'AP_classes'), return_zeros(row, 'AM_classes'),\n","                               return_zeros(row, 'BP_classes'), return_zeros(row, 'BM_classes'),\n","                               return_zeros(row, 'GP_classes'), return_zeros(row, 'GM_classes'),\n","                               return_zeros(row, 'DP_classes'), return_zeros(row, 'DM_classes')\n","                               ))   \n","\n","\n","    def __getitem__(self, index):\n","        \n","        source_text = self.data['text'].iloc[index]\n","        source = self.tokenize(source_text)\n","\n","        source_ids = source[\"input_ids\"].squeeze()\n","        source_mask = source[\"attention_mask\"].squeeze()\n","        \n","        labels = self.reorganize_labels(self.data.iloc[index])\n","        \n","\n","        return {\n","            \"source_ids\": source_ids.to(dtype=torch.long),\n","            \"source_mask\": source_mask.to(dtype=torch.long),\n","            \"labels\":  labels\n","        }"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T10:58:11.518942Z","iopub.status.busy":"2023-05-27T10:58:11.518199Z","iopub.status.idle":"2023-05-27T10:58:13.148889Z","shell.execute_reply":"2023-05-27T10:58:13.147924Z","shell.execute_reply.started":"2023-05-27T10:58:11.518910Z"},"id":"9BoWQGFZyfly","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f19f2b16bcaa4e97a6050679101b23f7","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"abd5ec098d864414869cf9e943f6da43","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"addf28e0d2624f398513d31ce5bb4613","version_major":2,"version_minor":0},"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/1.65M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"931238264b8a431eae81c6f7bcc8ec13","version_major":2,"version_minor":0},"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model_name = 'DeepPavlov/rubert-base-cased'\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-05-27T10:58:13.150791Z","iopub.status.busy":"2023-05-27T10:58:13.150406Z","iopub.status.idle":"2023-05-27T10:58:13.167411Z","shell.execute_reply":"2023-05-27T10:58:13.166277Z","shell.execute_reply.started":"2023-05-27T10:58:13.150753Z"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1684430216914,"user":{"displayName":"Help Study","userId":"07310851891543285849"},"user_tz":-180},"id":"Vh5u12noy3z6","outputId":"73c89dc5-00d8-4474-f800-0f38ff3abbdd","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["5181 713 583\n"]}],"source":["np.random.seed(112)\n","train_data, vaild_data, test_data = np.split(dataset.sample(frac=1, random_state=42), \n","                                     [int(.80*len(dataset)), int(.91*len(dataset))])\n","\n","print(len(train_data),len(vaild_data), len(test_data))"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":310},"execution":{"iopub.execute_input":"2023-05-27T10:58:13.169437Z","iopub.status.busy":"2023-05-27T10:58:13.168740Z","iopub.status.idle":"2023-05-27T10:58:13.192203Z","shell.execute_reply":"2023-05-27T10:58:13.191225Z","shell.execute_reply.started":"2023-05-27T10:58:13.169405Z"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1684430216915,"user":{"displayName":"Help Study","userId":"07310851891543285849"},"user_tz":-180},"id":"f5oC_LHa_WW7","outputId":"9250cb67-7480-4be9-caf6-06f4eecc2d46","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>f</th>\n","      <th>filename</th>\n","      <th>task_id</th>\n","      <th>question_id</th>\n","      <th>user_id</th>\n","      <th>gender</th>\n","      <th>age</th>\n","      <th>E</th>\n","      <th>A</th>\n","      <th>...</th>\n","      <th>raven_classes</th>\n","      <th>verb_classes</th>\n","      <th>AM_classes</th>\n","      <th>AP_classes</th>\n","      <th>BM_classes</th>\n","      <th>BP_classes</th>\n","      <th>GM_classes</th>\n","      <th>GP_classes</th>\n","      <th>DM_classes</th>\n","      <th>DP_classes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2138</th>\n","      <td>стала лучшим консультантом памперс</td>\n","      <td>NaN</td>\n","      <td>аудио/answer11_113_12665_3_241.wav</td>\n","      <td>11</td>\n","      <td>134_Видео-интервью</td>\n","      <td>241</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>4.13</td>\n","      <td>3.330000</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2467</th>\n","      <td>Вы знаете я нашла себе работу по любимую работу</td>\n","      <td>NaN</td>\n","      <td>аудио/answer11_113_20670_6_782.wav</td>\n","      <td>11</td>\n","      <td>134_Видео-интервью</td>\n","      <td>782</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>4.00</td>\n","      <td>3.555556</td>\n","      <td>...</td>\n","      <td>4.0</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2 rows × 63 columns</p>\n","</div>"],"text/plain":["                                                 text    f  \\\n","2138               стала лучшим консультантом памперс  NaN   \n","2467  Вы знаете я нашла себе работу по любимую работу  NaN   \n","\n","                                filename  task_id         question_id  \\\n","2138  аудио/answer11_113_12665_3_241.wav       11  134_Видео-интервью   \n","2467  аудио/answer11_113_20670_6_782.wav       11  134_Видео-интервью   \n","\n","      user_id gender  age     E         A  ...  raven_classes  verb_classes  \\\n","2138      241    NaN  NaN  4.13  3.330000  ...            0.0             0   \n","2467      782    NaN  NaN  4.00  3.555556  ...            4.0             4   \n","\n","      AM_classes  AP_classes  BM_classes  BP_classes  GM_classes  GP_classes  \\\n","2138           0           2           2           1           1           1   \n","2467           1           0           0           0           0           0   \n","\n","      DM_classes  DP_classes  \n","2138           2           0  \n","2467           0           1  \n","\n","[2 rows x 63 columns]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["train_data.head(2)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T10:58:13.194383Z","iopub.status.busy":"2023-05-27T10:58:13.193915Z","iopub.status.idle":"2023-05-27T10:58:13.202312Z","shell.execute_reply":"2023-05-27T10:58:13.201214Z","shell.execute_reply.started":"2023-05-27T10:58:13.194346Z"},"id":"-KDUzN23zNsf","trusted":true},"outputs":[],"source":["train_dataset_data = DataPreparation(\n","    tokenizer=tokenizer,\n","    data = train_data,\n","    max_length = 120,\n",")\n","\n","val_dataset_data = DataPreparation(\n","    tokenizer=tokenizer,\n","    data = vaild_data,\n","    max_length = 120,\n",")\n","\n","test_dataset_data = DataPreparation(\n","    tokenizer=tokenizer,\n","    data = test_data,\n","    max_length = 120,\n",")"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T10:58:13.204851Z","iopub.status.busy":"2023-05-27T10:58:13.204108Z","iopub.status.idle":"2023-05-27T10:58:13.212457Z","shell.execute_reply":"2023-05-27T10:58:13.211393Z","shell.execute_reply.started":"2023-05-27T10:58:13.204795Z"},"id":"EVYjthhfAi6d","trusted":true},"outputs":[],"source":["train_dataset = DataLoader(train_dataset_data, batch_size=8, drop_last=True, shuffle=True)\n","val_dataset = DataLoader(val_dataset_data, batch_size=8)\n","test_dataset = DataLoader(test_dataset_data, batch_size=8)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-05-27T10:58:13.227541Z","iopub.status.busy":"2023-05-27T10:58:13.226696Z","iopub.status.idle":"2023-05-27T10:58:13.332836Z","shell.execute_reply":"2023-05-27T10:58:13.331997Z","shell.execute_reply.started":"2023-05-27T10:58:13.227504Z"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1684430216918,"user":{"displayName":"Help Study","userId":"07310851891543285849"},"user_tz":-180},"id":"nln6y-oRBBKO","outputId":"b0426093-4bef-411e-e781-7b8c587dc949","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["source_ids shape: torch.Size([8, 120])\n","source_mask shape: torch.Size([8, 120])\n","labels shape: torch.Size([8, 24])\n"]}],"source":["b = next(iter(train_dataset))\n","for k, v in b.items():\n","    print(f'{k} shape: {v.shape}')\n","    # print(b['labels'])"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T10:58:13.336349Z","iopub.status.busy":"2023-05-27T10:58:13.336092Z","iopub.status.idle":"2023-05-27T10:58:13.360956Z","shell.execute_reply":"2023-05-27T10:58:13.359930Z","shell.execute_reply.started":"2023-05-27T10:58:13.336325Z"},"id":"9HjxI266BbV5","trusted":true},"outputs":[],"source":["class RNN_Block(nn.Module):\n","    \n","    def __init__(self, input_size=768, hidden_size=512, rnn='LSTM', biderectional=True):\n","        super().__init__()\n","\n","        rnn_type = {\"GRU\": nn.GRU, \"LSTM\": nn.LSTM, \"RNN\": nn.RNN}\n","        self.rnn = rnn_type[rnn](input_size=input_size,\n","                            hidden_size=hidden_size,\n","                            num_layers=1,\n","                            batch_first=True,\n","                            bidirectional=biderectional)\n","\n","\n","    def forward(self, input_ids):\n","        \n","        rnn_output = self.rnn(input_ids)\n","        return rnn_output\n","\n","\n","class CNN_Block(nn.Module):\n","    \n","    def __init__(self, input_size=1024, out_size=64, kernel_size=3, stride=1, padding=1):\n","        super().__init__()\n","\n","        self.conv_2 = nn.Conv1d(in_channels=input_size, out_channels=out_size,\n","                                kernel_size=2, stride=stride, padding=padding)\n","        self.conv_3 = nn.Conv1d(in_channels=input_size, out_channels=out_size,\n","                                kernel_size=3, stride=stride, padding=padding)\n","        self.conv_5 = nn.Conv1d(in_channels=input_size, out_channels=out_size,\n","                                kernel_size=5, stride=stride, padding=padding+1)\n","        self.relu = nn.ReLU()\n","\n","\n","    def forward(self, sequence_input):\n","\n","        conv_input = sequence_input.permute(0, 2, 1) # batch_size, hidden_size, sequence_length\n","        cnn_output2 = self.conv_2(conv_input)\n","        cnn_output2 = self.relu(cnn_output2)\n","        cnn_output2 = F.max_pool1d(cnn_output2, kernel_size=cnn_output2.shape[2])\n","        cnn_output3 = self.conv_3(conv_input)\n","        cnn_output3 = self.relu(cnn_output3)\n","        cnn_output3 = F.max_pool1d(cnn_output3, kernel_size=cnn_output3.shape[2])\n","        cnn_output5 = self.conv_5(conv_input)\n","        cnn_output5 = self.relu(cnn_output5)\n","        cnn_output5 = F.max_pool1d(cnn_output5, kernel_size=cnn_output5.shape[2])\n","        cnn_output = torch.cat([cnn_output2.squeeze(dim=2), cnn_output3.squeeze(dim=2), cnn_output5.squeeze(dim=2)], dim=1)\n","\n","        return cnn_output\n","\n","\n","class BIGRU_BILSTM_CNN(nn.Module):\n","    \n","    def __init__(self, out_features, hidden_size=512, hidden_size_lin=128,\n","                 p_spatial_dropout=0.5, out_chanels_cnn=64, kernel_size_cnn=3, \n","                 stride_cnn=1, padding_cnn=1, \n","                 rnn_type='LSTM', biderectional=True, pre_trained='DeepPavlov/rubert-base-cased-sentence'):\n","        super(BIGRU_BILSTM_CNN, self).__init__()\n","\n","        self.bert = AutoModel.from_pretrained(pre_trained)\n","        self.layer_norm = nn.LayerNorm(32)\n","        self.dropout = nn.Dropout(0.5)\n","        self.relu = nn.ReLU()\n","        self.p_spatial_dropout = p_spatial_dropout\n","        self.bigru_block = RNN_Block(input_size=self.bert.config.hidden_size, hidden_size=hidden_size, rnn='GRU', biderectional=True) \n","        self.bilstm_block = RNN_Block(input_size=self.bert.config.hidden_size, hidden_size=hidden_size, rnn='LSTM', biderectional=True) \n","        \n","        if biderectional == True:\n","            self.cnn_block = CNN_Block(input_size=hidden_size*2, out_size=out_chanels_cnn,\n","                                      kernel_size=kernel_size_cnn, stride=stride_cnn, padding=padding_cnn)\n","        else:\n","            self.cnn_block = CNN_Block(input_size=hidden_size, out_size=out_chanels_cnn,\n","                                      kernel_size=kernel_size_cnn, stride=stride_cnn, padding=padding_cnn)\n","            \n","\n","        self.linear_modules = nn.ModuleList([torch.nn.Linear(out_chanels_cnn*3*2, 32),\n","                                          torch.nn.Linear(32, 32),\n","                                          torch.nn.Linear(32, out_features)])\n","                                          \n","        for param in self.bert.parameters():\n","            param.requires_grad = False\n","    \n","    def forward(self, input_ids, attention_mask):\n","\n","        # _, cls_hs = self.bert(input_ids, attention_mask = attention_mask, return_dict = False)\n","\n","        encoded_layers = self.bert(input_ids=input_ids,attention_mask=attention_mask, output_hidden_states=True)\n","#         encoded_layers = encoded_layers['last_hidden_state'].permute(1, 0, 2)\n","        x = encoded_layers['last_hidden_state']#.permute(1, 0, 2)\n","#         # spatial dropout\n","\n","        embeddings = x.unsqueeze(2)    # (N, T, 1, K)\n","        embeddings = embeddings.permute(0, 3, 2, 1)  # (N, K, 1, T)\n","        embeddings = F.dropout2d(embeddings, self.p_spatial_dropout)  # (N, K, 1, T), some features are masked\n","        embeddings = embeddings.permute(0, 3, 2, 1)  # (N, T, 1, K)\n","        x = embeddings.squeeze(2)  # (N, T, K)\n","\n","        bigru,_ = self.bigru_block(x) #(N,L,H in) - batch size, sequence length, input size        \n","        bilstm, hidden_bilstm = self.bilstm_block(x)\n","\n","        bilstm_cnn = self.cnn_block(bilstm)\n","        bigru_cnn = self.cnn_block(bigru)\n","        x = torch.cat([bigru_cnn, bilstm_cnn], dim=1)\n","\n","        h = []\n","        \n","        for lin in self.linear_modules[:-1]:\n","            x = lin(x)\n","            h.append(x)\n","            x = self.relu(x)\n","            x = self.dropout(x)\n","        \n","        x = self.relu(h[-1] + h[-2])\n","        x = self.linear_modules[-1](x)\n","        return x"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-05-27T10:58:46.115412Z","iopub.status.busy":"2023-05-27T10:58:46.114739Z","iopub.status.idle":"2023-05-27T10:59:02.177605Z","shell.execute_reply":"2023-05-27T10:59:02.176638Z","shell.execute_reply.started":"2023-05-27T10:58:46.115378Z"},"executionInfo":{"elapsed":3708,"status":"ok","timestamp":1684430469700,"user":{"displayName":"Help Study","userId":"07310851891543285849"},"user_tz":-180},"id":"XK9NDVFTCxsh","outputId":"87464697-1cc0-4007-ac53-ec4deba775ec","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3240bdd45ca04c80a75b3d8fb02b5769","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/714M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["model = BIGRU_BILSTM_CNN(pre_trained=model_name,  out_features=len(curc_labels))"]},{"cell_type":"markdown","metadata":{"id":"VOpNOwg7dyTr"},"source":[]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T10:59:02.180056Z","iopub.status.busy":"2023-05-27T10:59:02.179667Z","iopub.status.idle":"2023-05-27T10:59:11.436409Z","shell.execute_reply":"2023-05-27T10:59:11.435464Z","shell.execute_reply.started":"2023-05-27T10:59:02.180020Z"},"id":"ET2lV0UTDfv-","trusted":true},"outputs":[],"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","epochs = 15\n","model = model.to(device)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T10:59:11.438202Z","iopub.status.busy":"2023-05-27T10:59:11.437818Z","iopub.status.idle":"2023-05-27T10:59:11.450400Z","shell.execute_reply":"2023-05-27T10:59:11.448155Z","shell.execute_reply.started":"2023-05-27T10:59:11.438163Z"},"id":"6sghonayDrOV","trusted":true},"outputs":[],"source":["from sklearn.metrics import r2_score\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score"]},{"cell_type":"markdown","metadata":{"id":"_ECS33f5dz62"},"source":["Надо сделать прогон на каждом классе отдельно, чтобы определеить, какие будут веса можно будет использовать для общего лосса"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T10:59:11.453683Z","iopub.status.busy":"2023-05-27T10:59:11.453102Z","iopub.status.idle":"2023-05-27T10:59:14.106895Z","shell.execute_reply":"2023-05-27T10:59:14.105848Z","shell.execute_reply.started":"2023-05-27T10:59:11.453649Z"},"id":"6ZiXmqgAD2oZ","trusted":true},"outputs":[],"source":["def analysing_logits(logits, class_indexes):\n","  \n","  def compute_maxes(logits, CUR_SCORE_INDEX):\n","    labels_zeros = np.zeros(logits[:, CUR_SCORE_INDEX].shape)\n","    pred_class = np.argmax(logits[:, CUR_SCORE_INDEX], axis=1)\n","    labels_zeros[list(range(len(labels_zeros))), pred_class] = 1\n","    return labels_zeros\n","\n","  list_of_best_labels = []\n","\n","  for circ_cl in class_indexes:\n","    labels_zeros = compute_maxes(logits, circ_cl)\n","    list_of_best_labels.append(labels_zeros)\n","  \n","  return np.concatenate((list_of_best_labels), axis=1)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T10:59:14.109011Z","iopub.status.busy":"2023-05-27T10:59:14.108557Z","iopub.status.idle":"2023-05-27T10:59:14.119185Z","shell.execute_reply":"2023-05-27T10:59:14.118263Z","shell.execute_reply.started":"2023-05-27T10:59:14.108977Z"},"id":"QXlkIB61DHgv","trusted":true},"outputs":[],"source":["def init_adding_weights():\n","    return (1/1.09, 1/1.09, 1/1.09, 1/1.09,\n","            1/1.09, 1/1.09, 1/1.09, 1/1.09)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T10:59:14.131131Z","iopub.status.busy":"2023-05-27T10:59:14.130785Z","iopub.status.idle":"2023-05-27T10:59:14.140380Z","shell.execute_reply":"2023-05-27T10:59:14.139500Z","shell.execute_reply.started":"2023-05-27T10:59:14.131107Z"},"id":"HI-NmbceArgZ","trusted":true},"outputs":[],"source":["def comupte_custom_loss(labels, logits, criterion, class_indexes):\n","    \n","\n","    custom_weights = init_adding_weights()\n","\n","    custom_loss = 0\n","    for ind, circ_cl in enumerate(class_indexes):\n","\n","      custom_loss += custom_weights[ind] * criterion(logits[:, circ_cl],\n","                                  labels[:, circ_cl])\n","      # print(custom_loss)\n","\n","    return custom_loss"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T10:59:14.143700Z","iopub.status.busy":"2023-05-27T10:59:14.142620Z","iopub.status.idle":"2023-05-27T10:59:14.153088Z","shell.execute_reply":"2023-05-27T10:59:14.152032Z","shell.execute_reply.started":"2023-05-27T10:59:14.143666Z"},"id":"RGDf6eCgHADO","trusted":true},"outputs":[],"source":["def show_metrics(labels, predicted, class_indexes):\n","\n","    labels_names = ['AP', 'AM', 'BP', 'BM',\n","              'GP', 'GM', 'DP', 'DM']\n","    \n","    labels = np.vstack(labels)\n","    predicted = np.vstack(predicted)\n","\n","    for lab, circ_cl in zip(labels_names, class_indexes):\n","      \n","      f1_sc = f1_score(labels[:, circ_cl],\n","               predicted[:, circ_cl], average=\"macro\")\n","      accur = accuracy_score(labels[:, circ_cl],\n","               predicted[:, circ_cl])\n","      \n","      \n","      print(f'Scores for {lab}\\n==================\\n')\n","      print('Macro F1 score for {0} - {1}\\n'.format(lab, f1_sc))\n","      print('Accuracy score for {0} - {1}\\n'.format(lab, accur))\n","      print(classification_report(labels[:, circ_cl], predicted[:, circ_cl], zero_division=0))\n"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T10:59:14.155278Z","iopub.status.busy":"2023-05-27T10:59:14.154848Z","iopub.status.idle":"2023-05-27T10:59:14.171184Z","shell.execute_reply":"2023-05-27T10:59:14.170065Z","shell.execute_reply.started":"2023-05-27T10:59:14.155244Z"},"id":"_KB-BQrqDuTD","trusted":true},"outputs":[],"source":["def train(model, data_loader, device, optimizer, criterion, n_epoch, class_indexes):\n","\n","    print('Epoch #{}\\n'.format(n_epoch+1))\n","\n","    train_losses = []\n","    train_labels = []\n","    train_predictions = []   \n","\n","    progress_bar = tqdm(total=int(len(data_loader.dataset)/data_loader.batch_size), \n","                        desc='Epoch {}'.format(n_epoch + 1))\n","\n","    model.train()\n","\n","    for _, data in enumerate(data_loader, 0):\n","\n","\n","          input_ids = data[\"source_ids\"].to(device)\n","          attention_mask = data[\"source_mask\"].to(device)\n","          labels = data['labels'].to(device)\n","\n","          optimizer.zero_grad()\n","\n","          pred = model(input_ids=input_ids, attention_mask=attention_mask)\n","\n","          loss = comupte_custom_loss(labels, pred, criterion, class_indexes)\n","\n","              \n","          loss.backward()\n","              \n","          optimizer.step()\n","          lr_list.append(optimizer.state_dict()['param_groups'][0]['lr'])\n","          scheduler.step()\n","        \n","          predict = torch.log_softmax(pred, dim=1)\n","\n","          resulting_output = analysing_logits(predict.detach().cpu().numpy(), class_indexes)\n","\n","\n","          train_losses.append(loss.item())\n","          train_labels.extend(labels.cpu().detach().numpy())\n","          train_predictions.extend(resulting_output)\n","\n","          progress_bar.set_postfix(loss=np.mean(train_losses))\n","          progress_bar.update(1)\n","\n","    progress_bar.close()\n","  \n","    \n","    print('\\n\\nMean Loss after epoch #{0} - {1}'.format(str(n_epoch + 1), np.mean(train_losses)))\n","    print(f'\\n Scores after {n_epoch + 1} on train:')\n","    show_metrics(train_labels, train_predictions, class_indexes)"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T10:59:14.175532Z","iopub.status.busy":"2023-05-27T10:59:14.175220Z","iopub.status.idle":"2023-05-27T10:59:14.188471Z","shell.execute_reply":"2023-05-27T10:59:14.187572Z","shell.execute_reply.started":"2023-05-27T10:59:14.175508Z"},"id":"KgZhVGLLaIvK","trusted":true},"outputs":[],"source":["def validating(model, data_loader, device, optimizer, criterion, n_epoch, class_indexes):\n","\n","    val_losses, val_labels, val_predictions = [], [], []\n","\n","    progress_bar = tqdm(total=int(len(data_loader.dataset)/data_loader.batch_size),\n","                        desc='Epoch {}'.format(n_epoch + 1))\n","\n","    model.eval()\n","\n","    for _, data in enumerate(data_loader, 0):\n","          \n","          input_ids = data[\"source_ids\"].to(device)\n","          attention_mask = data[\"source_mask\"].to(device)\n","          labels = data['labels'].to(device)\n","\n","          with torch.no_grad():\n","              pred = model(input_ids, attention_mask)\n","        \n","          predict = torch.log_softmax(pred, dim=1)\n","\n","          loss = comupte_custom_loss(labels, pred, criterion, class_indexes)\n","          \n","          resulting_output = analysing_logits(predict.detach().cpu().numpy(), class_indexes)\n","\n","          val_losses.append(loss.item())\n","          val_labels.extend(labels.cpu().detach().numpy())\n","          val_predictions.extend(resulting_output)\n","\n","          progress_bar.set_postfix(loss=np.mean(val_losses))\n","          progress_bar.update(1)\n","\n","    progress_bar.close()\n","    \n","    \n","    valid_stats.append(\n","        {\n","            'Val Loss': np.mean(val_losses)\n","        }\n","    )\n","\n","    print('\\n\\nMean Loss after epoch #{0} - {1}'.format(str(n_epoch + 1), np.mean(val_losses)))\n","    print(f'\\n Scores after {n_epoch + 1} on validation:')\n","    show_metrics(val_labels, val_predictions, class_indexes)\n","    return valid_stats"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T10:59:38.816518Z","iopub.status.busy":"2023-05-27T10:59:38.815835Z","iopub.status.idle":"2023-05-27T10:59:38.827089Z","shell.execute_reply":"2023-05-27T10:59:38.825954Z","shell.execute_reply.started":"2023-05-27T10:59:38.816484Z"},"id":"eMPNDNXyiJES","trusted":true},"outputs":[],"source":["import os\n","from transformers import get_linear_schedule_with_warmup, AdamW"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2690c9c8e09d4fe1906204108950acd0","667a61e654114c4f919e94786b1ca9c8","13973076a6e14bbeae99bdc319914622","47fdc6325b1c4950857c392c85989aa5","214dd526c7a44b5faa4e480c83e59bb1","ef3ff9c122ce4407863d74957b80fb32","971e6e6500e14f6193401a583d573ca7","13ba8b614aa2404bab8b92fb2ccad0ef","7fdeb4a53e8d42178a135770df7f4cdb","c8eba7d65c9141549ee3300637d2964e","4b08819b15494d9daa3915b57c0dbadd","a92773c310334cad8f4d100ab3887dce","8d7c87ec62024dd9bf2a5cdc66a4f3dd","59bd7e4fdf514ef08981f668fe1f6de1","0a74807e64274b0abe938bb35ae84822","f6b0842c95aa4f3db78750449300e7c7","2cfb1da74e17469ba16666334ffd80c2","4bd46a3629664f8aab8c3da3f3e14914","7b7d285d5da94e4d9e2803f818ebf662","621784821d53419193dd8259dc3ee973","cfbf03e60b824b07b3bd488405685505","8dfdf32e65a247bba25614e466808965","1c47006dfa214c5cbdf4ec74445c7ec7","d446447e40284fc99f9261a41f53dd35","0b0cbd6f2bb24186855c99c514153d99","aad76e6aa36b4619a6708b380a59062f","54655892111943429a026e4930c4380d","747602191bca49a29cdf2f4e875ab0e1","09c86c546d3743569cd2f23b598b1edd","b9c2fdfb3bb64285a1b66b2859ee37c1","d192f2554a5544138aadf19d4553fb4c","2e9abf059107470481d78bc4fb61e40f","1c8c819d3e5b4e399589b7ed216f43c7","2525e07d18c4400eb8f9e4fb6924e6b7","0237dc3eddd245b9bb5b51b162331e71","81262bbfdf104bb59eea33752832645e","76029cd5b5c44f0f8ee27040cd4c794a","630405bfd22943509ea0d26bc0e60db6","fbefb8047f4b417cb75abc46f79646ad","15dcc6ab1dc8445eb1d600136e0e5f65","cce82d99d5d44d3b9c2d09b6a8deeb77","a7bc8d475ba7471dbd4bb07022ad616a","7b4804c2c28a47fea27a58b38781f60d","135667e9429a45efa66b7a72e7c5c5d7","bda28a07fb874814ba0ef77adce987cb","9bfc54d8ba2141ea8c4e5d3e54ca0aba","2634a606fe094c438b75e897947bfc54","074c3946d2fd4047ac86fc6f44a5e442","f55d8635dada451ba7a51c7233669938","31d59aa4ed6d447288ef1cf7d0571055","d51b9cb8413d4c6c96fa23409f2c8b83","49d2528114ff4d9eb0e6fde129af2361","1a9f67202c814019972d721a809b63db","a7804c9a3fc044ed9c62195541cd2fb6","21e8f0a04cda45868c8e06b63e5325d7","435bf8c859504587918e4ab10f2a4d7a","0ace271cd43049b6b42079d2a1180356","7972e2ac1a9044a3962a3eba7cc1355a","9b4eb706863544229e9491daa10ce1a3","f1e8316b3f7f4af3a0aca012bf3f92ae","c03c6ad3764c4c8597c32bb1ffab4248","a149d8f66aaa4a99a61ccf75e6ce5750","0ed740e831aa43c9b82f17ef26a62eff","f9969524006349c88862de26318b4f94","e4ea4e4e6bb2427d9a2a864de5a23f3c","ebbc06aaec294aba8222536ab39e2647","558384c7699a44238e65e24f13b4fda1","45497ea71f79446c8b4e0341d4f7216b","fa5d5d5784754556bc936841cb472a23","afe6e88195b3483eb67939b3893bafe5","a99d8b51d1af44c09a5f2eb01d52bfa0","33afe891341145a2b6dd3378c2d961ae","7b0feaff93c74588b743e8d2ff597142","b0f88c2132f94e909309a823861368ab","9be4872088484fa4aa9e66e50f4934eb","4f4826946a024e8bbb1b89ce76b1ef0f","5d17388a3d1f454d8a8cdc828a189c67","1f6701140e414b5582f7e5b0f7656ee3","4ed122b0d09c47d2bcb2134bfb6325cd","101f2b6d214a4b2488670f716c866e8e","cb6f34d2ddb94d8cb82a198561cd1a43","8acaea8081a54d368b6f333fd05b8f6a","788246ecfccb455d849e589cfa72265f","c3a533f706d447e282fbdcbe102ef047","2f8d0e4b8152468287abfe4d4ce3484c","cacbf373b25f4bb09c96361d3aa98b66","697a625a986542c3bd7750e570644689","8cfcc130abe24f688655dcccca3c1119","cce136d540ce4bcbadb9af4767f54831","a4a1c6f345384e5199d58908b416ac83","0a69129f00564573a571e8ae645c4d1b","d62896e730604f07ad4cdc2a7fcad328","01314b46d0c14605b4493faf9049a28a","cec89209ccab4940bd996ad1da6bfd81","fcc302b8fb224862bf9651b6319963f8","26d66b91f7964eb1a8d08b6dc35c2744","49fad36a492143c98111439a24a406ca","24eae4dbaeeb4787939c27385dc8e2ab","08a70ddab74e44509ff38faeaa2accf5","5571b8593f364f49932a59de33b1714c","f60ec39020ff476f89fd37503deaa04d","f861325e1ee54420a547f02df1247d32","5a562566b50e4200af4465fe6aaa2ddc","7e09b6ab3a8b41eb9b64ee340f36eaf0","d4f1843490c54114933f07aa07796c4d","8f2fea6de81c486d8e40fc9180e65312","ab3d31b6cca84bfb87e5b34dbd685b2b","a4dd62547f43442e8588292cfaaf7a98","2f69fb97844344fb88e1f9c77f8b52c9","b481e18ba2d64333a5c9d0ce0c56ac9b","ee91356df2aa4357a8abc23cc3e8333d","d710341aa7374defad95420a943331cb","d88befdc052542ae8ab00175439c5f5f","49635cbec7cf4f0bb993cc6aef3a3931","f3a401a3a15349debcd69332e04dad92","e84b61fa16704e52be9b6d44da9fda4e","01e11ca1e93844fd98a9e4b412c51ffe","d32fa23084d54c09a97226fb1eb69c02","e8986cf621164f83ad1ca3283ceef894","a6c74b8db12e485cbf07978b711ac644","89abb9ad964a4bf9a0b6b9b94896f255","14757c04f5634bae956e4b3bf2840149","d22b41a7795d41b6a2d30a502b3b31e9","31754f22a11e45638046f6fcb8f3ecfd","4f1ddb8adb1348ff8b1201710d2b3e96","04b29c6cd93f4e89898fb561654f2b16","f43f36cff99d4c198420209708545ffd","dc28a233b1b144f19a1c3653c5dfc720","5d53f78b6cbd4cb1b18cab6a0eccfde5","3605c2e2e14645178dfd6a76cc4a6c2f","ed378a5d49e44d57bab4f20bc2df6ad8","7de7487aca8045bc875545e6e7bb9d15","a129f7458f5b4ac798e88731bee9c9f6","2789881bf43a4ae7b193c04243f2d9dc","84f8b81e08a64c6f9d480d702cf3d147","205aece5e14a41168c43a8660fc03291","5837efdcbf584d84b6201b00129d3991","0fe68a59548c4201924d43973a80a99c","7da25d6d6a5a4907b516687eddf0a2f4","b173826cc3524845b9f0a032fd4862a4","92fd763c82c446ff8bdda05ec0c777ae","c2e50311e632417a9f6405da24e57dbe","d0e3277ada894340b222941bc0d8b5bc","5eef3462adc5486cbe0f402b746abb19","d77ff34da3204e45b4876f009a025d95","4ce8cb1091d8468885e2d9163db9712e","c01ef5a8ab0b4e3586e1882d2768783a","df6cb3c3b34e4ca5910fe2993f465616","74c8109dfb5f48f2b960dbda084e8453","c9d2cb2454a14e3a85979f042ac333cb","d797b54a29364543bee3af18ccc5a7d6","772998a2cdf748e38d766c9b451e5afa","791e3a42867144869bb48e741245fedf","0f02fb31f1cb4c06b0a619d5e908238b","bb6731c6cdb64050ab4071aaad89da0d","240107dd617c482180ae3eb8b119d8a2","8f631be8707845afa8dfc9f102be3478","6c876da67fd64bc08cf93ad32967a10e","198081598cef4ee3a6fd87d4abf9ed5c","5e77f0103ec849bc98824487c39765e6","b3fb1acae760427f80277168b263a1e4","c574667dad254c8e8d92468673c89eea","ab44e921a79447e18edae0c9faf50673","c3b4c437718743fb8f77a2910fe5b110","9cbc7d6853804e9b94dabe7c8a7e2e5f","f02279245d744fcea4ba1360dc9c035b","4621bbcb3a844f61b2e6581b3c26bc9d","6b754494044c40eaa1628e0a72764fb8","6eddb37bc7ee4dfdafdb1dea1f34fd26","374b55d9ffff415b8b42b4ba6f71e638","09d85b49c7b34ba09db62a13bf7f12e2","d08aea6a09c745af830236ca3a0ec649","eea03aa3c5274be4b5efd77f8ebcd666","863ecf4086bc41289b0e9578217cd2ff","c222cad4fecf407191ce00ba1c819380","199f99e4a079408390595a2ec8d09607","71ec38b6d6ac4a13a99dda421c180ef6"]},"execution":{"iopub.execute_input":"2023-05-27T10:59:38.871776Z","iopub.status.busy":"2023-05-27T10:59:38.871499Z","iopub.status.idle":"2023-05-27T11:28:21.970751Z","shell.execute_reply":"2023-05-27T11:28:21.969674Z","shell.execute_reply.started":"2023-05-27T10:59:38.871751Z"},"executionInfo":{"elapsed":615354,"status":"ok","timestamp":1684431725450,"user":{"displayName":"Help Study","userId":"07310851891543285849"},"user_tz":-180},"id":"8XBmoBOGhxhD","outputId":"a8f152ef-1e36-4bd0-a752-53d1d38271aa","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch #1\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"60afd4c01c2d4f2caf7278321ca9e8c9","version_major":2,"version_minor":0},"text/plain":["Epoch 1:   0%|          | 0/647 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #1 - 7.705569319019107\n","\n"," Scores after 1 on train:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.2882590930018416\n","\n","Accuracy score for AP - 0.4385625965996909\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00      1056\n","           1       0.41      0.22      0.28      1896\n","           2       0.45      0.84      0.58      2224\n","\n","   micro avg       0.44      0.44      0.44      5176\n","   macro avg       0.29      0.35      0.29      5176\n","weighted avg       0.34      0.44      0.35      5176\n"," samples avg       0.44      0.44      0.44      5176\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.30379256202890426\n","\n","Accuracy score for AM - 0.5753477588871716\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.62      0.88      0.73      3185\n","           1       0.27      0.13      0.18      1267\n","           2       0.18      0.00      0.01       724\n","\n","   micro avg       0.58      0.58      0.58      5176\n","   macro avg       0.36      0.34      0.30      5176\n","weighted avg       0.47      0.58      0.49      5176\n"," samples avg       0.58      0.58      0.58      5176\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.24936526609686072\n","\n","Accuracy score for BP - 0.4037867078825348\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.32      0.12      0.18      1706\n","           1       0.42      0.86      0.56      2173\n","           2       0.23      0.00      0.01      1297\n","\n","   micro avg       0.40      0.40      0.40      5176\n","   macro avg       0.32      0.33      0.25      5176\n","weighted avg       0.34      0.40      0.30      5176\n"," samples avg       0.40      0.40      0.40      5176\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.24676373517018946\n","\n","Accuracy score for BM - 0.40146831530139104\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.42      0.86      0.56      2178\n","           1       0.29      0.12      0.17      1625\n","           2       0.20      0.00      0.01      1373\n","\n","   micro avg       0.40      0.40      0.40      5176\n","   macro avg       0.30      0.33      0.25      5176\n","weighted avg       0.32      0.40      0.29      5176\n"," samples avg       0.40      0.40      0.40      5176\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.31470098744205355\n","\n","Accuracy score for GP - 0.36901081916537865\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.30      0.21      0.25      1521\n","           1       0.40      0.65      0.50      2081\n","           2       0.33      0.15      0.20      1574\n","\n","   micro avg       0.37      0.37      0.37      5176\n","   macro avg       0.34      0.34      0.31      5176\n","weighted avg       0.35      0.37      0.33      5176\n"," samples avg       0.37      0.37      0.37      5176\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.2742167400954279\n","\n","Accuracy score for GM - 0.4138330757341577\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.49      0.74      0.59      2544\n","           1       0.23      0.01      0.02      1590\n","           2       0.20      0.24      0.22      1042\n","\n","   micro avg       0.41      0.41      0.41      5176\n","   macro avg       0.31      0.33      0.27      5176\n","weighted avg       0.35      0.41      0.34      5176\n"," samples avg       0.41      0.41      0.41      5176\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.31613512089702567\n","\n","Accuracy score for DP - 0.4609737248840804\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       786\n","           1       0.39      0.35      0.37      1909\n","           2       0.49      0.69      0.58      2481\n","\n","   micro avg       0.46      0.46      0.46      5176\n","   macro avg       0.30      0.35      0.32      5176\n","weighted avg       0.38      0.46      0.41      5176\n"," samples avg       0.46      0.46      0.46      5176\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.2831292835166633\n","\n","Accuracy score for DM - 0.509273570324575\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.54      0.90      0.67      2781\n","           1       0.14      0.02      0.04      1158\n","           2       0.31      0.09      0.13      1237\n","\n","   micro avg       0.51      0.51      0.51      5176\n","   macro avg       0.33      0.34      0.28      5176\n","weighted avg       0.40      0.51      0.40      5176\n"," samples avg       0.51      0.51      0.51      5176\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af1498ff896145e2b088c214516a99bd","version_major":2,"version_minor":0},"text/plain":["Epoch 1:   0%|          | 0/89 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #1 - 7.443074237376785\n","\n"," Scores after 1 on validation:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.3329967544175983\n","\n","Accuracy score for AP - 0.4586255259467041\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       131\n","           1       0.38      0.51      0.44       253\n","           2       0.53      0.60      0.56       329\n","\n","   micro avg       0.46      0.46      0.46       713\n","   macro avg       0.30      0.37      0.33       713\n","weighted avg       0.38      0.46      0.41       713\n"," samples avg       0.46      0.46      0.46       713\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.2628150665533843\n","\n","Accuracy score for AM - 0.6507713884992987\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.65      1.00      0.79       464\n","           1       0.00      0.00      0.00       166\n","           2       0.00      0.00      0.00        83\n","\n","   micro avg       0.65      0.65      0.65       713\n","   macro avg       0.22      0.33      0.26       713\n","weighted avg       0.42      0.65      0.51       713\n"," samples avg       0.65      0.65      0.65       713\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.19228210246174318\n","\n","Accuracy score for BP - 0.4053295932678822\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       248\n","           1       0.41      1.00      0.58       289\n","           2       0.00      0.00      0.00       176\n","\n","   micro avg       0.41      0.41      0.41       713\n","   macro avg       0.14      0.33      0.19       713\n","weighted avg       0.16      0.41      0.23       713\n"," samples avg       0.41      0.41      0.41       713\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.2873938495274682\n","\n","Accuracy score for BM - 0.394109396914446\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.43      0.69      0.52       299\n","           1       0.32      0.30      0.31       243\n","           2       0.67      0.01      0.02       171\n","\n","   micro avg       0.39      0.39      0.39       713\n","   macro avg       0.47      0.33      0.29       713\n","weighted avg       0.45      0.39      0.33       713\n"," samples avg       0.39      0.39      0.39       713\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.29996974759059297\n","\n","Accuracy score for GP - 0.4277699859747546\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.18      0.26       217\n","           1       0.42      0.90      0.57       287\n","           2       0.50      0.03      0.06       209\n","\n","   micro avg       0.43      0.43      0.43       713\n","   macro avg       0.46      0.37      0.30       713\n","weighted avg       0.46      0.43      0.33       713\n"," samples avg       0.43      0.43      0.43       713\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.22838975551791266\n","\n","Accuracy score for GM - 0.5049088359046283\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.51      1.00      0.67       359\n","           1       0.00      0.00      0.00       209\n","           2       0.33      0.01      0.01       145\n","\n","   micro avg       0.50      0.50      0.50       713\n","   macro avg       0.28      0.34      0.23       713\n","weighted avg       0.32      0.50      0.34       713\n"," samples avg       0.50      0.50      0.50       713\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.3482170105273956\n","\n","Accuracy score for DP - 0.517531556802244\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       114\n","           1       0.42      0.36      0.39       245\n","           2       0.56      0.79      0.65       354\n","\n","   micro avg       0.52      0.52      0.52       713\n","   macro avg       0.33      0.38      0.35       713\n","weighted avg       0.42      0.52      0.46       713\n"," samples avg       0.52      0.52      0.52       713\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.3012585532746823\n","\n","Accuracy score for DM - 0.5553997194950911\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.58      0.93      0.71       405\n","           1       0.00      0.00      0.00       153\n","           2       0.34      0.14      0.19       155\n","\n","   micro avg       0.56      0.56      0.56       713\n","   macro avg       0.30      0.35      0.30       713\n","weighted avg       0.40      0.56      0.45       713\n"," samples avg       0.56      0.56      0.56       713\n","\n","Best validation loss - 7.443074237376785\n","Epoch #2\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"519f334fcf694824aa03db25fa540468","version_major":2,"version_minor":0},"text/plain":["Epoch 2:   0%|          | 0/647 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #2 - 7.505593953830257\n","\n"," Scores after 2 on train:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.3292298725025376\n","\n","Accuracy score for AP - 0.4574961360123648\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.33      0.00      0.00      1056\n","           1       0.42      0.40      0.41      1896\n","           2       0.48      0.72      0.58      2224\n","\n","   micro avg       0.46      0.46      0.46      5176\n","   macro avg       0.41      0.37      0.33      5176\n","weighted avg       0.43      0.46      0.40      5176\n"," samples avg       0.46      0.46      0.46      5176\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.2589660180174587\n","\n","Accuracy score for AM - 0.6145672333848532\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.62      1.00      0.76      3185\n","           1       0.30      0.00      0.00      1268\n","           2       0.31      0.01      0.01       723\n","\n","   micro avg       0.61      0.61      0.61      5176\n","   macro avg       0.41      0.33      0.26      5176\n","weighted avg       0.50      0.61      0.47      5176\n"," samples avg       0.61      0.61      0.61      5176\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.3055782721988942\n","\n","Accuracy score for BP - 0.42020865533230295\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.40      0.24      0.30      1706\n","           1       0.43      0.79      0.56      2172\n","           2       0.30      0.03      0.06      1298\n","\n","   micro avg       0.42      0.42      0.42      5176\n","   macro avg       0.38      0.36      0.31      5176\n","weighted avg       0.39      0.42      0.35      5176\n"," samples avg       0.42      0.42      0.42      5176\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.3243896676251647\n","\n","Accuracy score for BM - 0.41653786707882534\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.44      0.77      0.56      2178\n","           1       0.33      0.21      0.26      1624\n","           2       0.37      0.09      0.15      1374\n","\n","   micro avg       0.42      0.42      0.42      5176\n","   macro avg       0.38      0.36      0.32      5176\n","weighted avg       0.39      0.42      0.36      5176\n"," samples avg       0.42      0.42      0.42      5176\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.32035327214086845\n","\n","Accuracy score for GP - 0.3956723338485317\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.35      0.23      0.28      1521\n","           1       0.41      0.74      0.53      2082\n","           2       0.34      0.10      0.15      1573\n","\n","   micro avg       0.40      0.40      0.40      5176\n","   macro avg       0.37      0.36      0.32      5176\n","weighted avg       0.37      0.40      0.34      5176\n"," samples avg       0.40      0.40      0.40      5176\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.2770143947133484\n","\n","Accuracy score for GM - 0.48183925811437406\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.91      0.65      2543\n","           1       0.32      0.11      0.17      1591\n","           2       0.25      0.01      0.02      1042\n","\n","   micro avg       0.48      0.48      0.48      5176\n","   macro avg       0.36      0.34      0.28      5176\n","weighted avg       0.40      0.48      0.37      5176\n"," samples avg       0.48      0.48      0.48      5176\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.3467658669720523\n","\n","Accuracy score for DP - 0.491112828438949\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       786\n","           1       0.42      0.47      0.44      1910\n","           2       0.55      0.66      0.60      2480\n","\n","   micro avg       0.49      0.49      0.49      5176\n","   macro avg       0.32      0.38      0.35      5176\n","weighted avg       0.41      0.49      0.45      5176\n"," samples avg       0.49      0.49      0.49      5176\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.2979334252923515\n","\n","Accuracy score for DM - 0.5376738794435858\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.55      0.95      0.70      2782\n","           1       0.33      0.02      0.04      1156\n","           2       0.38      0.10      0.16      1238\n","\n","   micro avg       0.54      0.54      0.54      5176\n","   macro avg       0.42      0.36      0.30      5176\n","weighted avg       0.46      0.54      0.42      5176\n"," samples avg       0.54      0.54      0.54      5176\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ccae34d1cc034d6295a9cf7f840cf504","version_major":2,"version_minor":0},"text/plain":["Epoch 2:   0%|          | 0/89 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #2 - 7.413966710623219\n","\n"," Scores after 2 on validation:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.3156036084285929\n","\n","Accuracy score for AP - 0.48667601683029454\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       131\n","           1       0.42      0.25      0.31       253\n","           2       0.50      0.87      0.64       329\n","\n","   micro avg       0.49      0.49      0.49       713\n","   macro avg       0.31      0.37      0.32       713\n","weighted avg       0.38      0.49      0.40       713\n"," samples avg       0.49      0.49      0.49       713\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.2628150665533843\n","\n","Accuracy score for AM - 0.6507713884992987\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.65      1.00      0.79       464\n","           1       0.00      0.00      0.00       166\n","           2       0.00      0.00      0.00        83\n","\n","   micro avg       0.65      0.65      0.65       713\n","   macro avg       0.22      0.33      0.26       713\n","weighted avg       0.42      0.65      0.51       713\n"," samples avg       0.65      0.65      0.65       713\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.23865582980564737\n","\n","Accuracy score for BP - 0.41374474053295934\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.08      0.14       248\n","           1       0.41      0.95      0.57       289\n","           2       0.00      0.00      0.00       176\n","\n","   micro avg       0.41      0.41      0.41       713\n","   macro avg       0.29      0.34      0.24       713\n","weighted avg       0.33      0.41      0.28       713\n"," samples avg       0.41      0.41      0.41       713\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.30082846906561295\n","\n","Accuracy score for BM - 0.42496493688639553\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.87      0.59       299\n","           1       0.39      0.11      0.17       243\n","           2       0.27      0.10      0.15       171\n","\n","   micro avg       0.42      0.42      0.42       713\n","   macro avg       0.37      0.36      0.30       713\n","weighted avg       0.39      0.42      0.34       713\n"," samples avg       0.42      0.42      0.42       713\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.2544679334461332\n","\n","Accuracy score for GP - 0.40392706872370265\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.39      0.11      0.17       217\n","           1       0.41      0.91      0.56       287\n","           2       0.23      0.01      0.03       209\n","\n","   micro avg       0.40      0.40      0.40       713\n","   macro avg       0.34      0.34      0.25       713\n","weighted avg       0.35      0.40      0.29       713\n"," samples avg       0.40      0.40      0.40       713\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.2232587064676617\n","\n","Accuracy score for GM - 0.5035063113604488\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      1.00      0.67       359\n","           1       0.00      0.00      0.00       209\n","           2       0.00      0.00      0.00       145\n","\n","   micro avg       0.50      0.50      0.50       713\n","   macro avg       0.17      0.33      0.22       713\n","weighted avg       0.25      0.50      0.34       713\n"," samples avg       0.50      0.50      0.50       713\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.37371067226455196\n","\n","Accuracy score for DP - 0.5287517531556802\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       114\n","           1       0.43      0.53      0.48       245\n","           2       0.60      0.70      0.64       354\n","\n","   micro avg       0.53      0.53      0.53       713\n","   macro avg       0.34      0.41      0.37       713\n","weighted avg       0.45      0.53      0.48       713\n"," samples avg       0.53      0.53      0.53       713\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.26424885058685205\n","\n","Accuracy score for DM - 0.5666199158485273\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.57      0.98      0.72       405\n","           1       0.00      0.00      0.00       153\n","           2       0.35      0.04      0.07       155\n","\n","   micro avg       0.57      0.57      0.57       713\n","   macro avg       0.31      0.34      0.26       713\n","weighted avg       0.40      0.57      0.43       713\n"," samples avg       0.57      0.57      0.57       713\n","\n","Best validation loss - 7.413966710623219\n","Epoch #3\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fec4548f33a14371805fdfa773234c14","version_major":2,"version_minor":0},"text/plain":["Epoch 3:   0%|          | 0/647 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #3 - 7.459421918182964\n","\n"," Scores after 3 on train:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.34092112983691725\n","\n","Accuracy score for AP - 0.4712132921174652\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.17      0.00      0.00      1057\n","           1       0.44      0.43      0.43      1894\n","           2       0.49      0.73      0.59      2225\n","\n","   micro avg       0.47      0.47      0.47      5176\n","   macro avg       0.36      0.39      0.34      5176\n","weighted avg       0.41      0.47      0.41      5176\n"," samples avg       0.47      0.47      0.47      5176\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.25581694255670956\n","\n","Accuracy score for AM - 0.615146831530139\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.62      1.00      0.76      3184\n","           1       0.50      0.00      0.00      1268\n","           2       0.50      0.00      0.00       724\n","\n","   micro avg       0.62      0.62      0.62      5176\n","   macro avg       0.54      0.33      0.26      5176\n","weighted avg       0.57      0.62      0.47      5176\n"," samples avg       0.62      0.62      0.62      5176\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.3139490181097778\n","\n","Accuracy score for BP - 0.4269706336939722\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.41      0.26      0.32      1706\n","           1       0.43      0.79      0.56      2172\n","           2       0.38      0.03      0.06      1298\n","\n","   micro avg       0.43      0.43      0.43      5176\n","   macro avg       0.41      0.36      0.31      5176\n","weighted avg       0.41      0.43      0.36      5176\n"," samples avg       0.43      0.43      0.43      5176\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.3311484119602894\n","\n","Accuracy score for BM - 0.42716383307573413\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.44      0.81      0.57      2178\n","           1       0.38      0.16      0.22      1626\n","           2       0.37      0.14      0.20      1372\n","\n","   micro avg       0.43      0.43      0.43      5176\n","   macro avg       0.40      0.37      0.33      5176\n","weighted avg       0.40      0.43      0.36      5176\n"," samples avg       0.43      0.43      0.43      5176\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.32342827423743326\n","\n","Accuracy score for GP - 0.40224111282843894\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.35      0.22      0.27      1520\n","           1       0.41      0.76      0.54      2081\n","           2       0.41      0.10      0.16      1575\n","\n","   micro avg       0.40      0.40      0.40      5176\n","   macro avg       0.39      0.36      0.32      5176\n","weighted avg       0.40      0.40      0.34      5176\n"," samples avg       0.40      0.40      0.40      5176\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.2750322296150258\n","\n","Accuracy score for GM - 0.491306027820711\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.51      0.94      0.66      2545\n","           1       0.35      0.09      0.14      1590\n","           2       0.30      0.01      0.03      1041\n","\n","   micro avg       0.49      0.49      0.49      5176\n","   macro avg       0.38      0.35      0.28      5176\n","weighted avg       0.42      0.49      0.37      5176\n"," samples avg       0.49      0.49      0.49      5176\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.35768321588345114\n","\n","Accuracy score for DP - 0.5075347758887172\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       786\n","           1       0.44      0.48      0.46      1910\n","           2       0.56      0.69      0.62      2480\n","\n","   micro avg       0.51      0.51      0.51      5176\n","   macro avg       0.33      0.39      0.36      5176\n","weighted avg       0.43      0.51      0.46      5176\n"," samples avg       0.51      0.51      0.51      5176\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.2927912818178758\n","\n","Accuracy score for DM - 0.535548686244204\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.55      0.94      0.70      2781\n","           1       0.42      0.00      0.01      1157\n","           2       0.33      0.12      0.17      1238\n","\n","   micro avg       0.54      0.54      0.54      5176\n","   macro avg       0.43      0.35      0.29      5176\n","weighted avg       0.47      0.54      0.42      5176\n"," samples avg       0.54      0.54      0.54      5176\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d686597e05f248d284691016c7c1f1e5","version_major":2,"version_minor":0},"text/plain":["Epoch 3:   0%|          | 0/89 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #3 - 7.402689248374705\n","\n"," Scores after 3 on validation:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.30785006891873085\n","\n","Accuracy score for AP - 0.4894810659186536\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       131\n","           1       0.46      0.21      0.28       253\n","           2       0.49      0.90      0.64       329\n","\n","   micro avg       0.49      0.49      0.49       713\n","   macro avg       0.32      0.37      0.31       713\n","weighted avg       0.39      0.49      0.40       713\n"," samples avg       0.49      0.49      0.49       713\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.2628150665533843\n","\n","Accuracy score for AM - 0.6507713884992987\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.65      1.00      0.79       464\n","           1       0.00      0.00      0.00       166\n","           2       0.00      0.00      0.00        83\n","\n","   micro avg       0.65      0.65      0.65       713\n","   macro avg       0.22      0.33      0.26       713\n","weighted avg       0.42      0.65      0.51       713\n"," samples avg       0.65      0.65      0.65       713\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.3198445458538905\n","\n","Accuracy score for BP - 0.4165497896213184\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.42      0.41      0.41       248\n","           1       0.42      0.67      0.52       289\n","           2       0.27      0.02      0.03       176\n","\n","   micro avg       0.42      0.42      0.42       713\n","   macro avg       0.37      0.36      0.32       713\n","weighted avg       0.38      0.42      0.36       713\n"," samples avg       0.42      0.42      0.42       713\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.34207920141539466\n","\n","Accuracy score for BM - 0.4123422159887798\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.71      0.56       299\n","           1       0.34      0.23      0.28       243\n","           2       0.28      0.14      0.19       171\n","\n","   micro avg       0.41      0.41      0.41       713\n","   macro avg       0.36      0.36      0.34       713\n","weighted avg       0.38      0.41      0.38       713\n"," samples avg       0.41      0.41      0.41       713\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.35024938559614144\n","\n","Accuracy score for GP - 0.41935483870967744\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.40      0.16      0.23       217\n","           1       0.42      0.77      0.55       287\n","           2       0.41      0.21      0.28       209\n","\n","   micro avg       0.42      0.42      0.42       713\n","   macro avg       0.41      0.38      0.35       713\n","weighted avg       0.41      0.42      0.37       713\n"," samples avg       0.42      0.42      0.42       713\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.2232587064676617\n","\n","Accuracy score for GM - 0.5035063113604488\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      1.00      0.67       359\n","           1       0.00      0.00      0.00       209\n","           2       0.00      0.00      0.00       145\n","\n","   micro avg       0.50      0.50      0.50       713\n","   macro avg       0.17      0.33      0.22       713\n","weighted avg       0.25      0.50      0.34       713\n"," samples avg       0.50      0.50      0.50       713\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.35425281035069095\n","\n","Accuracy score for DP - 0.5245441795231417\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       114\n","           1       0.44      0.38      0.41       245\n","           2       0.56      0.80      0.66       354\n","\n","   micro avg       0.52      0.52      0.52       713\n","   macro avg       0.33      0.39      0.35       713\n","weighted avg       0.43      0.52      0.47       713\n"," samples avg       0.52      0.52      0.52       713\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.30955691013438846\n","\n","Accuracy score for DM - 0.5511921458625526\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.58      0.91      0.71       405\n","           1       0.00      0.00      0.00       153\n","           2       0.33      0.17      0.22       155\n","\n","   micro avg       0.55      0.55      0.55       713\n","   macro avg       0.30      0.36      0.31       713\n","weighted avg       0.40      0.55      0.45       713\n"," samples avg       0.55      0.55      0.55       713\n","\n","Best validation loss - 7.402689248374705\n","Epoch #4\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"51c8032aefd84538a82685ba8b61f3cf","version_major":2,"version_minor":0},"text/plain":["Epoch 4:   0%|          | 0/647 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #4 - 7.435042412994892\n","\n"," Scores after 4 on train:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.3416410833144534\n","\n","Accuracy score for AP - 0.47198608964451316\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.20      0.00      0.00      1057\n","           1       0.43      0.43      0.43      1895\n","           2       0.50      0.73      0.59      2224\n","\n","   micro avg       0.47      0.47      0.47      5176\n","   macro avg       0.38      0.39      0.34      5176\n","weighted avg       0.41      0.47      0.41      5176\n"," samples avg       0.47      0.47      0.47      5176\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.2537593235211998\n","\n","Accuracy score for AM - 0.6145672333848532\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.61      1.00      0.76      3184\n","           1       0.00      0.00      0.00      1269\n","           2       0.00      0.00      0.00       723\n","\n","   micro avg       0.61      0.61      0.61      5176\n","   macro avg       0.20      0.33      0.25      5176\n","weighted avg       0.38      0.61      0.47      5176\n"," samples avg       0.61      0.61      0.61      5176\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.3197986543399039\n","\n","Accuracy score for BP - 0.4275502318392581\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.42      0.30      0.35      1707\n","           1       0.43      0.76      0.55      2173\n","           2       0.34      0.03      0.06      1296\n","\n","   micro avg       0.43      0.43      0.43      5176\n","   macro avg       0.40      0.37      0.32      5176\n","weighted avg       0.41      0.43      0.36      5176\n"," samples avg       0.43      0.43      0.43      5176\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.3418696386047014\n","\n","Accuracy score for BM - 0.42909582689335396\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.80      0.57      2177\n","           1       0.36      0.15      0.21      1625\n","           2       0.40      0.17      0.24      1374\n","\n","   micro avg       0.43      0.43      0.43      5176\n","   macro avg       0.40      0.37      0.34      5176\n","weighted avg       0.41      0.43      0.37      5176\n"," samples avg       0.43      0.43      0.43      5176\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.3191397382368448\n","\n","Accuracy score for GP - 0.40745749613601234\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.38      0.24      0.30      1521\n","           1       0.42      0.78      0.55      2081\n","           2       0.35      0.07      0.12      1574\n","\n","   micro avg       0.41      0.41      0.41      5176\n","   macro avg       0.38      0.37      0.32      5176\n","weighted avg       0.39      0.41      0.34      5176\n"," samples avg       0.41      0.41      0.41      5176\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.2528962753506773\n","\n","Accuracy score for GM - 0.490919629057187\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.96      0.66      2544\n","           1       0.36      0.05      0.09      1591\n","           2       0.39      0.01      0.01      1041\n","\n","   micro avg       0.49      0.49      0.49      5176\n","   macro avg       0.41      0.34      0.25      5176\n","weighted avg       0.43      0.49      0.35      5176\n"," samples avg       0.49      0.49      0.49      5176\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.3621937137456095\n","\n","Accuracy score for DP - 0.5166151468315301\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       785\n","           1       0.45      0.47      0.46      1911\n","           2       0.56      0.72      0.63      2480\n","\n","   micro avg       0.52      0.52      0.52      5176\n","   macro avg       0.34      0.40      0.36      5176\n","weighted avg       0.43      0.52      0.47      5176\n"," samples avg       0.52      0.52      0.52      5176\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.29857878394861564\n","\n","Accuracy score for DM - 0.535355486862442\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.56      0.94      0.70      2781\n","           1       0.25      0.00      0.01      1159\n","           2       0.35      0.13      0.19      1236\n","\n","   micro avg       0.54      0.54      0.54      5176\n","   macro avg       0.38      0.36      0.30      5176\n","weighted avg       0.44      0.54      0.42      5176\n"," samples avg       0.54      0.54      0.54      5176\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3532f90ef9194f31a23c9b16d6a7fb2f","version_major":2,"version_minor":0},"text/plain":["Epoch 4:   0%|          | 0/89 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #4 - 7.381758380293936\n","\n"," Scores after 4 on validation:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.3517262712325622\n","\n","Accuracy score for AP - 0.4796633941093969\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.01      0.02       131\n","           1       0.40      0.51      0.45       253\n","           2       0.55      0.64      0.59       329\n","\n","   micro avg       0.48      0.48      0.48       713\n","   macro avg       0.48      0.39      0.35       713\n","weighted avg       0.49      0.48      0.43       713\n"," samples avg       0.48      0.48      0.48       713\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.2628150665533843\n","\n","Accuracy score for AM - 0.6507713884992987\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.65      1.00      0.79       464\n","           1       0.00      0.00      0.00       166\n","           2       0.00      0.00      0.00        83\n","\n","   micro avg       0.65      0.65      0.65       713\n","   macro avg       0.22      0.33      0.26       713\n","weighted avg       0.42      0.65      0.51       713\n"," samples avg       0.65      0.65      0.65       713\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.24195974686170765\n","\n","Accuracy score for BP - 0.4165497896213184\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.09      0.15       248\n","           1       0.41      0.95      0.58       289\n","           2       0.00      0.00      0.00       176\n","\n","   micro avg       0.42      0.42      0.42       713\n","   macro avg       0.29      0.35      0.24       713\n","weighted avg       0.32      0.42      0.29       713\n"," samples avg       0.42      0.42      0.42       713\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.31344223492559836\n","\n","Accuracy score for BM - 0.4179523141654979\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.82      0.58       299\n","           1       0.46      0.09      0.15       243\n","           2       0.25      0.18      0.21       171\n","\n","   micro avg       0.42      0.42      0.42       713\n","   macro avg       0.39      0.36      0.31       713\n","weighted avg       0.41      0.42      0.35       713\n"," samples avg       0.42      0.42      0.42       713\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.20096411090822433\n","\n","Accuracy score for GP - 0.3955119214586255\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.17      0.01      0.03       217\n","           1       0.40      0.97      0.57       287\n","           2       0.33      0.00      0.01       209\n","\n","   micro avg       0.40      0.40      0.40       713\n","   macro avg       0.30      0.33      0.20       713\n","weighted avg       0.31      0.40      0.24       713\n"," samples avg       0.40      0.40      0.40       713\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.22573992466221618\n","\n","Accuracy score for GM - 0.5007012622720898\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.99      0.67       359\n","           1       0.17      0.00      0.01       209\n","           2       0.00      0.00      0.00       145\n","\n","   micro avg       0.50      0.50      0.50       713\n","   macro avg       0.22      0.33      0.23       713\n","weighted avg       0.30      0.50      0.34       713\n"," samples avg       0.50      0.50      0.50       713\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.38018840118369707\n","\n","Accuracy score for DP - 0.5329593267882188\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       114\n","           1       0.43      0.58      0.50       245\n","           2       0.62      0.67      0.64       354\n","\n","   micro avg       0.53      0.53      0.53       713\n","   macro avg       0.35      0.42      0.38       713\n","weighted avg       0.46      0.53      0.49       713\n"," samples avg       0.53      0.53      0.53       713\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.30920919638408423\n","\n","Accuracy score for DM - 0.5582047685834503\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.58      0.92      0.71       405\n","           1       0.00      0.00      0.00       153\n","           2       0.35      0.15      0.22       155\n","\n","   micro avg       0.56      0.56      0.56       713\n","   macro avg       0.31      0.36      0.31       713\n","weighted avg       0.41      0.56      0.45       713\n"," samples avg       0.56      0.56      0.56       713\n","\n","Best validation loss - 7.381758380293936\n","Epoch #5\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa6958aedb9c473b99e6258928a98557","version_major":2,"version_minor":0},"text/plain":["Epoch 5:   0%|          | 0/647 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #5 - 7.404773730738157\n","\n"," Scores after 5 on train:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.3630777365225517\n","\n","Accuracy score for AP - 0.4785548686244204\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.43      0.03      0.05      1056\n","           1       0.44      0.45      0.44      1894\n","           2       0.51      0.72      0.59      2226\n","\n","   micro avg       0.48      0.48      0.48      5176\n","   macro avg       0.46      0.40      0.36      5176\n","weighted avg       0.47      0.48      0.43      5176\n"," samples avg       0.48      0.48      0.48      5176\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.25456277581476067\n","\n","Accuracy score for AM - 0.615726429675425\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.62      1.00      0.76      3186\n","           1       1.00      0.00      0.00      1266\n","           2       0.00      0.00      0.00       724\n","\n","   micro avg       0.62      0.62      0.62      5176\n","   macro avg       0.54      0.33      0.25      5176\n","weighted avg       0.62      0.62      0.47      5176\n"," samples avg       0.62      0.62      0.62      5176\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.324271640467474\n","\n","Accuracy score for BP - 0.43469860896445134\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.44      0.29      0.35      1706\n","           1       0.44      0.79      0.56      2171\n","           2       0.37      0.03      0.06      1299\n","\n","   micro avg       0.43      0.43      0.43      5176\n","   macro avg       0.41      0.37      0.32      5176\n","weighted avg       0.42      0.43      0.37      5176\n"," samples avg       0.43      0.43      0.43      5176\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.3327983636067038\n","\n","Accuracy score for BM - 0.41479907264296756\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.76      0.56      2178\n","           1       0.32      0.15      0.21      1625\n","           2       0.34      0.17      0.23      1373\n","\n","   micro avg       0.41      0.41      0.41      5176\n","   macro avg       0.37      0.36      0.33      5176\n","weighted avg       0.38      0.41      0.36      5176\n"," samples avg       0.41      0.41      0.41      5176\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.3280790953061074\n","\n","Accuracy score for GP - 0.4221406491499227\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.42      0.22      0.28      1519\n","           1       0.42      0.83      0.56      2081\n","           2       0.43      0.08      0.14      1576\n","\n","   micro avg       0.42      0.42      0.42      5176\n","   macro avg       0.42      0.38      0.33      5176\n","weighted avg       0.42      0.42      0.35      5176\n"," samples avg       0.42      0.42      0.42      5176\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.25659971204684656\n","\n","Accuracy score for GM - 0.4899536321483771\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.96      0.65      2546\n","           1       0.36      0.06      0.10      1588\n","           2       0.50      0.01      0.01      1042\n","\n","   micro avg       0.49      0.49      0.49      5176\n","   macro avg       0.45      0.34      0.26      5176\n","weighted avg       0.46      0.49      0.36      5176\n"," samples avg       0.49      0.49      0.49      5176\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.3632892683043969\n","\n","Accuracy score for DP - 0.5164219474497682\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       786\n","           1       0.45      0.48      0.46      1908\n","           2       0.56      0.71      0.63      2482\n","\n","   micro avg       0.52      0.52      0.52      5176\n","   macro avg       0.34      0.40      0.36      5176\n","weighted avg       0.43      0.52      0.47      5176\n"," samples avg       0.52      0.52      0.52      5176\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.3055266015110841\n","\n","Accuracy score for DM - 0.535355486862442\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.56      0.93      0.70      2781\n","           1       0.29      0.00      0.00      1157\n","           2       0.36      0.16      0.22      1238\n","\n","   micro avg       0.54      0.54      0.54      5176\n","   macro avg       0.40      0.36      0.31      5176\n","weighted avg       0.45      0.54      0.43      5176\n"," samples avg       0.54      0.54      0.54      5176\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3730ad4ffbea4bb59301ce1c4ba69b8a","version_major":2,"version_minor":0},"text/plain":["Epoch 5:   0%|          | 0/89 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #5 - 7.361315676067157\n","\n"," Scores after 5 on validation:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.3481754261234607\n","\n","Accuracy score for AP - 0.4894810659186536\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.02      0.03       131\n","           1       0.43      0.37      0.40       253\n","           2       0.52      0.77      0.62       329\n","\n","   micro avg       0.49      0.49      0.49       713\n","   macro avg       0.65      0.39      0.35       713\n","weighted avg       0.57      0.49      0.43       713\n"," samples avg       0.49      0.49      0.49       713\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.2628150665533843\n","\n","Accuracy score for AM - 0.6507713884992987\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.65      1.00      0.79       464\n","           1       0.00      0.00      0.00       166\n","           2       0.00      0.00      0.00        83\n","\n","   micro avg       0.65      0.65      0.65       713\n","   macro avg       0.22      0.33      0.26       713\n","weighted avg       0.42      0.65      0.51       713\n"," samples avg       0.65      0.65      0.65       713\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.25768918752094244\n","\n","Accuracy score for BP - 0.4109396914446003\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.44      0.14      0.21       248\n","           1       0.41      0.89      0.56       289\n","           2       0.00      0.00      0.00       176\n","\n","   micro avg       0.41      0.41      0.41       713\n","   macro avg       0.28      0.34      0.26       713\n","weighted avg       0.32      0.41      0.30       713\n"," samples avg       0.41      0.41      0.41       713\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.27111877064483697\n","\n","Accuracy score for BM - 0.4319775596072931\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.44      0.94      0.60       299\n","           1       0.47      0.06      0.11       243\n","           2       0.28      0.06      0.10       171\n","\n","   micro avg       0.43      0.43      0.43       713\n","   macro avg       0.39      0.36      0.27       713\n","weighted avg       0.41      0.43      0.31       713\n"," samples avg       0.43      0.43      0.43       713\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.2514646827894153\n","\n","Accuracy score for GP - 0.39270687237026647\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.35      0.12      0.18       217\n","           1       0.40      0.87      0.55       287\n","           2       0.13      0.01      0.02       209\n","\n","   micro avg       0.39      0.39      0.39       713\n","   macro avg       0.30      0.34      0.25       713\n","weighted avg       0.31      0.39      0.28       713\n"," samples avg       0.39      0.39      0.39       713\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.22242990654205608\n","\n","Accuracy score for GM - 0.5007012622720898\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.99      0.67       359\n","           1       0.00      0.00      0.00       209\n","           2       0.00      0.00      0.00       145\n","\n","   micro avg       0.50      0.50      0.50       713\n","   macro avg       0.17      0.33      0.22       713\n","weighted avg       0.25      0.50      0.34       713\n"," samples avg       0.50      0.50      0.50       713\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.3487578005416225\n","\n","Accuracy score for DP - 0.5329593267882188\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       114\n","           1       0.45      0.31      0.37       245\n","           2       0.56      0.86      0.68       354\n","\n","   micro avg       0.53      0.53      0.53       713\n","   macro avg       0.34      0.39      0.35       713\n","weighted avg       0.43      0.53      0.46       713\n"," samples avg       0.53      0.53      0.53       713\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.2663434604611075\n","\n","Accuracy score for DM - 0.5722300140252454\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.57      0.99      0.73       405\n","           1       0.00      0.00      0.00       153\n","           2       0.46      0.04      0.07       155\n","\n","   micro avg       0.57      0.57      0.57       713\n","   macro avg       0.35      0.34      0.27       713\n","weighted avg       0.43      0.57      0.43       713\n"," samples avg       0.57      0.57      0.57       713\n","\n","Best validation loss - 7.361315676067157\n","Epoch #6\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6231811caef24db5bf8aabbef351c8fd","version_major":2,"version_minor":0},"text/plain":["Epoch 6:   0%|          | 0/647 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #6 - 7.371398366776488\n","\n"," Scores after 6 on train:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.36442820781051943\n","\n","Accuracy score for AP - 0.48261205564142196\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.35      0.02      0.04      1056\n","           1       0.44      0.48      0.46      1896\n","           2       0.51      0.70      0.59      2224\n","\n","   micro avg       0.48      0.48      0.48      5176\n","   macro avg       0.44      0.40      0.36      5176\n","weighted avg       0.45      0.48      0.43      5176\n"," samples avg       0.48      0.48      0.48      5176\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.25507973709461407\n","\n","Accuracy score for AM - 0.615533230293663\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.62      1.00      0.76      3186\n","           1       0.67      0.00      0.00      1266\n","           2       0.00      0.00      0.00       724\n","\n","   micro avg       0.62      0.62      0.62      5176\n","   macro avg       0.43      0.33      0.26      5176\n","weighted avg       0.54      0.62      0.47      5176\n"," samples avg       0.62      0.62      0.62      5176\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.3431553346249521\n","\n","Accuracy score for BP - 0.44435857805255025\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.44      0.34      0.38      1706\n","           1       0.44      0.76      0.56      2172\n","           2       0.49      0.05      0.08      1298\n","\n","   micro avg       0.44      0.44      0.44      5176\n","   macro avg       0.46      0.38      0.34      5176\n","weighted avg       0.45      0.44      0.38      5176\n"," samples avg       0.44      0.44      0.44      5176\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.3514641937433851\n","\n","Accuracy score for BM - 0.4341190108191654\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.79      0.58      2178\n","           1       0.36      0.13      0.20      1626\n","           2       0.40      0.22      0.28      1372\n","\n","   micro avg       0.43      0.43      0.43      5176\n","   macro avg       0.40      0.38      0.35      5176\n","weighted avg       0.41      0.43      0.38      5176\n"," samples avg       0.43      0.43      0.43      5176\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.3368928375453428\n","\n","Accuracy score for GP - 0.41924265842349306\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.39      0.24      0.29      1521\n","           1       0.42      0.79      0.55      2080\n","           2       0.45      0.10      0.16      1575\n","\n","   micro avg       0.42      0.42      0.42      5176\n","   macro avg       0.42      0.38      0.34      5176\n","weighted avg       0.42      0.42      0.36      5176\n"," samples avg       0.42      0.42      0.42      5176\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.27057002722996326\n","\n","Accuracy score for GM - 0.49246522411128285\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.94      0.66      2544\n","           1       0.38      0.09      0.14      1590\n","           2       0.30      0.01      0.01      1042\n","\n","   micro avg       0.49      0.49      0.49      5176\n","   macro avg       0.39      0.35      0.27      5176\n","weighted avg       0.42      0.49      0.37      5176\n"," samples avg       0.49      0.49      0.49      5176\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.366220217841833\n","\n","Accuracy score for DP - 0.5226043276661515\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       786\n","           1       0.45      0.47      0.46      1910\n","           2       0.57      0.73      0.64      2480\n","\n","   micro avg       0.52      0.52      0.52      5176\n","   macro avg       0.34      0.40      0.37      5176\n","weighted avg       0.44      0.52      0.48      5176\n"," samples avg       0.52      0.52      0.52      5176\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.3002876835717061\n","\n","Accuracy score for DM - 0.5351622874806801\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.56      0.94      0.70      2780\n","           1       0.20      0.01      0.01      1159\n","           2       0.35      0.13      0.19      1237\n","\n","   micro avg       0.54      0.54      0.54      5176\n","   macro avg       0.37      0.36      0.30      5176\n","weighted avg       0.43      0.54      0.42      5176\n"," samples avg       0.54      0.54      0.54      5176\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"641c3df82a754145ab2725a30cdf41c5","version_major":2,"version_minor":0},"text/plain":["Epoch 6:   0%|          | 0/89 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #6 - 7.352264052120233\n","\n"," Scores after 6 on validation:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.3711830291341905\n","\n","Accuracy score for AP - 0.49228611500701264\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.05      0.10       131\n","           1       0.41      0.38      0.39       253\n","           2       0.53      0.76      0.62       329\n","\n","   micro avg       0.49      0.49      0.49       713\n","   macro avg       0.57      0.40      0.37       713\n","weighted avg       0.53      0.49      0.44       713\n"," samples avg       0.49      0.49      0.49       713\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.2628150665533843\n","\n","Accuracy score for AM - 0.6507713884992987\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.65      1.00      0.79       464\n","           1       0.00      0.00      0.00       166\n","           2       0.00      0.00      0.00        83\n","\n","   micro avg       0.65      0.65      0.65       713\n","   macro avg       0.22      0.33      0.26       713\n","weighted avg       0.42      0.65      0.51       713\n"," samples avg       0.65      0.65      0.65       713\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.3132303897982846\n","\n","Accuracy score for BP - 0.40953716690042075\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.42      0.23      0.30       248\n","           1       0.41      0.78      0.54       289\n","           2       0.37      0.06      0.11       176\n","\n","   micro avg       0.41      0.41      0.41       713\n","   macro avg       0.40      0.36      0.31       713\n","weighted avg       0.40      0.41      0.35       713\n"," samples avg       0.41      0.41      0.41       713\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.3031537707874577\n","\n","Accuracy score for BM - 0.4361851332398317\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.90      0.60       299\n","           1       0.37      0.10      0.16       243\n","           2       0.31      0.09      0.14       171\n","\n","   micro avg       0.44      0.44      0.44       713\n","   macro avg       0.38      0.37      0.30       713\n","weighted avg       0.39      0.44      0.34       713\n"," samples avg       0.44      0.44      0.44       713\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.2910927883819516\n","\n","Accuracy score for GP - 0.41374474053295934\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.59      0.07      0.13       217\n","           1       0.41      0.89      0.56       287\n","           2       0.40      0.12      0.18       209\n","\n","   micro avg       0.41      0.41      0.41       713\n","   macro avg       0.47      0.36      0.29       713\n","weighted avg       0.46      0.41      0.32       713\n"," samples avg       0.41      0.41      0.41       713\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.24870699679514452\n","\n","Accuracy score for GM - 0.5007012622720898\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.97      0.66       359\n","           1       0.38      0.04      0.07       209\n","           2       1.00      0.01      0.01       145\n","\n","   micro avg       0.50      0.50      0.50       713\n","   macro avg       0.63      0.34      0.25       713\n","weighted avg       0.57      0.50      0.36       713\n"," samples avg       0.50      0.50      0.50       713\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.3780091253775464\n","\n","Accuracy score for DP - 0.5385694249649369\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       114\n","           1       0.44      0.51      0.47       245\n","           2       0.61      0.73      0.66       354\n","\n","   micro avg       0.54      0.54      0.54       713\n","   macro avg       0.35      0.41      0.38       713\n","weighted avg       0.45      0.54      0.49       713\n"," samples avg       0.54      0.54      0.54       713\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.321987330059079\n","\n","Accuracy score for DM - 0.5708274894810659\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.59      0.94      0.72       405\n","           1       0.00      0.00      0.00       153\n","           2       0.40      0.17      0.24       155\n","\n","   micro avg       0.57      0.57      0.57       713\n","   macro avg       0.33      0.37      0.32       713\n","weighted avg       0.42      0.57      0.46       713\n"," samples avg       0.57      0.57      0.57       713\n","\n","Best validation loss - 7.352264052120233\n","Epoch #7\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5b6cdd6c7653458a9305a5ee24844c02","version_major":2,"version_minor":0},"text/plain":["Epoch 7:   0%|          | 0/647 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #7 - 7.3404087177057304\n","\n"," Scores after 7 on train:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.3679485590977549\n","\n","Accuracy score for AP - 0.4804868624420402\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.43      0.04      0.07      1057\n","           1       0.44      0.43      0.43      1895\n","           2       0.51      0.73      0.60      2224\n","\n","   micro avg       0.48      0.48      0.48      5176\n","   macro avg       0.46      0.40      0.37      5176\n","weighted avg       0.47      0.48      0.43      5176\n"," samples avg       0.48      0.48      0.48      5176\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.2554920538680751\n","\n","Accuracy score for AM - 0.615726429675425\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.62      1.00      0.76      3185\n","           1       1.00      0.00      0.00      1267\n","           2       0.50      0.00      0.00       724\n","\n","   micro avg       0.62      0.62      0.62      5176\n","   macro avg       0.71      0.33      0.26      5176\n","weighted avg       0.69      0.62      0.47      5176\n"," samples avg       0.62      0.62      0.62      5176\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.34873703033307674\n","\n","Accuracy score for BP - 0.44860896445131376\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.38      0.41      1707\n","           1       0.45      0.75      0.56      2171\n","           2       0.42      0.04      0.07      1298\n","\n","   micro avg       0.45      0.45      0.45      5176\n","   macro avg       0.44      0.39      0.35      5176\n","weighted avg       0.44      0.45      0.39      5176\n"," samples avg       0.45      0.45      0.45      5176\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.35293810433745304\n","\n","Accuracy score for BM - 0.4339258114374034\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.79      0.58      2177\n","           1       0.35      0.13      0.19      1626\n","           2       0.40      0.23      0.30      1373\n","\n","   micro avg       0.43      0.43      0.43      5176\n","   macro avg       0.40      0.38      0.35      5176\n","weighted avg       0.41      0.43      0.38      5176\n"," samples avg       0.43      0.43      0.43      5176\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.3414885862802832\n","\n","Accuracy score for GP - 0.4221406491499227\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.40      0.23      0.29      1521\n","           1       0.42      0.80      0.55      2081\n","           2       0.44      0.11      0.18      1574\n","\n","   micro avg       0.42      0.42      0.42      5176\n","   macro avg       0.42      0.38      0.34      5176\n","weighted avg       0.42      0.42      0.36      5176\n"," samples avg       0.42      0.42      0.42      5176\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.26849136583461874\n","\n","Accuracy score for GM - 0.49671561051004637\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.96      0.66      2543\n","           1       0.40      0.08      0.14      1591\n","           2       0.31      0.00      0.01      1042\n","\n","   micro avg       0.50      0.50      0.50      5176\n","   macro avg       0.41      0.35      0.27      5176\n","weighted avg       0.43      0.50      0.37      5176\n"," samples avg       0.50      0.50      0.50      5176\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.36445286695945206\n","\n","Accuracy score for DP - 0.5195131375579598\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       786\n","           1       0.45      0.47      0.46      1910\n","           2       0.56      0.72      0.63      2480\n","\n","   micro avg       0.52      0.52      0.52      5176\n","   macro avg       0.34      0.40      0.36      5176\n","weighted avg       0.44      0.52      0.47      5176\n"," samples avg       0.52      0.52      0.52      5176\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.315903863766463\n","\n","Accuracy score for DM - 0.544435857805255\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.56      0.94      0.70      2780\n","           1       0.50      0.01      0.01      1158\n","           2       0.40      0.17      0.23      1238\n","\n","   micro avg       0.54      0.54      0.54      5176\n","   macro avg       0.49      0.37      0.32      5176\n","weighted avg       0.51      0.54      0.44      5176\n"," samples avg       0.54      0.54      0.54      5176\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59c0fe39b1374b88ae69ed1861662ed3","version_major":2,"version_minor":0},"text/plain":["Epoch 7:   0%|          | 0/89 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #7 - 7.391331171005523\n","\n"," Scores after 7 on validation:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.3529368221081484\n","\n","Accuracy score for AP - 0.46563814866760167\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.33      0.02      0.04       131\n","           1       0.39      0.54      0.45       253\n","           2       0.54      0.59      0.56       329\n","\n","   micro avg       0.47      0.47      0.47       713\n","   macro avg       0.42      0.38      0.35       713\n","weighted avg       0.45      0.47      0.43       713\n"," samples avg       0.47      0.47      0.47       713\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.2628150665533843\n","\n","Accuracy score for AM - 0.6507713884992987\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.65      1.00      0.79       464\n","           1       0.00      0.00      0.00       166\n","           2       0.00      0.00      0.00        83\n","\n","   micro avg       0.65      0.65      0.65       713\n","   macro avg       0.22      0.33      0.26       713\n","weighted avg       0.42      0.65      0.51       713\n"," samples avg       0.65      0.65      0.65       713\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.2796170397825311\n","\n","Accuracy score for BP - 0.40953716690042075\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.41      0.21      0.28       248\n","           1       0.41      0.83      0.55       289\n","           2       0.14      0.01      0.01       176\n","\n","   micro avg       0.41      0.41      0.41       713\n","   macro avg       0.32      0.35      0.28       713\n","weighted avg       0.34      0.41      0.32       713\n"," samples avg       0.41      0.41      0.41       713\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.2651432764514313\n","\n","Accuracy score for BM - 0.4053295932678822\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.43      0.88      0.58       299\n","           1       0.17      0.02      0.04       243\n","           2       0.29      0.12      0.17       171\n","\n","   micro avg       0.41      0.41      0.41       713\n","   macro avg       0.30      0.34      0.27       713\n","weighted avg       0.31      0.41      0.30       713\n"," samples avg       0.41      0.41      0.41       713\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.23757582636908392\n","\n","Accuracy score for GP - 0.40252454417952316\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.06      0.11       217\n","           1       0.40      0.94      0.56       287\n","           2       0.25      0.02      0.04       209\n","\n","   micro avg       0.40      0.40      0.40       713\n","   macro avg       0.38      0.34      0.24       713\n","weighted avg       0.38      0.40      0.27       713\n"," samples avg       0.40      0.40      0.40       713\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.2484433859468883\n","\n","Accuracy score for GM - 0.4908835904628331\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.94      0.66       359\n","           1       0.28      0.05      0.09       209\n","           2       0.00      0.00      0.00       145\n","\n","   micro avg       0.49      0.49      0.49       713\n","   macro avg       0.26      0.33      0.25       713\n","weighted avg       0.33      0.49      0.36       713\n"," samples avg       0.49      0.49      0.49       713\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.36564445841843735\n","\n","Accuracy score for DP - 0.520336605890603\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       114\n","           1       0.41      0.50      0.45       245\n","           2       0.59      0.70      0.64       354\n","\n","   micro avg       0.52      0.52      0.52       713\n","   macro avg       0.34      0.40      0.37       713\n","weighted avg       0.44      0.52      0.48       713\n"," samples avg       0.52      0.52      0.52       713\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.2982469115258865\n","\n","Accuracy score for DM - 0.5694249649368864\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.58      0.96      0.73       405\n","           1       0.00      0.00      0.00       153\n","           2       0.36      0.11      0.17       155\n","\n","   micro avg       0.57      0.57      0.57       713\n","   macro avg       0.32      0.36      0.30       713\n","weighted avg       0.41      0.57      0.45       713\n"," samples avg       0.57      0.57      0.57       713\n","\n","Epoch #8\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"faf003792fe740519588e320f053fc49","version_major":2,"version_minor":0},"text/plain":["Epoch 8:   0%|          | 0/647 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #8 - 7.303276920643116\n","\n"," Scores after 8 on train:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.380986417547569\n","\n","Accuracy score for AP - 0.4851236476043277\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.36      0.05      0.09      1056\n","           1       0.44      0.47      0.46      1895\n","           2       0.52      0.70      0.60      2225\n","\n","   micro avg       0.49      0.49      0.49      5176\n","   macro avg       0.44      0.41      0.38      5176\n","weighted avg       0.46      0.49      0.44      5176\n"," samples avg       0.49      0.49      0.49      5176\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.2568598556355873\n","\n","Accuracy score for AM - 0.615919629057187\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.62      1.00      0.76      3186\n","           1       0.00      0.00      0.00      1266\n","           2       1.00      0.00      0.01       724\n","\n","   micro avg       0.62      0.62      0.62      5176\n","   macro avg       0.54      0.33      0.26      5176\n","weighted avg       0.52      0.62      0.47      5176\n"," samples avg       0.62      0.62      0.62      5176\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.35435765719766765\n","\n","Accuracy score for BP - 0.4470633693972179\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.36      0.40      1707\n","           1       0.45      0.75      0.56      2171\n","           2       0.39      0.06      0.10      1298\n","\n","   micro avg       0.45      0.45      0.45      5176\n","   macro avg       0.43      0.39      0.35      5176\n","weighted avg       0.43      0.45      0.39      5176\n"," samples avg       0.45      0.45      0.45      5176\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.3604873394304266\n","\n","Accuracy score for BM - 0.4331530139103555\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.77      0.57      2177\n","           1       0.39      0.18      0.25      1626\n","           2       0.39      0.20      0.27      1373\n","\n","   micro avg       0.43      0.43      0.43      5176\n","   macro avg       0.41      0.38      0.36      5176\n","weighted avg       0.41      0.43      0.39      5176\n"," samples avg       0.43      0.43      0.43      5176\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.36535550314425236\n","\n","Accuracy score for GP - 0.42870942812983\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.40      0.29      0.33      1520\n","           1       0.43      0.75      0.55      2080\n","           2       0.45      0.14      0.21      1576\n","\n","   micro avg       0.43      0.43      0.43      5176\n","   macro avg       0.43      0.39      0.37      5176\n","weighted avg       0.43      0.43      0.38      5176\n"," samples avg       0.43      0.43      0.43      5176\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.2687588532806319\n","\n","Accuracy score for GM - 0.491112828438949\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.95      0.66      2545\n","           1       0.33      0.08      0.13      1590\n","           2       0.44      0.01      0.02      1041\n","\n","   micro avg       0.49      0.49      0.49      5176\n","   macro avg       0.43      0.34      0.27      5176\n","weighted avg       0.44      0.49      0.37      5176\n"," samples avg       0.49      0.49      0.49      5176\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.3735839751859468\n","\n","Accuracy score for DP - 0.5260819165378671\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       784\n","           1       0.46      0.54      0.49      1910\n","           2       0.58      0.68      0.63      2482\n","\n","   micro avg       0.53      0.53      0.53      5176\n","   macro avg       0.35      0.41      0.37      5176\n","weighted avg       0.45      0.53      0.48      5176\n"," samples avg       0.53      0.53      0.53      5176\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.3216480094955334\n","\n","Accuracy score for DM - 0.5450154559505409\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.56      0.93      0.70      2780\n","           1       0.30      0.00      0.01      1159\n","           2       0.40      0.19      0.26      1237\n","\n","   micro avg       0.55      0.55      0.55      5176\n","   macro avg       0.42      0.37      0.32      5176\n","weighted avg       0.47      0.55      0.44      5176\n"," samples avg       0.55      0.55      0.55      5176\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2086a0417fc4461897696fa13e8b62df","version_major":2,"version_minor":0},"text/plain":["Epoch 8:   0%|          | 0/89 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #8 - 7.340786802429594\n","\n"," Scores after 8 on validation:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.3640232057721003\n","\n","Accuracy score for AP - 0.48807854137447404\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.36      0.03      0.06       131\n","           1       0.42      0.43      0.43       253\n","           2       0.53      0.71      0.61       329\n","\n","   micro avg       0.49      0.49      0.49       713\n","   macro avg       0.44      0.39      0.36       713\n","weighted avg       0.46      0.49      0.44       713\n"," samples avg       0.49      0.49      0.49       713\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.2628150665533843\n","\n","Accuracy score for AM - 0.6507713884992987\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.65      1.00      0.79       464\n","           1       0.00      0.00      0.00       166\n","           2       0.00      0.00      0.00        83\n","\n","   micro avg       0.65      0.65      0.65       713\n","   macro avg       0.22      0.33      0.26       713\n","weighted avg       0.42      0.65      0.51       713\n"," samples avg       0.65      0.65      0.65       713\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.28219390841068953\n","\n","Accuracy score for BP - 0.4053295932678822\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.40      0.23      0.29       248\n","           1       0.41      0.80      0.54       289\n","           2       0.17      0.01      0.01       176\n","\n","   micro avg       0.41      0.41      0.41       713\n","   macro avg       0.32      0.35      0.28       713\n","weighted avg       0.35      0.41      0.32       713\n"," samples avg       0.41      0.41      0.41       713\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.2952913863019642\n","\n","Accuracy score for BM - 0.423562412342216\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.44      0.88      0.59       299\n","           1       0.42      0.09      0.15       243\n","           2       0.26      0.10      0.14       171\n","\n","   micro avg       0.42      0.42      0.42       713\n","   macro avg       0.37      0.36      0.30       713\n","weighted avg       0.39      0.42      0.33       713\n"," samples avg       0.42      0.42      0.42       713\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.257937917927997\n","\n","Accuracy score for GP - 0.4053295932678822\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.38      0.09      0.15       217\n","           1       0.41      0.91      0.56       287\n","           2       0.39      0.03      0.06       209\n","\n","   micro avg       0.41      0.41      0.41       713\n","   macro avg       0.39      0.35      0.26       713\n","weighted avg       0.40      0.41      0.29       713\n"," samples avg       0.41      0.41      0.41       713\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.2645031524387886\n","\n","Accuracy score for GM - 0.5035063113604488\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.51      0.96      0.67       359\n","           1       0.38      0.08      0.13       209\n","           2       0.00      0.00      0.00       145\n","\n","   micro avg       0.50      0.50      0.50       713\n","   macro avg       0.30      0.34      0.26       713\n","weighted avg       0.37      0.50      0.37       713\n"," samples avg       0.50      0.50      0.50       713\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.3675313840289484\n","\n","Accuracy score for DP - 0.5301542776998598\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       114\n","           1       0.42      0.46      0.44       245\n","           2       0.59      0.75      0.66       354\n","\n","   micro avg       0.53      0.53      0.53       713\n","   macro avg       0.34      0.40      0.37       713\n","weighted avg       0.44      0.53      0.48       713\n"," samples avg       0.53      0.53      0.53       713\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.31184541169133695\n","\n","Accuracy score for DM - 0.576437587657784\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.59      0.96      0.73       405\n","           1       0.00      0.00      0.00       153\n","           2       0.43      0.14      0.21       155\n","\n","   micro avg       0.58      0.58      0.58       713\n","   macro avg       0.34      0.37      0.31       713\n","weighted avg       0.43      0.58      0.46       713\n"," samples avg       0.58      0.58      0.58       713\n","\n","Best validation loss - 7.340786802429594\n","Epoch #9\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4fc4c20cdffe424199aaee8b918a1ad5","version_major":2,"version_minor":0},"text/plain":["Epoch 9:   0%|          | 0/647 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #9 - 7.273857812390381\n","\n"," Scores after 9 on train:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.4082865211222493\n","\n","Accuracy score for AP - 0.4963292117465224\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.09      0.15      1057\n","           1       0.46      0.50      0.48      1894\n","           2       0.53      0.69      0.60      2225\n","\n","   micro avg       0.50      0.50      0.50      5176\n","   macro avg       0.48      0.43      0.41      5176\n","weighted avg       0.49      0.50      0.46      5176\n"," samples avg       0.50      0.50      0.50      5176\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.2558669485220359\n","\n","Accuracy score for AM - 0.615340030911901\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.62      1.00      0.76      3186\n","           1       0.00      0.00      0.00      1267\n","           2       0.29      0.00      0.01       723\n","\n","   micro avg       0.62      0.62      0.62      5176\n","   macro avg       0.30      0.33      0.26      5176\n","weighted avg       0.42      0.62      0.47      5176\n"," samples avg       0.62      0.62      0.62      5176\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.3585532569478609\n","\n","Accuracy score for BP - 0.44860896445131376\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.44      0.40      0.42      1706\n","           1       0.45      0.72      0.56      2173\n","           2       0.47      0.06      0.10      1297\n","\n","   micro avg       0.45      0.45      0.45      5176\n","   macro avg       0.45      0.39      0.36      5176\n","weighted avg       0.45      0.45      0.40      5176\n"," samples avg       0.45      0.45      0.45      5176\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.37429490481947475\n","\n","Accuracy score for BM - 0.4428129829984544\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.77      0.58      2177\n","           1       0.38      0.19      0.25      1625\n","           2       0.40      0.23      0.29      1374\n","\n","   micro avg       0.44      0.44      0.44      5176\n","   macro avg       0.42      0.39      0.37      5176\n","weighted avg       0.42      0.44      0.40      5176\n"," samples avg       0.44      0.44      0.44      5176\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.37212006131665176\n","\n","Accuracy score for GP - 0.4329598145285935\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.42      0.31      0.36      1520\n","           1       0.44      0.75      0.55      2081\n","           2       0.44      0.13      0.21      1575\n","\n","   micro avg       0.43      0.43      0.43      5176\n","   macro avg       0.43      0.40      0.37      5176\n","weighted avg       0.43      0.43      0.39      5176\n"," samples avg       0.43      0.43      0.43      5176\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.30074367261140594\n","\n","Accuracy score for GM - 0.500193199381762\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.52      0.92      0.66      2545\n","           1       0.37      0.15      0.21      1590\n","           2       0.38      0.01      0.03      1041\n","\n","   micro avg       0.50      0.50      0.50      5176\n","   macro avg       0.43      0.36      0.30      5176\n","weighted avg       0.45      0.50      0.40      5176\n"," samples avg       0.50      0.50      0.50      5176\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.37274851217158905\n","\n","Accuracy score for DP - 0.5251159196290572\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       786\n","           1       0.45      0.53      0.49      1907\n","           2       0.58      0.69      0.63      2483\n","\n","   micro avg       0.53      0.53      0.53      5176\n","   macro avg       0.34      0.41      0.37      5176\n","weighted avg       0.45      0.53      0.48      5176\n"," samples avg       0.53      0.53      0.53      5176\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.3330578851054981\n","\n","Accuracy score for DM - 0.5496522411128284\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.57      0.93      0.71      2782\n","           1       0.47      0.01      0.03      1158\n","           2       0.40      0.20      0.27      1236\n","\n","   micro avg       0.55      0.55      0.55      5176\n","   macro avg       0.48      0.38      0.33      5176\n","weighted avg       0.51      0.55      0.45      5176\n"," samples avg       0.55      0.55      0.55      5176\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"80301bdf115149fa8e2ead96eecc9c40","version_major":2,"version_minor":0},"text/plain":["Epoch 9:   0%|          | 0/89 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #9 - 7.3982229854704595\n","\n"," Scores after 9 on validation:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.34023724067968936\n","\n","Accuracy score for AP - 0.46984572230014027\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.02      0.04       131\n","           1       0.39      0.37      0.38       253\n","           2       0.51      0.73      0.60       329\n","\n","   micro avg       0.47      0.47      0.47       713\n","   macro avg       0.55      0.37      0.34       713\n","weighted avg       0.51      0.47      0.42       713\n"," samples avg       0.47      0.47      0.47       713\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.2628150665533843\n","\n","Accuracy score for AM - 0.6507713884992987\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.65      1.00      0.79       464\n","           1       0.00      0.00      0.00       166\n","           2       0.00      0.00      0.00        83\n","\n","   micro avg       0.65      0.65      0.65       713\n","   macro avg       0.22      0.33      0.26       713\n","weighted avg       0.42      0.65      0.51       713\n"," samples avg       0.65      0.65      0.65       713\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.2805291881588416\n","\n","Accuracy score for BP - 0.4179523141654979\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.43      0.16      0.23       248\n","           1       0.42      0.88      0.57       289\n","           2       0.25      0.02      0.04       176\n","\n","   micro avg       0.42      0.42      0.42       713\n","   macro avg       0.37      0.35      0.28       713\n","weighted avg       0.38      0.42      0.32       713\n"," samples avg       0.42      0.42      0.42       713\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.3075731375395703\n","\n","Accuracy score for BM - 0.4221598877980365\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.44      0.85      0.58       299\n","           1       0.34      0.12      0.18       243\n","           2       0.33      0.11      0.16       171\n","\n","   micro avg       0.42      0.42      0.42       713\n","   macro avg       0.37      0.36      0.31       713\n","weighted avg       0.38      0.42      0.34       713\n"," samples avg       0.42      0.42      0.42       713\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.27371802874795875\n","\n","Accuracy score for GP - 0.3955119214586255\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.37      0.12      0.18       217\n","           1       0.40      0.85      0.55       287\n","           2       0.30      0.06      0.10       209\n","\n","   micro avg       0.40      0.40      0.40       713\n","   macro avg       0.36      0.34      0.27       713\n","weighted avg       0.36      0.40      0.30       713\n"," samples avg       0.40      0.40      0.40       713\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.23690655384239856\n","\n","Accuracy score for GM - 0.49228611500701264\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.96      0.66       359\n","           1       0.23      0.03      0.05       209\n","           2       0.00      0.00      0.00       145\n","\n","   micro avg       0.49      0.49      0.49       713\n","   macro avg       0.24      0.33      0.24       713\n","weighted avg       0.32      0.49      0.35       713\n"," samples avg       0.49      0.49      0.49       713\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.3655641200767555\n","\n","Accuracy score for DP - 0.5329593267882188\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       114\n","           1       0.44      0.42      0.43       245\n","           2       0.58      0.78      0.66       354\n","\n","   micro avg       0.53      0.53      0.53       713\n","   macro avg       0.34      0.40      0.37       713\n","weighted avg       0.44      0.53      0.48       713\n"," samples avg       0.53      0.53      0.53       713\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.26989265981023974\n","\n","Accuracy score for DM - 0.5638148667601683\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.57      0.97      0.72       405\n","           1       0.00      0.00      0.00       153\n","           2       0.33      0.05      0.09       155\n","\n","   micro avg       0.56      0.56      0.56       713\n","   macro avg       0.30      0.34      0.27       713\n","weighted avg       0.40      0.56      0.43       713\n"," samples avg       0.56      0.56      0.56       713\n","\n","Epoch #10\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2600e3a8c1404690816722431e640213","version_major":2,"version_minor":0},"text/plain":["Epoch 10:   0%|          | 0/647 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #10 - 7.230725380129252\n","\n"," Scores after 10 on train:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.39848091466958957\n","\n","Accuracy score for AP - 0.4938176197836167\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.07      0.12      1056\n","           1       0.44      0.50      0.47      1895\n","           2       0.53      0.69      0.60      2225\n","\n","   micro avg       0.49      0.49      0.49      5176\n","   macro avg       0.48      0.42      0.40      5176\n","weighted avg       0.49      0.49      0.46      5176\n"," samples avg       0.49      0.49      0.49      5176\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.25867384896939555\n","\n","Accuracy score for AM - 0.615533230293663\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.62      1.00      0.76      3185\n","           1       0.40      0.00      0.00      1268\n","           2       0.44      0.01      0.01       723\n","\n","   micro avg       0.62      0.62      0.62      5176\n","   macro avg       0.49      0.34      0.26      5176\n","weighted avg       0.54      0.62      0.47      5176\n"," samples avg       0.62      0.62      0.62      5176\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.3559915094539292\n","\n","Accuracy score for BP - 0.44609737248840803\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.36      0.40      1707\n","           1       0.45      0.74      0.56      2172\n","           2       0.41      0.06      0.11      1297\n","\n","   micro avg       0.45      0.45      0.45      5176\n","   macro avg       0.44      0.39      0.36      5176\n","weighted avg       0.44      0.45      0.39      5176\n"," samples avg       0.45      0.45      0.45      5176\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.3812178506860842\n","\n","Accuracy score for BM - 0.44783616692426587\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.77      0.58      2177\n","           1       0.40      0.20      0.27      1625\n","           2       0.42      0.22      0.29      1374\n","\n","   micro avg       0.45      0.45      0.45      5176\n","   macro avg       0.43      0.40      0.38      5176\n","weighted avg       0.43      0.45      0.41      5176\n"," samples avg       0.45      0.45      0.45      5176\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.36870614568192034\n","\n","Accuracy score for GP - 0.4329598145285935\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.42      0.30      0.35      1521\n","           1       0.43      0.76      0.55      2081\n","           2       0.45      0.13      0.20      1574\n","\n","   micro avg       0.43      0.43      0.43      5176\n","   macro avg       0.44      0.40      0.37      5176\n","weighted avg       0.44      0.43      0.39      5176\n"," samples avg       0.43      0.43      0.43      5176\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.3086090592313076\n","\n","Accuracy score for GM - 0.500386398763524\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.52      0.90      0.66      2545\n","           1       0.37      0.17      0.24      1590\n","           2       0.32      0.01      0.03      1041\n","\n","   micro avg       0.50      0.50      0.50      5176\n","   macro avg       0.40      0.36      0.31      5176\n","weighted avg       0.44      0.50      0.40      5176\n"," samples avg       0.50      0.50      0.50      5176\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.37401543484014194\n","\n","Accuracy score for DP - 0.5282071097372488\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       785\n","           1       0.46      0.52      0.49      1909\n","           2       0.58      0.70      0.63      2482\n","\n","   micro avg       0.53      0.53      0.53      5176\n","   macro avg       0.35      0.41      0.37      5176\n","weighted avg       0.45      0.53      0.48      5176\n"," samples avg       0.53      0.53      0.53      5176\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.3320486709072668\n","\n","Accuracy score for DM - 0.5471406491499228\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.57      0.92      0.70      2781\n","           1       0.47      0.01      0.03      1158\n","           2       0.41      0.20      0.27      1237\n","\n","   micro avg       0.55      0.55      0.55      5176\n","   macro avg       0.48      0.38      0.33      5176\n","weighted avg       0.51      0.55      0.45      5176\n"," samples avg       0.55      0.55      0.55      5176\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30f3d18e28e045cbb09bf1a6cdad9880","version_major":2,"version_minor":0},"text/plain":["Epoch 10:   0%|          | 0/89 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #10 - 7.3215685653235365\n","\n"," Scores after 10 on validation:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.3895189457929626\n","\n","Accuracy score for AP - 0.47124824684431976\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.40      0.13      0.20       131\n","           1       0.40      0.37      0.38       253\n","           2       0.52      0.69      0.59       329\n","\n","   micro avg       0.47      0.47      0.47       713\n","   macro avg       0.44      0.39      0.39       713\n","weighted avg       0.45      0.47      0.44       713\n"," samples avg       0.47      0.47      0.47       713\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.261437908496732\n","\n","Accuracy score for AM - 0.6451612903225806\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.65      0.99      0.78       464\n","           1       0.00      0.00      0.00       166\n","           2       0.00      0.00      0.00        83\n","\n","   micro avg       0.65      0.65      0.65       713\n","   macro avg       0.22      0.33      0.26       713\n","weighted avg       0.42      0.65      0.51       713\n"," samples avg       0.65      0.65      0.65       713\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.33685987119320754\n","\n","Accuracy score for BP - 0.4179523141654979\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.43      0.43      0.43       248\n","           1       0.41      0.63      0.50       289\n","           2       0.47      0.05      0.08       176\n","\n","   micro avg       0.42      0.42      0.42       713\n","   macro avg       0.44      0.37      0.34       713\n","weighted avg       0.43      0.42      0.37       713\n"," samples avg       0.42      0.42      0.42       713\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.32223842334033376\n","\n","Accuracy score for BM - 0.40392706872370265\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.75      0.57       299\n","           1       0.36      0.09      0.14       243\n","           2       0.26      0.26      0.26       171\n","\n","   micro avg       0.40      0.40      0.40       713\n","   macro avg       0.36      0.36      0.32       713\n","weighted avg       0.38      0.40      0.35       713\n"," samples avg       0.40      0.40      0.40       713\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.36362493286730246\n","\n","Accuracy score for GP - 0.4277699859747546\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.41      0.35      0.38       217\n","           1       0.43      0.72      0.54       287\n","           2       0.49      0.11      0.17       209\n","\n","   micro avg       0.43      0.43      0.43       713\n","   macro avg       0.44      0.39      0.36       713\n","weighted avg       0.44      0.43      0.38       713\n"," samples avg       0.43      0.43      0.43       713\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.3013583689978347\n","\n","Accuracy score for GM - 0.4670406732117812\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.54      0.79      0.64       359\n","           1       0.27      0.23      0.25       209\n","           2       0.17      0.01      0.01       145\n","\n","   micro avg       0.47      0.47      0.47       713\n","   macro avg       0.33      0.34      0.30       713\n","weighted avg       0.38      0.47      0.40       713\n"," samples avg       0.47      0.47      0.47       713\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.3481667191688514\n","\n","Accuracy score for DP - 0.5217391304347826\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       114\n","           1       0.43      0.35      0.39       245\n","           2       0.56      0.81      0.66       354\n","\n","   micro avg       0.52      0.52      0.52       713\n","   macro avg       0.33      0.39      0.35       713\n","weighted avg       0.42      0.52      0.46       713\n"," samples avg       0.52      0.52      0.52       713\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.28712600717806364\n","\n","Accuracy score for DM - 0.5750350631136045\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.59      0.99      0.73       405\n","           1       0.18      0.01      0.02       153\n","           2       0.45      0.06      0.10       155\n","\n","   micro avg       0.58      0.58      0.58       713\n","   macro avg       0.41      0.35      0.29       713\n","weighted avg       0.47      0.58      0.44       713\n"," samples avg       0.58      0.58      0.58       713\n","\n","Best validation loss - 7.3215685653235365\n","Epoch #11\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f09594816f8f4149abf49fafab7abb3a","version_major":2,"version_minor":0},"text/plain":["Epoch 11:   0%|          | 0/647 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #11 - 7.196476834765768\n","\n"," Scores after 11 on train:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.41932721986623506\n","\n","Accuracy score for AP - 0.5081143740340031\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.44      0.10      0.16      1056\n","           1       0.46      0.51      0.49      1895\n","           2       0.55      0.70      0.61      2225\n","\n","   micro avg       0.51      0.51      0.51      5176\n","   macro avg       0.48      0.44      0.42      5176\n","weighted avg       0.50      0.51      0.47      5176\n"," samples avg       0.51      0.51      0.51      5176\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.2678223875433592\n","\n","Accuracy score for AM - 0.616306027820711\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.62      1.00      0.76      3184\n","           1       1.00      0.00      0.01      1269\n","           2       0.39      0.02      0.03       723\n","\n","   micro avg       0.62      0.62      0.62      5176\n","   macro avg       0.67      0.34      0.27      5176\n","weighted avg       0.68      0.62      0.48      5176\n"," samples avg       0.62      0.62      0.62      5176\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.3786371514439751\n","\n","Accuracy score for BP - 0.4578825347758887\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.37      0.42      1708\n","           1       0.45      0.74      0.56      2170\n","           2       0.43      0.09      0.15      1298\n","\n","   micro avg       0.46      0.46      0.46      5176\n","   macro avg       0.45      0.40      0.38      5176\n","weighted avg       0.45      0.46      0.41      5176\n"," samples avg       0.46      0.46      0.46      5176\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.39140063091735544\n","\n","Accuracy score for BM - 0.45131375579598143\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.75      0.58      2177\n","           1       0.40      0.21      0.28      1624\n","           2       0.43      0.25      0.32      1375\n","\n","   micro avg       0.45      0.45      0.45      5176\n","   macro avg       0.43      0.41      0.39      5176\n","weighted avg       0.44      0.45      0.41      5176\n"," samples avg       0.45      0.45      0.45      5176\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.3955401595913057\n","\n","Accuracy score for GP - 0.4484157650695518\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.35      0.39      1521\n","           1       0.45      0.74      0.56      2080\n","           2       0.47      0.16      0.24      1575\n","\n","   micro avg       0.45      0.45      0.45      5176\n","   macro avg       0.45      0.42      0.40      5176\n","weighted avg       0.45      0.45      0.41      5176\n"," samples avg       0.45      0.45      0.45      5176\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.32172638168162654\n","\n","Accuracy score for GM - 0.5079211746522411\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.53      0.91      0.67      2543\n","           1       0.39      0.18      0.24      1592\n","           2       0.43      0.03      0.05      1041\n","\n","   micro avg       0.51      0.51      0.51      5176\n","   macro avg       0.45      0.37      0.32      5176\n","weighted avg       0.47      0.51      0.41      5176\n"," samples avg       0.51      0.51      0.51      5176\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.3736877631039666\n","\n","Accuracy score for DP - 0.5285935085007728\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       786\n","           1       0.45      0.52      0.48      1909\n","           2       0.58      0.71      0.64      2481\n","\n","   micro avg       0.53      0.53      0.53      5176\n","   macro avg       0.35      0.41      0.37      5176\n","weighted avg       0.45      0.53      0.48      5176\n"," samples avg       0.53      0.53      0.53      5176\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.3247979012530451\n","\n","Accuracy score for DM - 0.5494590417310664\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.57      0.94      0.71      2781\n","           1       0.38      0.02      0.03      1158\n","           2       0.41      0.16      0.23      1237\n","\n","   micro avg       0.55      0.55      0.55      5176\n","   macro avg       0.45      0.37      0.32      5176\n","weighted avg       0.49      0.55      0.44      5176\n"," samples avg       0.55      0.55      0.55      5176\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb74bf97c98c412eb56d21f6e7399e9f","version_major":2,"version_minor":0},"text/plain":["Epoch 11:   0%|          | 0/89 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #11 - 7.327523714930168\n","\n"," Scores after 11 on validation:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.42644800763501767\n","\n","Accuracy score for AP - 0.514726507713885\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.43      0.12      0.19       131\n","           1       0.46      0.48      0.47       253\n","           2       0.56      0.70      0.62       329\n","\n","   micro avg       0.51      0.51      0.51       713\n","   macro avg       0.48      0.43      0.43       713\n","weighted avg       0.50      0.51      0.49       713\n"," samples avg       0.51      0.51      0.51       713\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.266319190935886\n","\n","Accuracy score for AM - 0.6493688639551192\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.65      1.00      0.79       464\n","           1       0.50      0.01      0.01       166\n","           2       0.00      0.00      0.00        83\n","\n","   micro avg       0.65      0.65      0.65       713\n","   macro avg       0.38      0.33      0.27       713\n","weighted avg       0.54      0.65      0.51       713\n"," samples avg       0.65      0.65      0.65       713\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.3374997238858776\n","\n","Accuracy score for BP - 0.43899018232819076\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.31      0.37       248\n","           1       0.43      0.79      0.56       289\n","           2       0.38      0.05      0.08       176\n","\n","   micro avg       0.44      0.44      0.44       713\n","   macro avg       0.43      0.38      0.34       713\n","weighted avg       0.43      0.44      0.38       713\n"," samples avg       0.44      0.44      0.44       713\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.3239858272247164\n","\n","Accuracy score for BM - 0.4361851332398317\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.87      0.60       299\n","           1       0.45      0.08      0.14       243\n","           2       0.31      0.19      0.23       171\n","\n","   micro avg       0.44      0.44      0.44       713\n","   macro avg       0.41      0.38      0.32       713\n","weighted avg       0.42      0.44      0.35       713\n"," samples avg       0.44      0.44      0.44       713\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.337300684646281\n","\n","Accuracy score for GP - 0.423562412342216\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.42      0.22      0.29       217\n","           1       0.42      0.81      0.56       287\n","           2       0.43      0.11      0.17       209\n","\n","   micro avg       0.42      0.42      0.42       713\n","   macro avg       0.43      0.38      0.34       713\n","weighted avg       0.43      0.42      0.36       713\n"," samples avg       0.42      0.42      0.42       713\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.2944613627050499\n","\n","Accuracy score for GM - 0.49789621318373073\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.51      0.92      0.66       359\n","           1       0.34      0.10      0.15       209\n","           2       0.43      0.04      0.08       145\n","\n","   micro avg       0.50      0.50      0.50       713\n","   macro avg       0.43      0.35      0.29       713\n","weighted avg       0.45      0.50      0.39       713\n"," samples avg       0.50      0.50      0.50       713\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.36750154607297464\n","\n","Accuracy score for DP - 0.5245441795231417\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       114\n","           1       0.42      0.49      0.45       245\n","           2       0.59      0.72      0.65       354\n","\n","   micro avg       0.52      0.52      0.52       713\n","   macro avg       0.34      0.40      0.37       713\n","weighted avg       0.44      0.52      0.48       713\n"," samples avg       0.52      0.52      0.52       713\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.3266020873484777\n","\n","Accuracy score for DM - 0.5596072931276297\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.91      0.72       405\n","           1       0.50      0.01      0.01       153\n","           2       0.33      0.20      0.25       155\n","\n","   micro avg       0.56      0.56      0.56       713\n","   macro avg       0.47      0.37      0.33       713\n","weighted avg       0.52      0.56      0.47       713\n"," samples avg       0.56      0.56      0.56       713\n","\n","Epoch #12\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c1c892f80ad64724af9844eb52a0f4f9","version_major":2,"version_minor":0},"text/plain":["Epoch 12:   0%|          | 0/647 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #12 - 7.150837776369581\n","\n"," Scores after 12 on train:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.44046876341703084\n","\n","Accuracy score for AP - 0.517387944358578\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.49      0.13      0.21      1056\n","           1       0.47      0.52      0.49      1895\n","           2       0.56      0.70      0.62      2225\n","\n","   micro avg       0.52      0.52      0.52      5176\n","   macro avg       0.51      0.45      0.44      5176\n","weighted avg       0.51      0.52      0.49      5176\n"," samples avg       0.52      0.52      0.52      5176\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.27512211483026433\n","\n","Accuracy score for AM - 0.6174652241112828\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.62      1.00      0.76      3184\n","           1       0.53      0.01      0.01      1269\n","           2       0.50      0.03      0.05       723\n","\n","   micro avg       0.62      0.62      0.62      5176\n","   macro avg       0.55      0.34      0.28      5176\n","weighted avg       0.58      0.62      0.48      5176\n"," samples avg       0.62      0.62      0.62      5176\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.37828365670563063\n","\n","Accuracy score for BP - 0.4569165378670788\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.39      0.43      1706\n","           1       0.45      0.73      0.56      2173\n","           2       0.46      0.09      0.15      1297\n","\n","   micro avg       0.46      0.46      0.46      5176\n","   macro avg       0.46      0.40      0.38      5176\n","weighted avg       0.46      0.46      0.41      5176\n"," samples avg       0.46      0.46      0.46      5176\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.397630834321558\n","\n","Accuracy score for BM - 0.4573029366306028\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.76      0.58      2177\n","           1       0.42      0.24      0.31      1625\n","           2       0.42      0.23      0.30      1374\n","\n","   micro avg       0.46      0.46      0.46      5176\n","   macro avg       0.44      0.41      0.40      5176\n","weighted avg       0.44      0.46      0.42      5176\n"," samples avg       0.46      0.46      0.46      5176\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.39770964639387624\n","\n","Accuracy score for GP - 0.4470633693972179\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.31      0.37      1520\n","           1       0.44      0.74      0.55      2081\n","           2       0.47      0.19      0.27      1575\n","\n","   micro avg       0.45      0.45      0.45      5176\n","   macro avg       0.45      0.41      0.40      5176\n","weighted avg       0.45      0.45      0.41      5176\n"," samples avg       0.45      0.45      0.45      5176\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.3246546771561178\n","\n","Accuracy score for GM - 0.5067619783616693\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.53      0.90      0.67      2545\n","           1       0.40      0.20      0.27      1589\n","           2       0.33      0.02      0.04      1042\n","\n","   micro avg       0.51      0.51      0.51      5176\n","   macro avg       0.42      0.37      0.32      5176\n","weighted avg       0.45      0.51      0.42      5176\n"," samples avg       0.51      0.51      0.51      5176\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.38053391736282216\n","\n","Accuracy score for DP - 0.5384466769706336\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       786\n","           1       0.47      0.52      0.49      1909\n","           2       0.59      0.72      0.65      2481\n","\n","   micro avg       0.54      0.54      0.54      5176\n","   macro avg       0.35      0.41      0.38      5176\n","weighted avg       0.45      0.54      0.49      5176\n"," samples avg       0.54      0.54      0.54      5176\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.3466578658570541\n","\n","Accuracy score for DM - 0.5510046367851623\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.57      0.91      0.71      2781\n","           1       0.60      0.02      0.04      1158\n","           2       0.40      0.23      0.29      1237\n","\n","   micro avg       0.55      0.55      0.55      5176\n","   macro avg       0.53      0.39      0.35      5176\n","weighted avg       0.54      0.55      0.46      5176\n"," samples avg       0.55      0.55      0.55      5176\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"29a302275c834a6083f3364cd09b2aff","version_major":2,"version_minor":0},"text/plain":["Epoch 12:   0%|          | 0/89 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #12 - 7.387186913189994\n","\n"," Scores after 12 on validation:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.39589450348011246\n","\n","Accuracy score for AP - 0.48246844319775595\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.11      0.19       131\n","           1       0.42      0.40      0.41       253\n","           2       0.52      0.69      0.59       329\n","\n","   micro avg       0.48      0.48      0.48       713\n","   macro avg       0.47      0.40      0.40       713\n","weighted avg       0.48      0.48      0.45       713\n"," samples avg       0.48      0.48      0.48       713\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.2784519748364397\n","\n","Accuracy score for AM - 0.6507713884992987\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.65      0.99      0.79       464\n","           1       0.40      0.01      0.02       166\n","           2       0.33      0.01      0.02        83\n","\n","   micro avg       0.65      0.65      0.65       713\n","   macro avg       0.46      0.34      0.28       713\n","weighted avg       0.56      0.65      0.52       713\n"," samples avg       0.65      0.65      0.65       713\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.338183157722656\n","\n","Accuracy score for BP - 0.4474053295932679\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.31      0.39       248\n","           1       0.43      0.81      0.57       289\n","           2       0.40      0.03      0.06       176\n","\n","   micro avg       0.45      0.45      0.45       713\n","   macro avg       0.44      0.39      0.34       713\n","weighted avg       0.45      0.45      0.38       713\n"," samples avg       0.45      0.45      0.45       713\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.3142602884021648\n","\n","Accuracy score for BM - 0.3955119214586255\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.44      0.74      0.55       299\n","           1       0.30      0.12      0.17       243\n","           2       0.28      0.19      0.22       171\n","\n","   micro avg       0.40      0.40      0.40       713\n","   macro avg       0.34      0.35      0.31       713\n","weighted avg       0.35      0.40      0.34       713\n"," samples avg       0.40      0.40      0.40       713\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.34105882493393064\n","\n","Accuracy score for GP - 0.3997194950911641\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.34      0.25      0.29       217\n","           1       0.42      0.70      0.53       287\n","           2       0.39      0.14      0.21       209\n","\n","   micro avg       0.40      0.40      0.40       713\n","   macro avg       0.38      0.36      0.34       713\n","weighted avg       0.39      0.40      0.36       713\n"," samples avg       0.40      0.40      0.40       713\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.2719757729093592\n","\n","Accuracy score for GM - 0.5007012622720898\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.51      0.95      0.66       359\n","           1       0.34      0.07      0.11       209\n","           2       0.38      0.02      0.04       145\n","\n","   micro avg       0.50      0.50      0.50       713\n","   macro avg       0.41      0.34      0.27       713\n","weighted avg       0.43      0.50      0.38       713\n"," samples avg       0.50      0.50      0.50       713\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.3640372413660303\n","\n","Accuracy score for DP - 0.5189340813464236\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       114\n","           1       0.42      0.49      0.45       245\n","           2       0.59      0.71      0.64       354\n","\n","   micro avg       0.52      0.52      0.52       713\n","   macro avg       0.33      0.40      0.36       713\n","weighted avg       0.44      0.52      0.47       713\n"," samples avg       0.52      0.52      0.52       713\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.30906568132885387\n","\n","Accuracy score for DM - 0.5539971949509116\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.58      0.92      0.71       405\n","           1       0.25      0.01      0.02       153\n","           2       0.31      0.14      0.19       155\n","\n","   micro avg       0.55      0.55      0.55       713\n","   macro avg       0.38      0.36      0.31       713\n","weighted avg       0.45      0.55      0.45       713\n"," samples avg       0.55      0.55      0.55       713\n","\n","Epoch #13\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9b798c30b9b4872a312ebee1d5103d1","version_major":2,"version_minor":0},"text/plain":["Epoch 13:   0%|          | 0/647 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #13 - 7.12256120038484\n","\n"," Scores after 13 on train:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.4493037626155862\n","\n","Accuracy score for AP - 0.5197063369397218\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.15      0.24      1056\n","           1       0.48      0.51      0.49      1894\n","           2       0.55      0.70      0.62      2226\n","\n","   micro avg       0.52      0.52      0.52      5176\n","   macro avg       0.51      0.46      0.45      5176\n","weighted avg       0.51      0.52      0.49      5176\n"," samples avg       0.52      0.52      0.52      5176\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.2774252763571156\n","\n","Accuracy score for AM - 0.615919629057187\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.62      0.99      0.76      3186\n","           1       0.20      0.00      0.00      1267\n","           2       0.42      0.04      0.07       723\n","\n","   micro avg       0.62      0.62      0.62      5176\n","   macro avg       0.41      0.34      0.28      5176\n","weighted avg       0.49      0.62      0.48      5176\n"," samples avg       0.62      0.62      0.62      5176\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.3901254762484389\n","\n","Accuracy score for BP - 0.4677357032457496\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.40      0.44      1707\n","           1       0.46      0.74      0.57      2170\n","           2       0.46      0.10      0.16      1299\n","\n","   micro avg       0.47      0.47      0.47      5176\n","   macro avg       0.47      0.41      0.39      5176\n","weighted avg       0.47      0.47      0.42      5176\n"," samples avg       0.47      0.47      0.47      5176\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.4049164630001991\n","\n","Accuracy score for BM - 0.46309891808346215\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.76      0.59      2179\n","           1       0.42      0.22      0.29      1624\n","           2       0.44      0.28      0.34      1373\n","\n","   micro avg       0.46      0.46      0.46      5176\n","   macro avg       0.44      0.42      0.40      5176\n","weighted avg       0.45      0.46      0.43      5176\n"," samples avg       0.46      0.46      0.46      5176\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.4128881108512659\n","\n","Accuracy score for GP - 0.4567233384853168\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.44      0.35      0.39      1520\n","           1       0.46      0.73      0.56      2081\n","           2       0.48      0.21      0.29      1575\n","\n","   micro avg       0.46      0.46      0.46      5176\n","   macro avg       0.46      0.43      0.41      5176\n","weighted avg       0.46      0.46      0.43      5176\n"," samples avg       0.46      0.46      0.46      5176\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.33382349703597436\n","\n","Accuracy score for GM - 0.508500772797527\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.53      0.90      0.67      2545\n","           1       0.40      0.19      0.26      1590\n","           2       0.39      0.04      0.07      1041\n","\n","   micro avg       0.51      0.51      0.51      5176\n","   macro avg       0.44      0.38      0.33      5176\n","weighted avg       0.46      0.51      0.42      5176\n"," samples avg       0.51      0.51      0.51      5176\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.3789624438678923\n","\n","Accuracy score for DP - 0.535355486862442\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       786\n","           1       0.46      0.53      0.49      1908\n","           2       0.59      0.71      0.65      2482\n","\n","   micro avg       0.54      0.54      0.54      5176\n","   macro avg       0.35      0.41      0.38      5176\n","weighted avg       0.45      0.54      0.49      5176\n"," samples avg       0.54      0.54      0.54      5176\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.3482726036918275\n","\n","Accuracy score for DM - 0.5515842349304482\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.57      0.92      0.71      2782\n","           1       0.45      0.03      0.06      1156\n","           2       0.41      0.21      0.28      1238\n","\n","   micro avg       0.55      0.55      0.55      5176\n","   macro avg       0.48      0.39      0.35      5176\n","weighted avg       0.51      0.55      0.46      5176\n"," samples avg       0.55      0.55      0.55      5176\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"836bf03fc89f40089031ac4ac5ec1f57","version_major":2,"version_minor":0},"text/plain":["Epoch 13:   0%|          | 0/89 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #13 - 7.382911280999443\n","\n"," Scores after 13 on validation:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.41488434426410975\n","\n","Accuracy score for AP - 0.5021037868162693\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.42      0.11      0.17       131\n","           1       0.44      0.51      0.48       253\n","           2       0.55      0.65      0.60       329\n","\n","   micro avg       0.50      0.50      0.50       713\n","   macro avg       0.47      0.42      0.41       713\n","weighted avg       0.49      0.50      0.48       713\n"," samples avg       0.50      0.50      0.50       713\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.2751018591102208\n","\n","Accuracy score for AM - 0.638148667601683\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.65      0.98      0.78       464\n","           1       0.00      0.00      0.00       166\n","           2       0.33      0.02      0.04        83\n","\n","   micro avg       0.64      0.64      0.64       713\n","   macro avg       0.33      0.33      0.28       713\n","weighted avg       0.46      0.64      0.51       713\n"," samples avg       0.64      0.64      0.64       713\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.33805282313744983\n","\n","Accuracy score for BP - 0.4277699859747546\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.33      0.38       248\n","           1       0.44      0.74      0.55       289\n","           2       0.24      0.05      0.08       176\n","\n","   micro avg       0.43      0.43      0.43       713\n","   macro avg       0.37      0.37      0.34       713\n","weighted avg       0.39      0.43      0.38       713\n"," samples avg       0.43      0.43      0.43       713\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.35249212215415376\n","\n","Accuracy score for BM - 0.4179523141654979\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.73      0.57       299\n","           1       0.37      0.19      0.25       243\n","           2       0.30      0.21      0.25       171\n","\n","   micro avg       0.42      0.42      0.42       713\n","   macro avg       0.37      0.37      0.35       713\n","weighted avg       0.39      0.42      0.38       713\n"," samples avg       0.42      0.42      0.42       713\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.3336268220347068\n","\n","Accuracy score for GP - 0.4109396914446003\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.43      0.20      0.28       217\n","           1       0.42      0.78      0.54       287\n","           2       0.35      0.12      0.18       209\n","\n","   micro avg       0.41      0.41      0.41       713\n","   macro avg       0.40      0.37      0.33       713\n","weighted avg       0.40      0.41      0.36       713\n"," samples avg       0.41      0.41      0.41       713\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.30185935224246835\n","\n","Accuracy score for GM - 0.4796633941093969\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.51      0.86      0.64       359\n","           1       0.30      0.13      0.18       209\n","           2       0.37      0.05      0.09       145\n","\n","   micro avg       0.48      0.48      0.48       713\n","   macro avg       0.39      0.35      0.30       713\n","weighted avg       0.42      0.48      0.39       713\n"," samples avg       0.48      0.48      0.48       713\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.3698430565922712\n","\n","Accuracy score for DP - 0.5259467040673211\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       114\n","           1       0.42      0.51      0.46       245\n","           2       0.60      0.71      0.65       354\n","\n","   micro avg       0.53      0.53      0.53       713\n","   macro avg       0.34      0.41      0.37       713\n","weighted avg       0.44      0.53      0.48       713\n"," samples avg       0.53      0.53      0.53       713\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.3236803159919352\n","\n","Accuracy score for DM - 0.5539971949509116\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.59      0.89      0.71       405\n","           1       0.00      0.00      0.00       153\n","           2       0.33      0.21      0.26       155\n","\n","   micro avg       0.55      0.55      0.55       713\n","   macro avg       0.31      0.37      0.32       713\n","weighted avg       0.41      0.55      0.46       713\n"," samples avg       0.55      0.55      0.55       713\n","\n","Epoch #14\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd5a11ab400d4e7db9408b458de038c5","version_major":2,"version_minor":0},"text/plain":["Epoch 14:   0%|          | 0/647 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #14 - 7.095930277974094\n","\n"," Scores after 14 on train:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.4398795363327827\n","\n","Accuracy score for AP - 0.5189335394126738\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.13      0.20      1056\n","           1       0.47      0.52      0.49      1895\n","           2       0.56      0.70      0.63      2225\n","\n","   micro avg       0.52      0.52      0.52      5176\n","   macro avg       0.50      0.45      0.44      5176\n","weighted avg       0.51      0.52      0.49      5176\n"," samples avg       0.52      0.52      0.52      5176\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.28492243202347683\n","\n","Accuracy score for AM - 0.6193972179289027\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.62      0.99      0.77      3185\n","           1       0.44      0.01      0.01      1268\n","           2       0.44      0.04      0.08       723\n","\n","   micro avg       0.62      0.62      0.62      5176\n","   macro avg       0.50      0.35      0.28      5176\n","weighted avg       0.55      0.62      0.48      5176\n"," samples avg       0.62      0.62      0.62      5176\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.4017260473480168\n","\n","Accuracy score for BP - 0.47836166924265844\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.41      0.45      1706\n","           1       0.47      0.75      0.58      2172\n","           2       0.48      0.11      0.17      1298\n","\n","   micro avg       0.48      0.48      0.48      5176\n","   macro avg       0.48      0.42      0.40      5176\n","weighted avg       0.48      0.48      0.44      5176\n"," samples avg       0.48      0.48      0.48      5176\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.4065446506589622\n","\n","Accuracy score for BM - 0.4605873261205564\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.75      0.59      2176\n","           1       0.41      0.23      0.29      1626\n","           2       0.43      0.28      0.34      1374\n","\n","   micro avg       0.46      0.46      0.46      5176\n","   macro avg       0.44      0.42      0.41      5176\n","weighted avg       0.45      0.46      0.43      5176\n"," samples avg       0.46      0.46      0.46      5176\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.4107399961483957\n","\n","Accuracy score for GP - 0.45401854714064915\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.32      0.38      1521\n","           1       0.45      0.73      0.56      2081\n","           2       0.47      0.22      0.30      1574\n","\n","   micro avg       0.45      0.45      0.45      5176\n","   macro avg       0.46      0.42      0.41      5176\n","weighted avg       0.46      0.45      0.43      5176\n"," samples avg       0.45      0.45      0.45      5176\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.3449028026530892\n","\n","Accuracy score for GM - 0.5121715610510046\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.54      0.89      0.67      2543\n","           1       0.40      0.21      0.28      1592\n","           2       0.47      0.05      0.09      1041\n","\n","   micro avg       0.51      0.51      0.51      5176\n","   macro avg       0.47      0.38      0.34      5176\n","weighted avg       0.48      0.51      0.43      5176\n"," samples avg       0.51      0.51      0.51      5176\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.3836569616041561\n","\n","Accuracy score for DP - 0.5430834621329211\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       784\n","           1       0.47      0.53      0.50      1909\n","           2       0.60      0.73      0.66      2483\n","\n","   micro avg       0.54      0.54      0.54      5176\n","   macro avg       0.35      0.42      0.38      5176\n","weighted avg       0.46      0.54      0.50      5176\n"," samples avg       0.54      0.54      0.54      5176\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.34094139534200935\n","\n","Accuracy score for DM - 0.5525502318392581\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.57      0.93      0.71      2783\n","           1       0.32      0.02      0.03      1156\n","           2       0.42      0.21      0.28      1237\n","\n","   micro avg       0.55      0.55      0.55      5176\n","   macro avg       0.44      0.38      0.34      5176\n","weighted avg       0.48      0.55      0.46      5176\n"," samples avg       0.55      0.55      0.55      5176\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e500e64924054c2ea6328ed9dcb8fbd5","version_major":2,"version_minor":0},"text/plain":["Epoch 14:   0%|          | 0/89 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #14 - 7.352932212279992\n","\n"," Scores after 14 on validation:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.3757323685811332\n","\n","Accuracy score for AP - 0.4684431977559607\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.26      0.08      0.12       131\n","           1       0.41      0.45      0.43       253\n","           2       0.53      0.64      0.58       329\n","\n","   micro avg       0.47      0.47      0.47       713\n","   macro avg       0.40      0.39      0.38       713\n","weighted avg       0.44      0.47      0.44       713\n"," samples avg       0.47      0.47      0.47       713\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.29246886562782887\n","\n","Accuracy score for AM - 0.6507713884992987\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.66      0.99      0.79       464\n","           1       0.50      0.01      0.02       166\n","           2       0.33      0.04      0.07        83\n","\n","   micro avg       0.65      0.65      0.65       713\n","   macro avg       0.50      0.35      0.29       713\n","weighted avg       0.58      0.65      0.53       713\n"," samples avg       0.65      0.65      0.65       713\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.33618529867089375\n","\n","Accuracy score for BP - 0.42075736325385693\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.34      0.39       248\n","           1       0.42      0.71      0.52       289\n","           2       0.32      0.06      0.10       176\n","\n","   micro avg       0.42      0.42      0.42       713\n","   macro avg       0.40      0.37      0.34       713\n","weighted avg       0.41      0.42      0.37       713\n"," samples avg       0.42      0.42      0.42       713\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.3187041910949603\n","\n","Accuracy score for BM - 0.3899018232819074\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.44      0.71      0.54       299\n","           1       0.30      0.14      0.19       243\n","           2       0.28      0.19      0.23       171\n","\n","   micro avg       0.39      0.39      0.39       713\n","   macro avg       0.34      0.35      0.32       713\n","weighted avg       0.35      0.39      0.35       713\n"," samples avg       0.39      0.39      0.39       713\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.3654181587543132\n","\n","Accuracy score for GP - 0.42075736325385693\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.41      0.29      0.34       217\n","           1       0.43      0.71      0.54       287\n","           2       0.37      0.15      0.22       209\n","\n","   micro avg       0.42      0.42      0.42       713\n","   macro avg       0.41      0.39      0.37       713\n","weighted avg       0.41      0.42      0.38       713\n"," samples avg       0.42      0.42      0.42       713\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.31126313968590896\n","\n","Accuracy score for GM - 0.4894810659186536\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.52      0.86      0.65       359\n","           1       0.35      0.18      0.23       209\n","           2       0.22      0.03      0.05       145\n","\n","   micro avg       0.49      0.49      0.49       713\n","   macro avg       0.36      0.35      0.31       713\n","weighted avg       0.41      0.49      0.41       713\n"," samples avg       0.49      0.49      0.49       713\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.3527093136201625\n","\n","Accuracy score for DP - 0.5049088359046283\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       114\n","           1       0.40      0.46      0.43       245\n","           2       0.58      0.70      0.63       354\n","\n","   micro avg       0.50      0.50      0.50       713\n","   macro avg       0.32      0.39      0.35       713\n","weighted avg       0.42      0.50      0.46       713\n"," samples avg       0.50      0.50      0.50       713\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.3311513632791047\n","\n","Accuracy score for DM - 0.5610098176718092\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.90      0.72       405\n","           1       0.33      0.01      0.01       153\n","           2       0.34      0.21      0.26       155\n","\n","   micro avg       0.56      0.56      0.56       713\n","   macro avg       0.42      0.37      0.33       713\n","weighted avg       0.48      0.56      0.47       713\n"," samples avg       0.56      0.56      0.56       713\n","\n","Epoch #15\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6508fe7db84742eaac34a5c5b3c968ad","version_major":2,"version_minor":0},"text/plain":["Epoch 15:   0%|          | 0/647 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #15 - 7.070600668324999\n","\n"," Scores after 15 on train:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.4399002818796154\n","\n","Accuracy score for AP - 0.5193199381761978\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.13      0.20      1056\n","           1       0.47      0.53      0.50      1895\n","           2       0.57      0.70      0.63      2225\n","\n","   micro avg       0.52      0.52      0.52      5176\n","   macro avg       0.49      0.45      0.44      5176\n","weighted avg       0.51      0.52      0.49      5176\n"," samples avg       0.52      0.52      0.52      5176\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.2884391482923736\n","\n","Accuracy score for AM - 0.6192040185471407\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.62      0.99      0.76      3184\n","           1       0.70      0.01      0.01      1268\n","           2       0.49      0.05      0.09       724\n","\n","   micro avg       0.62      0.62      0.62      5176\n","   macro avg       0.60      0.35      0.29      5176\n","weighted avg       0.62      0.62      0.49      5176\n"," samples avg       0.62      0.62      0.62      5176\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.39106878915772114\n","\n","Accuracy score for BP - 0.4766228748068006\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.42      0.46      1707\n","           1       0.47      0.76      0.58      2172\n","           2       0.50      0.08      0.14      1297\n","\n","   micro avg       0.48      0.48      0.48      5176\n","   macro avg       0.49      0.42      0.39      5176\n","weighted avg       0.49      0.48      0.43      5176\n"," samples avg       0.48      0.48      0.48      5176\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.4139566100578412\n","\n","Accuracy score for BM - 0.46947449768160743\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.49      0.76      0.59      2178\n","           1       0.45      0.25      0.32      1625\n","           2       0.43      0.27      0.33      1373\n","\n","   micro avg       0.47      0.47      0.47      5176\n","   macro avg       0.45      0.43      0.41      5176\n","weighted avg       0.46      0.47      0.44      5176\n"," samples avg       0.47      0.47      0.47      5176\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.4248225546468865\n","\n","Accuracy score for GP - 0.46445131375579596\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.38      0.41      1522\n","           1       0.46      0.72      0.56      2081\n","           2       0.49      0.22      0.30      1573\n","\n","   micro avg       0.46      0.46      0.46      5176\n","   macro avg       0.47      0.44      0.42      5176\n","weighted avg       0.47      0.46      0.44      5176\n"," samples avg       0.46      0.46      0.46      5176\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.3362727984106328\n","\n","Accuracy score for GM - 0.5081143740340031\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.53      0.89      0.67      2544\n","           1       0.39      0.19      0.26      1590\n","           2       0.41      0.05      0.08      1042\n","\n","   micro avg       0.51      0.51      0.51      5176\n","   macro avg       0.44      0.38      0.34      5176\n","weighted avg       0.46      0.51      0.42      5176\n"," samples avg       0.51      0.51      0.51      5176\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.3821496036611445\n","\n","Accuracy score for DP - 0.5390262751159196\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       786\n","           1       0.47      0.54      0.50      1909\n","           2       0.59      0.71      0.65      2481\n","\n","   micro avg       0.54      0.54      0.54      5176\n","   macro avg       0.35      0.42      0.38      5176\n","weighted avg       0.46      0.54      0.49      5176\n"," samples avg       0.54      0.54      0.54      5176\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.3500896093872757\n","\n","Accuracy score for DM - 0.5531298299845441\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.58      0.92      0.71      2781\n","           1       0.46      0.03      0.05      1159\n","           2       0.41      0.23      0.29      1236\n","\n","   micro avg       0.55      0.55      0.55      5176\n","   macro avg       0.48      0.39      0.35      5176\n","weighted avg       0.51      0.55      0.46      5176\n"," samples avg       0.55      0.55      0.55      5176\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b7223c4083e049839bd4d7a05fa3b5f4","version_major":2,"version_minor":0},"text/plain":["Epoch 15:   0%|          | 0/89 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","Mean Loss after epoch #15 - 7.356078927129863\n","\n"," Scores after 15 on validation:\n","Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.391371351464254\n","\n","Accuracy score for AP - 0.49368863955119213\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.31      0.07      0.11       131\n","           1       0.42      0.49      0.45       253\n","           2       0.56      0.67      0.61       329\n","\n","   micro avg       0.49      0.49      0.49       713\n","   macro avg       0.43      0.41      0.39       713\n","weighted avg       0.47      0.49      0.46       713\n"," samples avg       0.49      0.49      0.49       713\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.2828983256132176\n","\n","Accuracy score for AM - 0.6437587657784011\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.65      0.98      0.78       464\n","           1       0.00      0.00      0.00       166\n","           2       0.30      0.04      0.06        83\n","\n","   micro avg       0.64      0.64      0.64       713\n","   macro avg       0.32      0.34      0.28       713\n","weighted avg       0.46      0.64      0.52       713\n"," samples avg       0.64      0.64      0.64       713\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.3367374600626943\n","\n","Accuracy score for BP - 0.42496493688639553\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.29      0.35       248\n","           1       0.43      0.76      0.54       289\n","           2       0.31      0.07      0.11       176\n","\n","   micro avg       0.42      0.42      0.42       713\n","   macro avg       0.40      0.37      0.34       713\n","weighted avg       0.41      0.42      0.37       713\n"," samples avg       0.42      0.42      0.42       713\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.3407569282569282\n","\n","Accuracy score for BM - 0.41514726507713884\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.75      0.56       299\n","           1       0.39      0.17      0.24       243\n","           2       0.30      0.18      0.23       171\n","\n","   micro avg       0.42      0.42      0.42       713\n","   macro avg       0.38      0.37      0.34       713\n","weighted avg       0.39      0.42      0.37       713\n"," samples avg       0.42      0.42      0.42       713\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.3465801187142284\n","\n","Accuracy score for GP - 0.41374474053295934\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.42      0.25      0.31       217\n","           1       0.42      0.75      0.54       287\n","           2       0.36      0.13      0.19       209\n","\n","   micro avg       0.41      0.41      0.41       713\n","   macro avg       0.40      0.37      0.35       713\n","weighted avg       0.40      0.41      0.37       713\n"," samples avg       0.41      0.41      0.41       713\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.30143031998601155\n","\n","Accuracy score for GM - 0.4642356241234222\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.51      0.83      0.63       359\n","           1       0.21      0.09      0.13       209\n","           2       0.43      0.09      0.15       145\n","\n","   micro avg       0.46      0.46      0.46       713\n","   macro avg       0.38      0.34      0.30       713\n","weighted avg       0.40      0.46      0.38       713\n"," samples avg       0.46      0.46      0.46       713\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.36035242859031785\n","\n","Accuracy score for DP - 0.517531556802244\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       114\n","           1       0.40      0.46      0.43       245\n","           2       0.59      0.72      0.65       354\n","\n","   micro avg       0.52      0.52      0.52       713\n","   macro avg       0.33      0.39      0.36       713\n","weighted avg       0.43      0.52      0.47       713\n"," samples avg       0.52      0.52      0.52       713\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.34501434720229557\n","\n","Accuracy score for DM - 0.5708274894810659\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.91      0.73       405\n","           1       0.29      0.01      0.02       153\n","           2       0.38      0.23      0.28       155\n","\n","   micro avg       0.57      0.57      0.57       713\n","   macro avg       0.42      0.38      0.35       713\n","weighted avg       0.49      0.57      0.48       713\n"," samples avg       0.57      0.57      0.57       713\n","\n"]}],"source":["valid_stats = []\n","lr=2e-4\n","best_valid_loss = float('inf')\n","optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n","criterion = nn.CrossEntropyLoss().to(device)\n","global lr_list\n","lr_list = []\n","global scheduler\n","total_steps = len(train_dataset) * epochs\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                num_warmup_steps=int(total_steps * 0.1),\n","                                                num_training_steps=total_steps)\n","\n","# for each epoch\n","for epoch in range(epochs):\n","    # train\n","\n","    try:\n","        train(model, train_dataset, device, optimizer, criterion, epoch, curc_indexes)\n","          # # validate\n","        \n","        valid_stats = validating(model, val_dataset, device, optimizer, criterion, epoch, curc_indexes )\n","\n","        if valid_stats[epoch]['Val Loss'] < best_valid_loss:\n","            print(f\"Best validation loss - {valid_stats[epoch]['Val Loss']}\")\n","            best_valid_loss = valid_stats[epoch]['Val Loss']\n","            \n","            name_to_save = f'model_baseline_basic_all_circ'\n","            if os.path.isfile('results/'+name_to_save+'.pth'):\n","                    os.remove('results/'+name_to_save+'.pth')\n","                    torch.save(model.state_dict(), 'results/'+name_to_save+'.pth')\n","            else:\n","                    if not os.path.isdir('results'):\n","                        os.mkdir('results')\n","                    torch.save(model.state_dict(), 'results/'+name_to_save+'.pth')\n","#                     else:\n","#                         os.mkdir('results')\n","    except KeyboardInterrupt:\n","        break"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T11:28:21.973904Z","iopub.status.busy":"2023-05-27T11:28:21.973525Z","iopub.status.idle":"2023-05-27T11:28:21.982069Z","shell.execute_reply":"2023-05-27T11:28:21.980902Z","shell.execute_reply.started":"2023-05-27T11:28:21.973869Z"},"id":"Zde3NDgDMa8z","trusted":true},"outputs":[],"source":["def test(data_loader, device, class_indexes):\n","\n","    val_losses, val_labels, val_predictions = [], [], []\n","    model.load_state_dict(torch.load('results/model_baseline_basic_all_circ.pth'))\n","    \n","\n","    model.eval()\n","\n","    for _, data in enumerate(data_loader, 0):\n","          \n","          input_ids = data[\"source_ids\"].to(device)\n","          attention_mask = data[\"source_mask\"].to(device)\n","          labels = data['labels'].to(device)\n","\n","          with torch.no_grad():\n","              pred = model(input_ids, attention_mask)\n","          predict = torch.log_softmax(pred, dim=1)\n","\n","          \n","          resulting_output = analysing_logits(predict.detach().cpu().numpy(), class_indexes)\n","\n","          val_labels.extend(labels.cpu().detach().numpy())\n","          val_predictions.extend(resulting_output)\n","\n","\n","\n","    show_metrics(val_labels, val_predictions, class_indexes)\n","    # print('F1 score after epoch #{0} on validation - {1}\\n'.format(str(n_epoch + 1), f1_score(val_labels, val_predictions, average='macro'))"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.execute_input":"2023-05-27T11:28:21.984209Z","iopub.status.busy":"2023-05-27T11:28:21.983586Z","iopub.status.idle":"2023-05-27T11:29:18.950599Z","shell.execute_reply":"2023-05-27T11:29:18.949531Z","shell.execute_reply.started":"2023-05-27T11:28:21.984176Z"},"executionInfo":{"elapsed":47711,"status":"ok","timestamp":1684431823152,"user":{"displayName":"Help Study","userId":"07310851891543285849"},"user_tz":-180},"id":"jJIUyE2hNd4z","outputId":"cdc64ea2-8694-43bd-aa18-4e38bb3c7fad","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.43920387894783414\n","\n","Accuracy score for AP - 0.5139103554868625\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.16      0.24      1055\n","           1       0.48      0.43      0.45      1895\n","           2       0.54      0.76      0.63      2226\n","\n","   micro avg       0.51      0.51      0.51      5176\n","   macro avg       0.49      0.45      0.44      5176\n","weighted avg       0.50      0.51      0.48      5176\n"," samples avg       0.51      0.51      0.51      5176\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.2638610253314944\n","\n","Accuracy score for AM - 0.6170788253477589\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.62      1.00      0.76      3186\n","           1       0.50      0.00      0.00      1267\n","           2       0.62      0.01      0.03       723\n","\n","   micro avg       0.62      0.62      0.62      5176\n","   macro avg       0.58      0.34      0.26      5176\n","weighted avg       0.59      0.62      0.47      5176\n"," samples avg       0.62      0.62      0.62      5176\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.3805315600019672\n","\n","Accuracy score for BP - 0.4679289026275116\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.50      0.49      1707\n","           1       0.47      0.69      0.55      2172\n","           2       0.50      0.06      0.10      1297\n","\n","   micro avg       0.47      0.47      0.47      5176\n","   macro avg       0.48      0.42      0.38      5176\n","weighted avg       0.48      0.47      0.42      5176\n"," samples avg       0.47      0.47      0.47      5176\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.41225390704632175\n","\n","Accuracy score for BM - 0.4715996908809892\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.49      0.76      0.60      2177\n","           1       0.50      0.16      0.25      1626\n","           2       0.41      0.38      0.39      1373\n","\n","   micro avg       0.47      0.47      0.47      5176\n","   macro avg       0.47      0.43      0.41      5176\n","weighted avg       0.47      0.47      0.43      5176\n"," samples avg       0.47      0.47      0.47      5176\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.41626693511815366\n","\n","Accuracy score for GP - 0.46889489953632146\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.46      0.46      1520\n","           1       0.47      0.72      0.57      2081\n","           2       0.52      0.14      0.22      1575\n","\n","   micro avg       0.47      0.47      0.47      5176\n","   macro avg       0.48      0.44      0.42      5176\n","weighted avg       0.48      0.47      0.43      5176\n"," samples avg       0.47      0.47      0.47      5176\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.3483633922863317\n","\n","Accuracy score for GM - 0.5063755795981453\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.56      0.82      0.66      2545\n","           1       0.37      0.32      0.35      1590\n","           2       0.53      0.02      0.04      1041\n","\n","   micro avg       0.51      0.51      0.51      5176\n","   macro avg       0.48      0.39      0.35      5176\n","weighted avg       0.49      0.51      0.44      5176\n"," samples avg       0.51      0.51      0.51      5176\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.3677031493912753\n","\n","Accuracy score for DP - 0.5367078825347759\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       784\n","           1       0.48      0.41      0.44      1909\n","           2       0.56      0.81      0.66      2483\n","\n","   micro avg       0.54      0.54      0.54      5176\n","   macro avg       0.35      0.40      0.37      5176\n","weighted avg       0.45      0.54      0.48      5176\n"," samples avg       0.54      0.54      0.54      5176\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.31024807537758753\n","\n","Accuracy score for DM - 0.5513910355486863\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.56      0.97      0.71      2780\n","           1       0.42      0.05      0.08      1159\n","           2       0.48      0.08      0.14      1237\n","\n","   micro avg       0.55      0.55      0.55      5176\n","   macro avg       0.49      0.37      0.31      5176\n","weighted avg       0.51      0.55      0.43      5176\n"," samples avg       0.55      0.55      0.55      5176\n","\n"]}],"source":["test(train_dataset, device, curc_indexes)"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-05-27T11:29:18.953576Z","iopub.status.busy":"2023-05-27T11:29:18.953248Z","iopub.status.idle":"2023-05-27T11:29:27.358786Z","shell.execute_reply":"2023-05-27T11:29:27.357721Z","shell.execute_reply.started":"2023-05-27T11:29:18.953545Z"},"executionInfo":{"elapsed":7841,"status":"ok","timestamp":1684431859515,"user":{"displayName":"Help Study","userId":"07310851891543285849"},"user_tz":-180},"id":"hmplsmgXNkUh","outputId":"9bcf9035-2c71-4ece-d3b5-1ae1c6e3d8de","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.3843847784348004\n","\n","Accuracy score for AP - 0.4796633941093969\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.30      0.10      0.15       131\n","           1       0.43      0.38      0.40       253\n","           2       0.52      0.71      0.60       329\n","\n","   micro avg       0.48      0.48      0.48       713\n","   macro avg       0.42      0.40      0.38       713\n","weighted avg       0.45      0.48      0.45       713\n"," samples avg       0.48      0.48      0.48       713\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.2628150665533843\n","\n","Accuracy score for AM - 0.6507713884992987\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.65      1.00      0.79       464\n","           1       0.00      0.00      0.00       166\n","           2       0.00      0.00      0.00        83\n","\n","   micro avg       0.65      0.65      0.65       713\n","   macro avg       0.22      0.33      0.26       713\n","weighted avg       0.42      0.65      0.51       713\n"," samples avg       0.65      0.65      0.65       713\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.3442414881193941\n","\n","Accuracy score for BP - 0.44039270687237025\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.47      0.46       248\n","           1       0.43      0.67      0.53       289\n","           2       0.33      0.02      0.04       176\n","\n","   micro avg       0.44      0.44      0.44       713\n","   macro avg       0.41      0.39      0.34       713\n","weighted avg       0.42      0.44      0.39       713\n"," samples avg       0.44      0.44      0.44       713\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.33652445663329456\n","\n","Accuracy score for BM - 0.4067321178120617\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.73      0.57       299\n","           1       0.36      0.14      0.20       243\n","           2       0.26      0.23      0.24       171\n","\n","   micro avg       0.41      0.41      0.41       713\n","   macro avg       0.36      0.37      0.34       713\n","weighted avg       0.38      0.41      0.36       713\n"," samples avg       0.41      0.41      0.41       713\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.3473685233419803\n","\n","Accuracy score for GP - 0.41935483870967744\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.40      0.34      0.37       217\n","           1       0.43      0.72      0.54       287\n","           2       0.39      0.08      0.13       209\n","\n","   micro avg       0.42      0.42      0.42       713\n","   macro avg       0.41      0.38      0.35       713\n","weighted avg       0.41      0.42      0.37       713\n"," samples avg       0.42      0.42      0.42       713\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.31290333853860613\n","\n","Accuracy score for GM - 0.485273492286115\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.54      0.82      0.65       359\n","           1       0.32      0.24      0.28       209\n","           2       0.17      0.01      0.01       145\n","\n","   micro avg       0.49      0.49      0.49       713\n","   macro avg       0.34      0.36      0.31       713\n","weighted avg       0.40      0.49      0.41       713\n"," samples avg       0.49      0.49      0.49       713\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.34038601614902114\n","\n","Accuracy score for DP - 0.5105189340813464\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       114\n","           1       0.41      0.34      0.37       245\n","           2       0.55      0.79      0.65       354\n","\n","   micro avg       0.51      0.51      0.51       713\n","   macro avg       0.32      0.38      0.34       713\n","weighted avg       0.41      0.51      0.45       713\n"," samples avg       0.51      0.51      0.51       713\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.3010681586014628\n","\n","Accuracy score for DM - 0.5750350631136045\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.58      0.98      0.73       405\n","           1       0.50      0.04      0.07       153\n","           2       0.41      0.06      0.10       155\n","\n","   micro avg       0.58      0.58      0.58       713\n","   macro avg       0.50      0.36      0.30       713\n","weighted avg       0.53      0.58      0.45       713\n"," samples avg       0.58      0.58      0.58       713\n","\n"]}],"source":["test(val_dataset, device, curc_indexes)"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-05-27T11:29:27.360986Z","iopub.status.busy":"2023-05-27T11:29:27.360613Z","iopub.status.idle":"2023-05-27T11:29:34.295310Z","shell.execute_reply":"2023-05-27T11:29:34.294266Z","shell.execute_reply.started":"2023-05-27T11:29:27.360953Z"},"executionInfo":{"elapsed":6638,"status":"ok","timestamp":1684431872890,"user":{"displayName":"Help Study","userId":"07310851891543285849"},"user_tz":-180},"id":"UNk1S5m9NqLW","outputId":"e3002ea7-dc9c-463e-8607-6c2381982d5c","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Scores for AP\n","==================\n","\n","Macro F1 score for AP - 0.4058067282189037\n","\n","Accuracy score for AP - 0.4854202401372213\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.13      0.21       114\n","           1       0.45      0.39      0.42       214\n","           2       0.50      0.73      0.59       255\n","\n","   micro avg       0.49      0.49      0.49       583\n","   macro avg       0.47      0.41      0.41       583\n","weighted avg       0.48      0.49      0.45       583\n"," samples avg       0.49      0.49      0.49       583\n","\n","Scores for AM\n","==================\n","\n","Macro F1 score for AM - 0.26942027794410595\n","\n","Accuracy score for AM - 0.6466552315608919\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.65      1.00      0.79       376\n","           1       0.00      0.00      0.00       120\n","           2       0.50      0.01      0.02        87\n","\n","   micro avg       0.65      0.65      0.65       583\n","   macro avg       0.38      0.34      0.27       583\n","weighted avg       0.49      0.65      0.51       583\n"," samples avg       0.65      0.65      0.65       583\n","\n","Scores for BP\n","==================\n","\n","Macro F1 score for BP - 0.32275873431181606\n","\n","Accuracy score for BP - 0.4013722126929674\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.41      0.40      0.40       192\n","           1       0.40      0.64      0.50       235\n","           2       0.30      0.04      0.07       156\n","\n","   micro avg       0.40      0.40      0.40       583\n","   macro avg       0.37      0.36      0.32       583\n","weighted avg       0.38      0.40      0.35       583\n"," samples avg       0.40      0.40      0.40       583\n","\n","Scores for BM\n","==================\n","\n","Macro F1 score for BM - 0.33596228321798177\n","\n","Accuracy score for BM - 0.3979416809605489\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.73      0.55       231\n","           1       0.33      0.12      0.18       196\n","           2       0.30      0.26      0.28       156\n","\n","   micro avg       0.40      0.40      0.40       583\n","   macro avg       0.36      0.37      0.34       583\n","weighted avg       0.37      0.40      0.35       583\n"," samples avg       0.40      0.40      0.40       583\n","\n","Scores for GP\n","==================\n","\n","Macro F1 score for GP - 0.34060596558318723\n","\n","Accuracy score for GP - 0.3910806174957118\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.37      0.35      0.36       168\n","           1       0.41      0.63      0.50       238\n","           2       0.35      0.11      0.17       177\n","\n","   micro avg       0.39      0.39      0.39       583\n","   macro avg       0.38      0.36      0.34       583\n","weighted avg       0.38      0.39      0.36       583\n"," samples avg       0.39      0.39      0.39       583\n","\n","Scores for GM\n","==================\n","\n","Macro F1 score for GM - 0.3134396900748709\n","\n","Accuracy score for GM - 0.4699828473413379\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.52      0.81      0.63       283\n","           1       0.31      0.25      0.28       173\n","           2       0.40      0.02      0.03       127\n","\n","   micro avg       0.47      0.47      0.47       583\n","   macro avg       0.41      0.36      0.31       583\n","weighted avg       0.43      0.47      0.40       583\n"," samples avg       0.47      0.47      0.47       583\n","\n","Scores for DP\n","==================\n","\n","Macro F1 score for DP - 0.3570747411014674\n","\n","Accuracy score for DP - 0.5283018867924528\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00        86\n","           1       0.44      0.38      0.41       209\n","           2       0.57      0.79      0.66       288\n","\n","   micro avg       0.53      0.53      0.53       583\n","   macro avg       0.34      0.39      0.36       583\n","weighted avg       0.44      0.53      0.47       583\n"," samples avg       0.53      0.53      0.53       583\n","\n","Scores for DM\n","==================\n","\n","Macro F1 score for DM - 0.2974160758732729\n","\n","Accuracy score for DM - 0.5403087478559176\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.54      0.97      0.70       309\n","           1       0.30      0.02      0.04       141\n","           2       0.55      0.09      0.15       133\n","\n","   micro avg       0.54      0.54      0.54       583\n","   macro avg       0.46      0.36      0.30       583\n","weighted avg       0.49      0.54      0.41       583\n"," samples avg       0.54      0.54      0.54       583\n","\n"]}],"source":["test(test_dataset, device, curc_indexes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tX1t0ZFyAeja"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Nr72f9O3ajK"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNmAOs4xqSToG+0piQFuAt/","gpuType":"T4","mount_file_id":"1JbeHfYbv6XE5v8oylrD8SVVQE4bzwOzO","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"01314b46d0c14605b4493faf9049a28a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08a70ddab74e44509ff38faeaa2accf5","placeholder":"​","style":"IPY_MODEL_5571b8593f364f49932a59de33b1714c","value":" 90/? [00:06&lt;00:00, 14.44it/s, loss=8.1]"}},"01e11ca1e93844fd98a9e4b412c51ffe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0237dc3eddd245b9bb5b51b162331e71":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbefb8047f4b417cb75abc46f79646ad","placeholder":"​","style":"IPY_MODEL_15dcc6ab1dc8445eb1d600136e0e5f65","value":"Epoch 2: "}},"04b29c6cd93f4e89898fb561654f2b16":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7de7487aca8045bc875545e6e7bb9d15","placeholder":"​","style":"IPY_MODEL_a129f7458f5b4ac798e88731bee9c9f6","value":" 647/647 [02:27&lt;00:00,  4.47it/s, loss=5.07]"}},"074c3946d2fd4047ac86fc6f44a5e442":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7804c9a3fc044ed9c62195541cd2fb6","placeholder":"​","style":"IPY_MODEL_21e8f0a04cda45868c8e06b63e5325d7","value":" 647/647 [02:28&lt;00:00,  4.22it/s, loss=7.09]"}},"08a70ddab74e44509ff38faeaa2accf5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09c86c546d3743569cd2f23b598b1edd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09d85b49c7b34ba09db62a13bf7f12e2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a69129f00564573a571e8ae645c4d1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fcc302b8fb224862bf9651b6319963f8","placeholder":"​","style":"IPY_MODEL_26d66b91f7964eb1a8d08b6dc35c2744","value":"Epoch 5: "}},"0a74807e64274b0abe938bb35ae84822":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfbf03e60b824b07b3bd488405685505","placeholder":"​","style":"IPY_MODEL_8dfdf32e65a247bba25614e466808965","value":" 90/? [00:06&lt;00:00, 14.68it/s, loss=7.38]"}},"0ace271cd43049b6b42079d2a1180356":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c03c6ad3764c4c8597c32bb1ffab4248","placeholder":"​","style":"IPY_MODEL_a149d8f66aaa4a99a61ccf75e6ce5750","value":"Epoch 3: "}},"0b0cbd6f2bb24186855c99c514153d99":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9c2fdfb3bb64285a1b66b2859ee37c1","max":647,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d192f2554a5544138aadf19d4553fb4c","value":647}},"0ed740e831aa43c9b82f17ef26a62eff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f02fb31f1cb4c06b0a619d5e908238b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fe68a59548c4201924d43973a80a99c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"101f2b6d214a4b2488670f716c866e8e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f8d0e4b8152468287abfe4d4ce3484c","max":89,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cacbf373b25f4bb09c96361d3aa98b66","value":58}},"135667e9429a45efa66b7a72e7c5c5d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13973076a6e14bbeae99bdc319914622":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_13ba8b614aa2404bab8b92fb2ccad0ef","max":647,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7fdeb4a53e8d42178a135770df7f4cdb","value":647}},"13ba8b614aa2404bab8b92fb2ccad0ef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14757c04f5634bae956e4b3bf2840149":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15dcc6ab1dc8445eb1d600136e0e5f65":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"198081598cef4ee3a6fd87d4abf9ed5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cbc7d6853804e9b94dabe7c8a7e2e5f","placeholder":"​","style":"IPY_MODEL_f02279245d744fcea4ba1360dc9c035b","value":" 90/? [00:06&lt;00:00, 14.59it/s, loss=9.14]"}},"199f99e4a079408390595a2ec8d09607":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a9f67202c814019972d721a809b63db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1c47006dfa214c5cbdf4ec74445c7ec7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d446447e40284fc99f9261a41f53dd35","IPY_MODEL_0b0cbd6f2bb24186855c99c514153d99","IPY_MODEL_aad76e6aa36b4619a6708b380a59062f"],"layout":"IPY_MODEL_54655892111943429a026e4930c4380d"}},"1c8c819d3e5b4e399589b7ed216f43c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f6701140e414b5582f7e5b0f7656ee3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ed122b0d09c47d2bcb2134bfb6325cd","IPY_MODEL_101f2b6d214a4b2488670f716c866e8e","IPY_MODEL_cb6f34d2ddb94d8cb82a198561cd1a43"],"layout":"IPY_MODEL_8acaea8081a54d368b6f333fd05b8f6a"}},"205aece5e14a41168c43a8660fc03291":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_92fd763c82c446ff8bdda05ec0c777ae","max":89,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2e50311e632417a9f6405da24e57dbe","value":89}},"214dd526c7a44b5faa4e480c83e59bb1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21e8f0a04cda45868c8e06b63e5325d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"240107dd617c482180ae3eb8b119d8a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8f631be8707845afa8dfc9f102be3478","IPY_MODEL_6c876da67fd64bc08cf93ad32967a10e","IPY_MODEL_198081598cef4ee3a6fd87d4abf9ed5c"],"layout":"IPY_MODEL_5e77f0103ec849bc98824487c39765e6"}},"24eae4dbaeeb4787939c27385dc8e2ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2525e07d18c4400eb8f9e4fb6924e6b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0237dc3eddd245b9bb5b51b162331e71","IPY_MODEL_81262bbfdf104bb59eea33752832645e","IPY_MODEL_76029cd5b5c44f0f8ee27040cd4c794a"],"layout":"IPY_MODEL_630405bfd22943509ea0d26bc0e60db6"}},"2634a606fe094c438b75e897947bfc54":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_49d2528114ff4d9eb0e6fde129af2361","max":647,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1a9f67202c814019972d721a809b63db","value":647}},"2690c9c8e09d4fe1906204108950acd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_667a61e654114c4f919e94786b1ca9c8","IPY_MODEL_13973076a6e14bbeae99bdc319914622","IPY_MODEL_47fdc6325b1c4950857c392c85989aa5"],"layout":"IPY_MODEL_214dd526c7a44b5faa4e480c83e59bb1"}},"26d66b91f7964eb1a8d08b6dc35c2744":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2789881bf43a4ae7b193c04243f2d9dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_84f8b81e08a64c6f9d480d702cf3d147","IPY_MODEL_205aece5e14a41168c43a8660fc03291","IPY_MODEL_5837efdcbf584d84b6201b00129d3991"],"layout":"IPY_MODEL_0fe68a59548c4201924d43973a80a99c"}},"2cfb1da74e17469ba16666334ffd80c2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e9abf059107470481d78bc4fb61e40f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f69fb97844344fb88e1f9c77f8b52c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2f8d0e4b8152468287abfe4d4ce3484c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31754f22a11e45638046f6fcb8f3ecfd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc28a233b1b144f19a1c3653c5dfc720","placeholder":"​","style":"IPY_MODEL_5d53f78b6cbd4cb1b18cab6a0eccfde5","value":"Epoch 7: 100%"}},"31d59aa4ed6d447288ef1cf7d0571055":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33afe891341145a2b6dd3378c2d961ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3605c2e2e14645178dfd6a76cc4a6c2f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"374b55d9ffff415b8b42b4ba6f71e638":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_199f99e4a079408390595a2ec8d09607","placeholder":"​","style":"IPY_MODEL_71ec38b6d6ac4a13a99dda421c180ef6","value":" 11/647 [00:53&lt;02:26,  4.35it/s, loss=3.98]"}},"435bf8c859504587918e4ab10f2a4d7a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0ace271cd43049b6b42079d2a1180356","IPY_MODEL_7972e2ac1a9044a3962a3eba7cc1355a","IPY_MODEL_9b4eb706863544229e9491daa10ce1a3"],"layout":"IPY_MODEL_f1e8316b3f7f4af3a0aca012bf3f92ae"}},"45497ea71f79446c8b4e0341d4f7216b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33afe891341145a2b6dd3378c2d961ae","placeholder":"​","style":"IPY_MODEL_7b0feaff93c74588b743e8d2ff597142","value":"Epoch 4: 100%"}},"4621bbcb3a844f61b2e6581b3c26bc9d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6b754494044c40eaa1628e0a72764fb8","IPY_MODEL_6eddb37bc7ee4dfdafdb1dea1f34fd26","IPY_MODEL_374b55d9ffff415b8b42b4ba6f71e638"],"layout":"IPY_MODEL_09d85b49c7b34ba09db62a13bf7f12e2"}},"47fdc6325b1c4950857c392c85989aa5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8eba7d65c9141549ee3300637d2964e","placeholder":"​","style":"IPY_MODEL_4b08819b15494d9daa3915b57c0dbadd","value":" 647/647 [02:27&lt;00:00,  4.28it/s, loss=7.57]"}},"49635cbec7cf4f0bb993cc6aef3a3931":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8986cf621164f83ad1ca3283ceef894","max":89,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a6c74b8db12e485cbf07978b711ac644","value":89}},"49d2528114ff4d9eb0e6fde129af2361":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49fad36a492143c98111439a24a406ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b08819b15494d9daa3915b57c0dbadd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4bd46a3629664f8aab8c3da3f3e14914":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ce8cb1091d8468885e2d9163db9712e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9d2cb2454a14e3a85979f042ac333cb","placeholder":"​","style":"IPY_MODEL_d797b54a29364543bee3af18ccc5a7d6","value":"Epoch 8: 100%"}},"4ed122b0d09c47d2bcb2134bfb6325cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_788246ecfccb455d849e589cfa72265f","placeholder":"​","style":"IPY_MODEL_c3a533f706d447e282fbdcbe102ef047","value":"Epoch 4:  64%"}},"4f1ddb8adb1348ff8b1201710d2b3e96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3605c2e2e14645178dfd6a76cc4a6c2f","max":647,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ed378a5d49e44d57bab4f20bc2df6ad8","value":647}},"4f4826946a024e8bbb1b89ce76b1ef0f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54655892111943429a026e4930c4380d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5571b8593f364f49932a59de33b1714c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"558384c7699a44238e65e24f13b4fda1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45497ea71f79446c8b4e0341d4f7216b","IPY_MODEL_fa5d5d5784754556bc936841cb472a23","IPY_MODEL_afe6e88195b3483eb67939b3893bafe5"],"layout":"IPY_MODEL_a99d8b51d1af44c09a5f2eb01d52bfa0"}},"5837efdcbf584d84b6201b00129d3991":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0e3277ada894340b222941bc0d8b5bc","placeholder":"​","style":"IPY_MODEL_5eef3462adc5486cbe0f402b746abb19","value":" 90/? [00:06&lt;00:00, 13.92it/s, loss=8.61]"}},"59bd7e4fdf514ef08981f668fe1f6de1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b7d285d5da94e4d9e2803f818ebf662","max":89,"min":0,"orientation":"horizontal","style":"IPY_MODEL_621784821d53419193dd8259dc3ee973","value":89}},"5a562566b50e4200af4465fe6aaa2ddc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4dd62547f43442e8588292cfaaf7a98","max":647,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f69fb97844344fb88e1f9c77f8b52c9","value":647}},"5d17388a3d1f454d8a8cdc828a189c67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d53f78b6cbd4cb1b18cab6a0eccfde5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e77f0103ec849bc98824487c39765e6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5eef3462adc5486cbe0f402b746abb19":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"621784821d53419193dd8259dc3ee973":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"630405bfd22943509ea0d26bc0e60db6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"667a61e654114c4f919e94786b1ca9c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef3ff9c122ce4407863d74957b80fb32","placeholder":"​","style":"IPY_MODEL_971e6e6500e14f6193401a583d573ca7","value":"Epoch 1: 100%"}},"697a625a986542c3bd7750e570644689":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b754494044c40eaa1628e0a72764fb8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d08aea6a09c745af830236ca3a0ec649","placeholder":"​","style":"IPY_MODEL_eea03aa3c5274be4b5efd77f8ebcd666","value":"Epoch 9:   2%"}},"6c876da67fd64bc08cf93ad32967a10e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab44e921a79447e18edae0c9faf50673","max":89,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c3b4c437718743fb8f77a2910fe5b110","value":89}},"6eddb37bc7ee4dfdafdb1dea1f34fd26":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_863ecf4086bc41289b0e9578217cd2ff","max":647,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c222cad4fecf407191ce00ba1c819380","value":11}},"71ec38b6d6ac4a13a99dda421c180ef6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"747602191bca49a29cdf2f4e875ab0e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74c8109dfb5f48f2b960dbda084e8453":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76029cd5b5c44f0f8ee27040cd4c794a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b4804c2c28a47fea27a58b38781f60d","placeholder":"​","style":"IPY_MODEL_135667e9429a45efa66b7a72e7c5c5d7","value":" 90/? [00:06&lt;00:00, 14.76it/s, loss=7.35]"}},"772998a2cdf748e38d766c9b451e5afa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"788246ecfccb455d849e589cfa72265f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"791e3a42867144869bb48e741245fedf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7972e2ac1a9044a3962a3eba7cc1355a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ed740e831aa43c9b82f17ef26a62eff","max":89,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f9969524006349c88862de26318b4f94","value":89}},"7b0feaff93c74588b743e8d2ff597142":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b4804c2c28a47fea27a58b38781f60d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b7d285d5da94e4d9e2803f818ebf662":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7da25d6d6a5a4907b516687eddf0a2f4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7de7487aca8045bc875545e6e7bb9d15":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e09b6ab3a8b41eb9b64ee340f36eaf0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b481e18ba2d64333a5c9d0ce0c56ac9b","placeholder":"​","style":"IPY_MODEL_ee91356df2aa4357a8abc23cc3e8333d","value":" 647/647 [02:27&lt;00:00,  4.45it/s, loss=5.59]"}},"7fdeb4a53e8d42178a135770df7f4cdb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"81262bbfdf104bb59eea33752832645e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cce82d99d5d44d3b9c2d09b6a8deeb77","max":89,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a7bc8d475ba7471dbd4bb07022ad616a","value":89}},"84f8b81e08a64c6f9d480d702cf3d147":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7da25d6d6a5a4907b516687eddf0a2f4","placeholder":"​","style":"IPY_MODEL_b173826cc3524845b9f0a032fd4862a4","value":"Epoch 7: "}},"863ecf4086bc41289b0e9578217cd2ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89abb9ad964a4bf9a0b6b9b94896f255":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8acaea8081a54d368b6f333fd05b8f6a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cfcc130abe24f688655dcccca3c1119":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d7c87ec62024dd9bf2a5cdc66a4f3dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cfb1da74e17469ba16666334ffd80c2","placeholder":"​","style":"IPY_MODEL_4bd46a3629664f8aab8c3da3f3e14914","value":"Epoch 1: "}},"8dfdf32e65a247bba25614e466808965":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f2fea6de81c486d8e40fc9180e65312":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f631be8707845afa8dfc9f102be3478":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3fb1acae760427f80277168b263a1e4","placeholder":"​","style":"IPY_MODEL_c574667dad254c8e8d92468673c89eea","value":"Epoch 8: "}},"92fd763c82c446ff8bdda05ec0c777ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"971e6e6500e14f6193401a583d573ca7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b4eb706863544229e9491daa10ce1a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4ea4e4e6bb2427d9a2a864de5a23f3c","placeholder":"​","style":"IPY_MODEL_ebbc06aaec294aba8222536ab39e2647","value":" 90/? [00:06&lt;00:00, 14.43it/s, loss=7.34]"}},"9be4872088484fa4aa9e66e50f4934eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9bfc54d8ba2141ea8c4e5d3e54ca0aba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31d59aa4ed6d447288ef1cf7d0571055","placeholder":"​","style":"IPY_MODEL_d51b9cb8413d4c6c96fa23409f2c8b83","value":"Epoch 3: 100%"}},"9cbc7d6853804e9b94dabe7c8a7e2e5f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a129f7458f5b4ac798e88731bee9c9f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a149d8f66aaa4a99a61ccf75e6ce5750":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4a1c6f345384e5199d58908b416ac83":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0a69129f00564573a571e8ae645c4d1b","IPY_MODEL_d62896e730604f07ad4cdc2a7fcad328","IPY_MODEL_01314b46d0c14605b4493faf9049a28a"],"layout":"IPY_MODEL_cec89209ccab4940bd996ad1da6bfd81"}},"a4dd62547f43442e8588292cfaaf7a98":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6c74b8db12e485cbf07978b711ac644":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7804c9a3fc044ed9c62195541cd2fb6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7bc8d475ba7471dbd4bb07022ad616a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a92773c310334cad8f4d100ab3887dce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8d7c87ec62024dd9bf2a5cdc66a4f3dd","IPY_MODEL_59bd7e4fdf514ef08981f668fe1f6de1","IPY_MODEL_0a74807e64274b0abe938bb35ae84822"],"layout":"IPY_MODEL_f6b0842c95aa4f3db78750449300e7c7"}},"a99d8b51d1af44c09a5f2eb01d52bfa0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aad76e6aa36b4619a6708b380a59062f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e9abf059107470481d78bc4fb61e40f","placeholder":"​","style":"IPY_MODEL_1c8c819d3e5b4e399589b7ed216f43c7","value":" 647/647 [02:28&lt;00:00,  4.37it/s, loss=7.36]"}},"ab3d31b6cca84bfb87e5b34dbd685b2b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab44e921a79447e18edae0c9faf50673":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afe6e88195b3483eb67939b3893bafe5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f4826946a024e8bbb1b89ce76b1ef0f","placeholder":"​","style":"IPY_MODEL_5d17388a3d1f454d8a8cdc828a189c67","value":" 647/647 [02:32&lt;00:00,  4.48it/s, loss=6.64]"}},"b0f88c2132f94e909309a823861368ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b173826cc3524845b9f0a032fd4862a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b3fb1acae760427f80277168b263a1e4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b481e18ba2d64333a5c9d0ce0c56ac9b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9c2fdfb3bb64285a1b66b2859ee37c1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb6731c6cdb64050ab4071aaad89da0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bda28a07fb874814ba0ef77adce987cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9bfc54d8ba2141ea8c4e5d3e54ca0aba","IPY_MODEL_2634a606fe094c438b75e897947bfc54","IPY_MODEL_074c3946d2fd4047ac86fc6f44a5e442"],"layout":"IPY_MODEL_f55d8635dada451ba7a51c7233669938"}},"c01ef5a8ab0b4e3586e1882d2768783a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_772998a2cdf748e38d766c9b451e5afa","max":647,"min":0,"orientation":"horizontal","style":"IPY_MODEL_791e3a42867144869bb48e741245fedf","value":647}},"c03c6ad3764c4c8597c32bb1ffab4248":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c222cad4fecf407191ce00ba1c819380":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c2e50311e632417a9f6405da24e57dbe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c3a533f706d447e282fbdcbe102ef047":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c3b4c437718743fb8f77a2910fe5b110":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c574667dad254c8e8d92468673c89eea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8eba7d65c9141549ee3300637d2964e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9d2cb2454a14e3a85979f042ac333cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cacbf373b25f4bb09c96361d3aa98b66":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb6f34d2ddb94d8cb82a198561cd1a43":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_697a625a986542c3bd7750e570644689","placeholder":"​","style":"IPY_MODEL_8cfcc130abe24f688655dcccca3c1119","value":" 57/89 [00:04&lt;00:02, 13.90it/s, loss=7.56]"}},"cce82d99d5d44d3b9c2d09b6a8deeb77":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cec89209ccab4940bd996ad1da6bfd81":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfbf03e60b824b07b3bd488405685505":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d08aea6a09c745af830236ca3a0ec649":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0e3277ada894340b222941bc0d8b5bc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d192f2554a5544138aadf19d4553fb4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d22b41a7795d41b6a2d30a502b3b31e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_31754f22a11e45638046f6fcb8f3ecfd","IPY_MODEL_4f1ddb8adb1348ff8b1201710d2b3e96","IPY_MODEL_04b29c6cd93f4e89898fb561654f2b16"],"layout":"IPY_MODEL_f43f36cff99d4c198420209708545ffd"}},"d32fa23084d54c09a97226fb1eb69c02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d446447e40284fc99f9261a41f53dd35":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_747602191bca49a29cdf2f4e875ab0e1","placeholder":"​","style":"IPY_MODEL_09c86c546d3743569cd2f23b598b1edd","value":"Epoch 2: 100%"}},"d4f1843490c54114933f07aa07796c4d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d51b9cb8413d4c6c96fa23409f2c8b83":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d62896e730604f07ad4cdc2a7fcad328":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_49fad36a492143c98111439a24a406ca","max":89,"min":0,"orientation":"horizontal","style":"IPY_MODEL_24eae4dbaeeb4787939c27385dc8e2ab","value":89}},"d710341aa7374defad95420a943331cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d88befdc052542ae8ab00175439c5f5f","IPY_MODEL_49635cbec7cf4f0bb993cc6aef3a3931","IPY_MODEL_f3a401a3a15349debcd69332e04dad92"],"layout":"IPY_MODEL_e84b61fa16704e52be9b6d44da9fda4e"}},"d77ff34da3204e45b4876f009a025d95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ce8cb1091d8468885e2d9163db9712e","IPY_MODEL_c01ef5a8ab0b4e3586e1882d2768783a","IPY_MODEL_df6cb3c3b34e4ca5910fe2993f465616"],"layout":"IPY_MODEL_74c8109dfb5f48f2b960dbda084e8453"}},"d797b54a29364543bee3af18ccc5a7d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d88befdc052542ae8ab00175439c5f5f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01e11ca1e93844fd98a9e4b412c51ffe","placeholder":"​","style":"IPY_MODEL_d32fa23084d54c09a97226fb1eb69c02","value":"Epoch 6: "}},"dc28a233b1b144f19a1c3653c5dfc720":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df6cb3c3b34e4ca5910fe2993f465616":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f02fb31f1cb4c06b0a619d5e908238b","placeholder":"​","style":"IPY_MODEL_bb6731c6cdb64050ab4071aaad89da0d","value":" 647/647 [02:27&lt;00:00,  4.48it/s, loss=4.59]"}},"e4ea4e4e6bb2427d9a2a864de5a23f3c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e84b61fa16704e52be9b6d44da9fda4e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8986cf621164f83ad1ca3283ceef894":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebbc06aaec294aba8222536ab39e2647":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed378a5d49e44d57bab4f20bc2df6ad8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ee91356df2aa4357a8abc23cc3e8333d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eea03aa3c5274be4b5efd77f8ebcd666":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef3ff9c122ce4407863d74957b80fb32":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f02279245d744fcea4ba1360dc9c035b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1e8316b3f7f4af3a0aca012bf3f92ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3a401a3a15349debcd69332e04dad92":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89abb9ad964a4bf9a0b6b9b94896f255","placeholder":"​","style":"IPY_MODEL_14757c04f5634bae956e4b3bf2840149","value":" 90/? [00:06&lt;00:00, 15.27it/s, loss=8.08]"}},"f43f36cff99d4c198420209708545ffd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f55d8635dada451ba7a51c7233669938":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f60ec39020ff476f89fd37503deaa04d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f861325e1ee54420a547f02df1247d32","IPY_MODEL_5a562566b50e4200af4465fe6aaa2ddc","IPY_MODEL_7e09b6ab3a8b41eb9b64ee340f36eaf0"],"layout":"IPY_MODEL_d4f1843490c54114933f07aa07796c4d"}},"f6b0842c95aa4f3db78750449300e7c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f861325e1ee54420a547f02df1247d32":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f2fea6de81c486d8e40fc9180e65312","placeholder":"​","style":"IPY_MODEL_ab3d31b6cca84bfb87e5b34dbd685b2b","value":"Epoch 6: 100%"}},"f9969524006349c88862de26318b4f94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa5d5d5784754556bc936841cb472a23":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0f88c2132f94e909309a823861368ab","max":647,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9be4872088484fa4aa9e66e50f4934eb","value":647}},"fbefb8047f4b417cb75abc46f79646ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcc302b8fb224862bf9651b6319963f8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":4}
